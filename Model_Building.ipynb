{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- I. [Loading the data:](#Loading-the-data:)\n",
    "\n",
    "II. [Model Building:](#Model-Building:)\n",
    "\n",
    "* [Base Model:](#Base-Model:)\n",
    "\n",
    "* [Automatic Hyper parameter tuning:](#Automatic-Hyper-parameter-tuning:)\n",
    "    * [Model Data Monitoring:](#Model-Data-Monitoring:)\n",
    "    * [Deploying the model with Data Capture:](#Deploying-the-model-with-Data-Capture:)\n",
    "    * [Invoking the endpoint using Boto3: (way-1)](#Invoking-the-endpoint-using-Boto3:-(way-1))\n",
    "    * [Invoking the Endpoint: (way-2)](#Invoking-the-Endpoint:-(way-2))\n",
    "    * [Explore the captured data:](#Explore-the-captured-data:)\n",
    "\n",
    "III. [Model Data Monitor - Baselining and continuous monitoring:](#Model-Data-Monitor-:-Baselining-and-continuous-monitoring:)\n",
    "\n",
    "* [1. Constraint suggestion with baseline/training dataset](#1.-Constraint-suggestion-with-baseline/training-dataset)\n",
    "\n",
    "* [2. Creating a Schedule and Analyzing collected data for data quality issues](#2.-Creating-a-Schedule-and-Analyzing-collected-data-for-data-quality-issues)\n",
    "    * [Create a schedule](#Create-a-schedule)\n",
    "    * [Generating some artificial traffic](#Generating-some-artificial-traffic)\n",
    "    * [Describe and inspect the schedule](#Describe-and-inspect-the-schedule)\n",
    "    * [Analyze the Executions](#Analyze-the-Executions) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. [Loading the data:](#Loading-the-data:)\n",
    "\n",
    "II. [Model Building:](#Model-Building:)\n",
    "\n",
    "* [Base Model:](#Base-Model:)\n",
    "\n",
    "* [Automatic Hyper parameter tuning:](#Automatic-Hyper-parameter-tuning:)\n",
    "\n",
    "III. [Model Data Monitor : Capturing, Baselining and Continuous monitoring:](#Model-Data-Monitor-:-Capturing,-Baselining-and-Continuous-monitoring:)\n",
    "\n",
    "* [1. Data Capturing:](#1.-Data-Capturing:)\n",
    "    * [Deploying the model with Data Capture:](#Deploying-the-model-with-Data-Capture:)\n",
    "    * [Invoking the endpoint using Boto3: (way-1)](#Invoking-the-endpoint-using-Boto3:-(way-1))\n",
    "    * [Invoking the Endpoint: (way-2)](#Invoking-the-Endpoint:-(way-2))\n",
    "    * [Explore the captured data:](#Explore-the-captured-data:)\n",
    "\n",
    "\n",
    "* [2. Constraint suggestion with baseline/training dataset](#2.-Constraint-suggestion-with-baseline/training-dataset)\n",
    "\n",
    "* [3. Creating a Schedule and Analyzing collected data for data quality issues](#3.-Creating-a-Schedule-and-Analyzing-collected-data-for-data-quality-issues)\n",
    "    * [Create a schedule](#Create-a-schedule)\n",
    "    * [Generating some artificial traffic](#Generating-some-artificial-traffic)\n",
    "    * [Describe and inspect the schedule](#Describe-and-inspect-the-schedule)\n",
    "    * [Analyze the Executions](#Analyze-the-Executions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading the data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions for data while modeling in AWS:\n",
    "\n",
    "* Target variable should be the first column\n",
    "* The data should not have any headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer,csv_deserializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Bucket:  accidentbucket\n",
      "Prefix (or Subdirectory):  Data-Processing-Trial3-2022-08-24T23-47-43\n",
      "AWS Region:  us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Specify the resource names and roles\n",
    "role = get_execution_role()\n",
    "bucket = 'accidentbucket'\n",
    "# prefix = 'Data-Processing-2022-08-02T17-07-37' \n",
    "prefix = 'Data-Processing-Trial3-2022-08-24T23-47-43' # s3://accidentbucket/Data-Processing-Trial3-2022-08-24T23-47-43/\n",
    "my_region = boto3.session.Session().region_name\n",
    "\n",
    "print(\"AWS Bucket: \", bucket)\n",
    "print(\"Prefix (or Subdirectory): \", prefix)\n",
    "print(\"AWS Region: \", my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-Processing-Trial3-2022-08-24T23-47-43/part-00000-95dae8bf-d75d-4c62-9dc1-4fe7805b684c-c000.csv\n"
     ]
    }
   ],
   "source": [
    "# Using Boto3 to create a connection\n",
    "s3_client = boto3.client('s3')\n",
    "contents = s3_client.list_objects(Bucket=bucket, Prefix=prefix)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'PC2B8B04KQGWRFY6',\n",
       "  'HostId': '/2qiQjpr+iDoGa/HR2XK0XQOLBiHqjZyzHeb3kYS65dhxnVM356Lvtybvh+flh9wCiEVo8Grz9M=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '/2qiQjpr+iDoGa/HR2XK0XQOLBiHqjZyzHeb3kYS65dhxnVM356Lvtybvh+flh9wCiEVo8Grz9M=',\n",
       "   'x-amz-request-id': 'PC2B8B04KQGWRFY6',\n",
       "   'date': 'Thu, 25 Aug 2022 02:09:32 GMT',\n",
       "   'x-amz-bucket-region': 'us-east-1',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'Contents': [{'Key': 'Data-Processing-Trial3-2022-08-24T23-47-43/part-00000-95dae8bf-d75d-4c62-9dc1-4fe7805b684c-c000.csv',\n",
       "   'LastModified': datetime.datetime(2022, 8, 24, 18, 24, 57, tzinfo=tzlocal()),\n",
       "   'ETag': '\"81844ae851e5eec92edf317d1d0175e1\"',\n",
       "   'Size': 7892940,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': 'aws',\n",
       "    'ID': 'd4a4229a6a4db7cc4f57f9bad2f6023ff80c93d342fb330a153cdf48899ef836'}}],\n",
       " 'Name': 'accidentbucket',\n",
       " 'Prefix': 'Data-Processing-Trial3-2022-08-24T23-47-43',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_client.list_objects(Bucket=bucket, Prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data-Processing-Trial3-2022-08-24T23-47-43/part-00000-95dae8bf-d75d-4c62-9dc1-4fe7805b684c-c000.csv'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[0]['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47406, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_reason_of_death</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hemorrhagic stroke</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reported_reason_of_death  target_encoded  age_years  insurance_grp  \\\n",
       "0             Heart attack               0         71           46.0   \n",
       "1       Hemorrhagic stroke               1          0           46.0   \n",
       "2             Heart attack               0          0           31.0   \n",
       "3             Heart attack               0          5           31.0   \n",
       "4             Heart attack               0          3           31.0   \n",
       "\n",
       "   no_fam_member  total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "0            1.0                1.0              62.0              -1.0   \n",
       "1            1.0                0.0              53.0              -1.0   \n",
       "2            1.0                1.0              53.0              -1.0   \n",
       "3            1.0                1.0              59.0              75.0   \n",
       "4            1.0                2.0              59.0              -1.0   \n",
       "\n",
       "   diagnosis_code_3      p1      p2   p3  alcohol  drug  fire  sex_M  sex_F  \\\n",
       "0              -1.0  1893.0  1820.0  0.0      0.0   0.0   0.0    1.0    0.0   \n",
       "1              -1.0  4010.0  1807.0  0.0      0.0   0.0   0.0    1.0    0.0   \n",
       "2              -1.0  4076.0  1807.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "3              62.0  1807.0     0.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "4              -1.0  4076.0     0.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "\n",
       "   country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  1.0                  0.0   \n",
       "3                  0.0                  1.0                  0.0   \n",
       "4                  0.0                  1.0                  0.0   \n",
       "\n",
       "   country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "0                  1.0                  0.0               1.0   \n",
       "1                  1.0                  0.0               0.0   \n",
       "2                  0.0                  0.0               0.0   \n",
       "3                  0.0                  0.0               1.0   \n",
       "4                  0.0                  0.0               1.0   \n",
       "\n",
       "   place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "0               0.0               0.0                     1.0   \n",
       "1               1.0               0.0                     1.0   \n",
       "2               0.0               1.0                     1.0   \n",
       "3               0.0               0.0                     0.0   \n",
       "4               0.0               0.0                     1.0   \n",
       "\n",
       "   place_of_incident_Not recorded  place_of_incident_School/ Sports Complex  \\\n",
       "0                             0.0                                       0.0   \n",
       "1                             0.0                                       0.0   \n",
       "2                             0.0                                       0.0   \n",
       "3                             1.0                                       0.0   \n",
       "4                             0.0                                       0.0   \n",
       "\n",
       "   place_of_incident_Public property  place_of_incident_Street  \\\n",
       "0                                0.0                       0.0   \n",
       "1                                0.0                       0.0   \n",
       "2                                0.0                       0.0   \n",
       "3                                0.0                       0.0   \n",
       "4                                0.0                       0.0   \n",
       "\n",
       "   place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "0                        0.0                                0.0   \n",
       "1                        0.0                                0.0   \n",
       "2                        0.0                                0.0   \n",
       "3                        0.0                                0.0   \n",
       "4                        0.0                                0.0   \n",
       "\n",
       "   age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "0                    0.0                1.0                0.0   \n",
       "1                    1.0                0.0                0.0   \n",
       "2                    1.0                0.0                0.0   \n",
       "3                    1.0                0.0                0.0   \n",
       "4                    1.0                0.0                0.0   \n",
       "\n",
       "   age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "0                0.0                             1.0   \n",
       "1                0.0                             1.0   \n",
       "2                0.0                             1.0   \n",
       "3                0.0                             1.0   \n",
       "4                0.0                             1.0   \n",
       "\n",
       "   insurance_grp_bin_greater than 50  \n",
       "0                                0.0  \n",
       "1                                0.0  \n",
       "2                                0.0  \n",
       "3                                0.0  \n",
       "4                                0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the S3 uri location for the processed dataset (Option-1)\n",
    "file_obj = s3_client.get_object(Bucket=bucket,Key=contents[0]['Key'])\n",
    "df = pd.read_csv(io.BytesIO(file_obj['Body'].read()))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://accidentbucket/Data-Processing-Trial3-2022-08-24T23-47-43/part-00000-95dae8bf-d75d-4c62-9dc1-4fe7805b684c-c000.csv\n",
      "(47406, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_reason_of_death</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hemorrhagic stroke</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reported_reason_of_death  target_encoded  age_years  insurance_grp  \\\n",
       "0             Heart attack               0         71           46.0   \n",
       "1       Hemorrhagic stroke               1          0           46.0   \n",
       "2             Heart attack               0          0           31.0   \n",
       "3             Heart attack               0          5           31.0   \n",
       "4             Heart attack               0          3           31.0   \n",
       "\n",
       "   no_fam_member  total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "0            1.0                1.0              62.0              -1.0   \n",
       "1            1.0                0.0              53.0              -1.0   \n",
       "2            1.0                1.0              53.0              -1.0   \n",
       "3            1.0                1.0              59.0              75.0   \n",
       "4            1.0                2.0              59.0              -1.0   \n",
       "\n",
       "   diagnosis_code_3      p1      p2   p3  alcohol  drug  fire  sex_M  sex_F  \\\n",
       "0              -1.0  1893.0  1820.0  0.0      0.0   0.0   0.0    1.0    0.0   \n",
       "1              -1.0  4010.0  1807.0  0.0      0.0   0.0   0.0    1.0    0.0   \n",
       "2              -1.0  4076.0  1807.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "3              62.0  1807.0     0.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "4              -1.0  4076.0     0.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "\n",
       "   country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  1.0                  0.0   \n",
       "3                  0.0                  1.0                  0.0   \n",
       "4                  0.0                  1.0                  0.0   \n",
       "\n",
       "   country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "0                  1.0                  0.0               1.0   \n",
       "1                  1.0                  0.0               0.0   \n",
       "2                  0.0                  0.0               0.0   \n",
       "3                  0.0                  0.0               1.0   \n",
       "4                  0.0                  0.0               1.0   \n",
       "\n",
       "   place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "0               0.0               0.0                     1.0   \n",
       "1               1.0               0.0                     1.0   \n",
       "2               0.0               1.0                     1.0   \n",
       "3               0.0               0.0                     0.0   \n",
       "4               0.0               0.0                     1.0   \n",
       "\n",
       "   place_of_incident_Not recorded  place_of_incident_School/ Sports Complex  \\\n",
       "0                             0.0                                       0.0   \n",
       "1                             0.0                                       0.0   \n",
       "2                             0.0                                       0.0   \n",
       "3                             1.0                                       0.0   \n",
       "4                             0.0                                       0.0   \n",
       "\n",
       "   place_of_incident_Public property  place_of_incident_Street  \\\n",
       "0                                0.0                       0.0   \n",
       "1                                0.0                       0.0   \n",
       "2                                0.0                       0.0   \n",
       "3                                0.0                       0.0   \n",
       "4                                0.0                       0.0   \n",
       "\n",
       "   place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "0                        0.0                                0.0   \n",
       "1                        0.0                                0.0   \n",
       "2                        0.0                                0.0   \n",
       "3                        0.0                                0.0   \n",
       "4                        0.0                                0.0   \n",
       "\n",
       "   age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "0                    0.0                1.0                0.0   \n",
       "1                    1.0                0.0                0.0   \n",
       "2                    1.0                0.0                0.0   \n",
       "3                    1.0                0.0                0.0   \n",
       "4                    1.0                0.0                0.0   \n",
       "\n",
       "   age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "0                0.0                             1.0   \n",
       "1                0.0                             1.0   \n",
       "2                0.0                             1.0   \n",
       "3                0.0                             1.0   \n",
       "4                0.0                             1.0   \n",
       "\n",
       "   insurance_grp_bin_greater than 50  \n",
       "0                                0.0  \n",
       "1                                0.0  \n",
       "2                                0.0  \n",
       "3                                0.0  \n",
       "4                                0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly using s3 uri (Option-2)\n",
    "s3_location = 's3://{}/{}'.format(bucket,contents[0]['Key'])\n",
    "print(s3_location)\n",
    "df = pd.read_csv(s3_location)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33184, 38) (14222, 38)\n"
     ]
    }
   ],
   "source": [
    "# Random split\n",
    "train_data, test_data = np.split(df.sample(frac=1, random_state=123), [int(0.70 * len(df))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_reason_of_death</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14593</th>\n",
       "      <td>Hemorrhagic stroke</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34710</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16543</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reported_reason_of_death  target_encoded  age_years  insurance_grp  \\\n",
       "14593       Hemorrhagic stroke               1          5           37.0   \n",
       "34710             Heart attack               0         24            2.0   \n",
       "16543             Heart attack               0         14           32.0   \n",
       "\n",
       "       no_fam_member  total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "14593            1.0                0.0              59.0              -1.0   \n",
       "34710            1.0                0.0              62.0              -1.0   \n",
       "16543            1.0                1.0              52.0              -1.0   \n",
       "\n",
       "       diagnosis_code_3      p1   p2   p3  alcohol  drug  fire  sex_M  sex_F  \\\n",
       "14593              -1.0  4076.0  0.0  0.0      0.0   0.0   0.0    1.0    0.0   \n",
       "34710              -1.0  1864.0  0.0  0.0      0.0   0.0   0.0    0.0    1.0   \n",
       "16543              -1.0   661.0  0.0  0.0      0.0   0.0   0.0    1.0    0.0   \n",
       "\n",
       "       country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "14593                  0.0                  1.0                  0.0   \n",
       "34710                  0.0                  1.0                  0.0   \n",
       "16543                  0.0                  1.0                  0.0   \n",
       "\n",
       "       country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "14593                  0.0                  0.0               0.0   \n",
       "34710                  0.0                  0.0               0.0   \n",
       "16543                  0.0                  0.0               0.0   \n",
       "\n",
       "       place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "14593               1.0               0.0                     1.0   \n",
       "34710               1.0               0.0                     1.0   \n",
       "16543               1.0               0.0                     1.0   \n",
       "\n",
       "       place_of_incident_Not recorded  \\\n",
       "14593                             0.0   \n",
       "34710                             0.0   \n",
       "16543                             0.0   \n",
       "\n",
       "       place_of_incident_School/ Sports Complex  \\\n",
       "14593                                       0.0   \n",
       "34710                                       0.0   \n",
       "16543                                       0.0   \n",
       "\n",
       "       place_of_incident_Public property  place_of_incident_Street  \\\n",
       "14593                                0.0                       0.0   \n",
       "34710                                0.0                       0.0   \n",
       "16543                                0.0                       0.0   \n",
       "\n",
       "       place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "14593                        0.0                                0.0   \n",
       "34710                        0.0                                0.0   \n",
       "16543                        0.0                                0.0   \n",
       "\n",
       "       age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "14593                    1.0                0.0                0.0   \n",
       "34710                    0.0                0.0                1.0   \n",
       "16543                    1.0                0.0                0.0   \n",
       "\n",
       "       age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "14593                0.0                             1.0   \n",
       "34710                0.0                             1.0   \n",
       "16543                0.0                             1.0   \n",
       "\n",
       "       insurance_grp_bin_greater than 50  \n",
       "14593                                0.0  \n",
       "34710                                0.0  \n",
       "16543                                0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_reason_of_death</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24640</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35381</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33726</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reported_reason_of_death  target_encoded  age_years  insurance_grp  \\\n",
       "24640             Heart attack               0         15           47.0   \n",
       "35381             Heart attack               0         88           50.0   \n",
       "33726             Heart attack               0          0           10.0   \n",
       "\n",
       "       no_fam_member  total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "24640            1.0                1.0              52.0              -1.0   \n",
       "35381            1.0                2.0              62.0              -1.0   \n",
       "33726            1.0                4.0              59.0              76.0   \n",
       "\n",
       "       diagnosis_code_3      p1      p2   p3  alcohol  drug  fire  sex_M  \\\n",
       "24640              -1.0  3287.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "35381              -1.0  1807.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "33726              58.0  1519.0  1679.0  0.0      0.0   0.0   0.0    1.0   \n",
       "\n",
       "       sex_F  country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "24640    1.0                  0.0                  1.0                  0.0   \n",
       "35381    1.0                  0.0                  0.0                  1.0   \n",
       "33726    0.0                  0.0                  1.0                  0.0   \n",
       "\n",
       "       country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "24640                  0.0                  0.0               1.0   \n",
       "35381                  0.0                  0.0               1.0   \n",
       "33726                  0.0                  0.0               1.0   \n",
       "\n",
       "       place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "24640               0.0               0.0                     0.0   \n",
       "35381               0.0               0.0                     1.0   \n",
       "33726               0.0               0.0                     0.0   \n",
       "\n",
       "       place_of_incident_Not recorded  \\\n",
       "24640                             0.0   \n",
       "35381                             0.0   \n",
       "33726                             0.0   \n",
       "\n",
       "       place_of_incident_School/ Sports Complex  \\\n",
       "24640                                       0.0   \n",
       "35381                                       0.0   \n",
       "33726                                       0.0   \n",
       "\n",
       "       place_of_incident_Public property  place_of_incident_Street  \\\n",
       "24640                                0.0                       1.0   \n",
       "35381                                0.0                       0.0   \n",
       "33726                                1.0                       0.0   \n",
       "\n",
       "       place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "24640                        0.0                                0.0   \n",
       "35381                        0.0                                0.0   \n",
       "33726                        0.0                                0.0   \n",
       "\n",
       "       age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "24640                    1.0                0.0                0.0   \n",
       "35381                    0.0                1.0                0.0   \n",
       "33726                    1.0                0.0                0.0   \n",
       "\n",
       "       age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "24640                0.0                             1.0   \n",
       "35381                0.0                             0.0   \n",
       "33726                0.0                             1.0   \n",
       "\n",
       "       insurance_grp_bin_greater than 50  \n",
       "24640                                0.0  \n",
       "35381                                1.0  \n",
       "33726                                0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_reason_of_death</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heart attack</td>\n",
       "      <td>0</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hemorrhagic stroke</td>\n",
       "      <td>1</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "      <td>14902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suicide</td>\n",
       "      <td>2</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reported_reason_of_death  target_encoded  age_years  insurance_grp  \\\n",
       "0             Heart attack               0      28000          28000   \n",
       "1       Hemorrhagic stroke               1      14902          14902   \n",
       "2                    Other               3       2009           2009   \n",
       "3                  Suicide               2       2495           2495   \n",
       "\n",
       "   no_fam_member  total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "0          28000              28000             28000             28000   \n",
       "1          14902              14902             14902             14902   \n",
       "2           2009               2009              2009              2009   \n",
       "3           2495               2495              2495              2495   \n",
       "\n",
       "   diagnosis_code_3     p1     p2     p3  alcohol   drug   fire  sex_M  sex_F  \\\n",
       "0             28000  28000  28000  28000    28000  28000  28000  28000  28000   \n",
       "1             14902  14902  14902  14902    14902  14902  14902  14902  14902   \n",
       "2              2009   2009   2009   2009     2009   2009   2009   2009   2009   \n",
       "3              2495   2495   2495   2495     2495   2495   2495   2495   2495   \n",
       "\n",
       "   country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "0                28000                28000                28000   \n",
       "1                14902                14902                14902   \n",
       "2                 2009                 2009                 2009   \n",
       "3                 2495                 2495                 2495   \n",
       "\n",
       "   country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "0                28000                28000             28000   \n",
       "1                14902                14902             14902   \n",
       "2                 2009                 2009              2009   \n",
       "3                 2495                 2495              2495   \n",
       "\n",
       "   place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "0             28000             28000                   28000   \n",
       "1             14902             14902                   14902   \n",
       "2              2009              2009                    2009   \n",
       "3              2495              2495                    2495   \n",
       "\n",
       "   place_of_incident_Not recorded  place_of_incident_School/ Sports Complex  \\\n",
       "0                           28000                                     28000   \n",
       "1                           14902                                     14902   \n",
       "2                            2009                                      2009   \n",
       "3                            2495                                      2495   \n",
       "\n",
       "   place_of_incident_Public property  place_of_incident_Street  \\\n",
       "0                              28000                     28000   \n",
       "1                              14902                     14902   \n",
       "2                               2009                      2009   \n",
       "3                               2495                      2495   \n",
       "\n",
       "   place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "0                      28000                              28000   \n",
       "1                      14902                              14902   \n",
       "2                       2009                               2009   \n",
       "3                       2495                               2495   \n",
       "\n",
       "   age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "0                  28000              28000              28000   \n",
       "1                  14902              14902              14902   \n",
       "2                   2009               2009               2009   \n",
       "3                   2495               2495               2495   \n",
       "\n",
       "   age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "0              28000                           28000   \n",
       "1              14902                           14902   \n",
       "2               2009                            2009   \n",
       "3               2495                            2495   \n",
       "\n",
       "   insurance_grp_bin_greater than 50  \n",
       "0                              28000  \n",
       "1                              14902  \n",
       "2                               2009  \n",
       "3                               2495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Heart attack': 0, 'Hemorrhagic stroke': 1, 'Other': 3, 'Suicide': 2}\n"
     ]
    }
   ],
   "source": [
    "# Getting the label map dictionary\n",
    "temp = df.groupby(['reported_reason_of_death','target_encoded']).count().reset_index()\n",
    "display(temp.head(5))\n",
    "label_map = dict(zip(temp['reported_reason_of_death'].values, temp['target_encoded'].values))\n",
    "print(label_map)\n",
    "\n",
    "# Saving it as a pickle file for s3 upload\n",
    "import pickle\n",
    "label_file = 'target_label_map.pkl'\n",
    "with open(label_file,'wb') as f:\n",
    "    pickle.dump(label_map,f)\n",
    "    \n",
    "# Uploading the file to s3 bucket for future use\n",
    "s3_client.upload_file(Filename=label_file,Bucket=bucket,Key='target_label_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to load the pickle file from s3 for future use\n",
    "# s3_client.download_file(Bucket=bucket,Key='target_label_map',Filename='target_label_map')\n",
    "\n",
    "# with open('target_label_map','rb') as F:\n",
    "#     map_ = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the label column (we already have encoded version of the label for training purpose)\n",
    "train_data = train_data.drop('reported_reason_of_death',axis=1)\n",
    "test_data = test_data.drop('reported_reason_of_death',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the training data to s3\n",
    "pd.concat([train_data['target_encoded'], train_data.drop(['target_encoded'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "s3_client.upload_file(Filename='train.csv',Bucket=bucket,Key='data/train/train.csv')\n",
    "\n",
    "# Creating the Training input for modeling\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train.csv'.format(bucket, 'data/train'), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the test data to s3\n",
    "pd.concat([test_data['target_encoded'], test_data.drop(['target_encoded'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "s3_client.upload_file(Filename='test.csv',Bucket=bucket,Key='data/test/test.csv')\n",
    "\n",
    "# Creating the Test input for modeling\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/test.csv'.format(bucket, 'data/test'), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://accidentbucket/model/training/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "subdir = 'model/training'\n",
    "output_path ='s3://{}/{}/output'.format(bucket, subdir)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Building:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Base Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = sagemaker.image_uris.retrieve(region=my_region,\n",
    "                                         framework='xgboost',\n",
    "                                         version='latest')\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.estimator.Estimator object at 0x7f49ae3f7b10>\n"
     ]
    }
   ],
   "source": [
    "# create the sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Instantiate the model object\n",
    "xgb = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                   role = role,\n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   volume_size=4,\n",
    "                                    output_path=output_path,\n",
    "                                    sagemaker_session=sess\n",
    "                                   )\n",
    "\n",
    "# Set the hyperparameters\n",
    "xgb.set_hyperparameters(objective= 'multi:softmax',num_class=4,num_round=500,max_depth=5)\n",
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-25 02:29:27 Starting - Starting the training job...\n",
      "2022-08-25 02:29:51 Starting - Preparing the instances for trainingProfilerReport-1661394567: InProgress\n",
      "......\n",
      "2022-08-25 02:30:54 Downloading - Downloading input data...\n",
      "2022-08-25 02:31:14 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-08-25:02:32:03:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-08-25:02:32:03:INFO] File size need to be processed in the node: 6.88mb. Available memory size in the node: 8324.2mb\u001b[0m\n",
      "\u001b[34m[2022-08-25:02:32:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[02:32:03] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[02:32:03] 33184x36 matrix with 1194624 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-08-25:02:32:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[02:32:03] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[02:32:03] 14222x36 matrix with 511992 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.166948#011validation-merror:0.166221\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[1]#011train-merror:0.161132#011validation-merror:0.162495\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[2]#011train-merror:0.160047#011validation-merror:0.162073\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[3]#011train-merror:0.159113#011validation-merror:0.160526\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.157244#011validation-merror:0.159612\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[5]#011train-merror:0.156732#011validation-merror:0.15919\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[6]#011train-merror:0.156581#011validation-merror:0.158487\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[7]#011train-merror:0.156702#011validation-merror:0.158065\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[8]#011train-merror:0.156672#011validation-merror:0.158276\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[9]#011train-merror:0.15625#011validation-merror:0.157573\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[10]#011train-merror:0.155828#011validation-merror:0.157502\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[11]#011train-merror:0.154954#011validation-merror:0.157151\u001b[0m\n",
      "\u001b[34m[02:32:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[12]#011train-merror:0.153839#011validation-merror:0.155393\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[13]#011train-merror:0.151669#011validation-merror:0.153424\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[14]#011train-merror:0.151489#011validation-merror:0.153143\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[15]#011train-merror:0.150464#011validation-merror:0.153495\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[16]#011train-merror:0.148294#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[17]#011train-merror:0.1473#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[18]#011train-merror:0.14507#011validation-merror:0.15026\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[19]#011train-merror:0.143895#011validation-merror:0.15012\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[20]#011train-merror:0.143292#011validation-merror:0.15019\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[21]#011train-merror:0.142328#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[22]#011train-merror:0.141665#011validation-merror:0.15019\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[23]#011train-merror:0.140128#011validation-merror:0.149416\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[24]#011train-merror:0.139284#011validation-merror:0.149909\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[25]#011train-merror:0.138229#011validation-merror:0.150049\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[26]#011train-merror:0.137777#011validation-merror:0.150049\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[27]#011train-merror:0.137175#011validation-merror:0.149627\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[28]#011train-merror:0.136632#011validation-merror:0.149557\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[29]#011train-merror:0.135818#011validation-merror:0.148854\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[30]#011train-merror:0.135366#011validation-merror:0.148713\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[31]#011train-merror:0.133347#011validation-merror:0.149979\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[32]#011train-merror:0.132594#011validation-merror:0.15019\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[33]#011train-merror:0.132112#011validation-merror:0.149487\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[34]#011train-merror:0.131841#011validation-merror:0.148643\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[35]#011train-merror:0.131148#011validation-merror:0.148713\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[36]#011train-merror:0.130756#011validation-merror:0.148713\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[37]#011train-merror:0.130424#011validation-merror:0.148573\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[38]#011train-merror:0.130002#011validation-merror:0.148291\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[39]#011train-merror:0.12937#011validation-merror:0.148432\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[40]#011train-merror:0.128978#011validation-merror:0.14808\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[41]#011train-merror:0.127953#011validation-merror:0.147799\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[42]#011train-merror:0.12732#011validation-merror:0.148291\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[43]#011train-merror:0.12714#011validation-merror:0.147729\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[44]#011train-merror:0.126115#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[45]#011train-merror:0.125693#011validation-merror:0.146393\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[46]#011train-merror:0.12503#011validation-merror:0.146112\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[47]#011train-merror:0.124307#011validation-merror:0.146041\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[48]#011train-merror:0.123734#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[49]#011train-merror:0.123041#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[50]#011train-merror:0.122408#011validation-merror:0.145479\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[51]#011train-merror:0.122047#011validation-merror:0.145127\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[52]#011train-merror:0.121595#011validation-merror:0.14583\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[53]#011train-merror:0.121203#011validation-merror:0.146041\u001b[0m\n",
      "\u001b[34m[02:32:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[54]#011train-merror:0.120419#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[55]#011train-merror:0.119817#011validation-merror:0.145971\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[56]#011train-merror:0.119757#011validation-merror:0.14569\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[57]#011train-merror:0.119757#011validation-merror:0.145549\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[58]#011train-merror:0.118822#011validation-merror:0.145549\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[59]#011train-merror:0.118129#011validation-merror:0.14569\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[60]#011train-merror:0.117496#011validation-merror:0.146041\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[61]#011train-merror:0.117346#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[62]#011train-merror:0.116984#011validation-merror:0.145198\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[63]#011train-merror:0.116502#011validation-merror:0.144424\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[64]#011train-merror:0.116291#011validation-merror:0.144494\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[65]#011train-merror:0.116291#011validation-merror:0.144284\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[66]#011train-merror:0.115839#011validation-merror:0.144424\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[67]#011train-merror:0.115387#011validation-merror:0.144213\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[68]#011train-merror:0.115297#011validation-merror:0.143651\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[69]#011train-merror:0.115116#011validation-merror:0.143862\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[70]#011train-merror:0.114392#011validation-merror:0.144635\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[71]#011train-merror:0.113699#011validation-merror:0.144776\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[72]#011train-merror:0.112615#011validation-merror:0.144916\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[73]#011train-merror:0.112524#011validation-merror:0.14583\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[74]#011train-merror:0.112072#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[75]#011train-merror:0.11162#011validation-merror:0.145901\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-merror:0.111319#011validation-merror:0.14569\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-merror:0.110535#011validation-merror:0.145479\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-merror:0.110294#011validation-merror:0.144987\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-merror:0.109782#011validation-merror:0.144073\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-merror:0.109571#011validation-merror:0.144846\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-merror:0.109119#011validation-merror:0.145268\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-merror:0.108456#011validation-merror:0.145549\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-merror:0.107672#011validation-merror:0.144776\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-merror:0.107582#011validation-merror:0.144916\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-merror:0.1071#011validation-merror:0.145127\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-merror:0.106648#011validation-merror:0.145409\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-merror:0.106648#011validation-merror:0.145338\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-merror:0.106497#011validation-merror:0.14569\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-merror:0.106437#011validation-merror:0.146112\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-merror:0.106015#011validation-merror:0.14583\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-merror:0.106045#011validation-merror:0.146041\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-merror:0.105925#011validation-merror:0.145971\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-merror:0.105081#011validation-merror:0.145409\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-merror:0.104599#011validation-merror:0.144846\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-merror:0.104177#011validation-merror:0.144635\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-merror:0.103996#011validation-merror:0.144987\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-merror:0.103514#011validation-merror:0.145268\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-merror:0.103423#011validation-merror:0.144987\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-merror:0.10276#011validation-merror:0.145409\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[100]#011train-merror:0.102067#011validation-merror:0.145268\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[101]#011train-merror:0.101826#011validation-merror:0.145971\u001b[0m\n",
      "\u001b[34m[02:32:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[102]#011train-merror:0.101555#011validation-merror:0.146252\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[103]#011train-merror:0.101193#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[104]#011train-merror:0.100771#011validation-merror:0.14583\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[105]#011train-merror:0.10041#011validation-merror:0.145971\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[106]#011train-merror:0.10038#011validation-merror:0.146252\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[107]#011train-merror:0.099928#011validation-merror:0.146112\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[108]#011train-merror:0.099747#011validation-merror:0.146604\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[109]#011train-merror:0.099144#011validation-merror:0.146252\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[110]#011train-merror:0.098903#011validation-merror:0.146112\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\n",
      "2022-08-25 02:32:11 Training - Training image download completed. Training in progress.\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[111]#011train-merror:0.098481#011validation-merror:0.14583\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[112]#011train-merror:0.0983#011validation-merror:0.14576\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[113]#011train-merror:0.09815#011validation-merror:0.146041\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[114]#011train-merror:0.097969#011validation-merror:0.146463\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[115]#011train-merror:0.097547#011validation-merror:0.145971\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[116]#011train-merror:0.097065#011validation-merror:0.146463\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[117]#011train-merror:0.096944#011validation-merror:0.146182\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[118]#011train-merror:0.096553#011validation-merror:0.14583\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[119]#011train-merror:0.096131#011validation-merror:0.146182\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[120]#011train-merror:0.09607#011validation-merror:0.146534\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[121]#011train-merror:0.095709#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[122]#011train-merror:0.095196#011validation-merror:0.146323\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[123]#011train-merror:0.094805#011validation-merror:0.146604\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[124]#011train-merror:0.094503#011validation-merror:0.146463\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[125]#011train-merror:0.094292#011validation-merror:0.146463\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[126]#011train-merror:0.09378#011validation-merror:0.146604\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[127]#011train-merror:0.09381#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[128]#011train-merror:0.093419#011validation-merror:0.147026\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[129]#011train-merror:0.093027#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[130]#011train-merror:0.092876#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[131]#011train-merror:0.092454#011validation-merror:0.146674\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[132]#011train-merror:0.092093#011validation-merror:0.146604\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[133]#011train-merror:0.091972#011validation-merror:0.146323\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[134]#011train-merror:0.091791#011validation-merror:0.146463\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[135]#011train-merror:0.09152#011validation-merror:0.146604\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[136]#011train-merror:0.09149#011validation-merror:0.146534\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[137]#011train-merror:0.091309#011validation-merror:0.146252\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[138]#011train-merror:0.090134#011validation-merror:0.146463\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[139]#011train-merror:0.089802#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[140]#011train-merror:0.089652#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[141]#011train-merror:0.089622#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[142]#011train-merror:0.089411#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[143]#011train-merror:0.088989#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[144]#011train-merror:0.088687#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[145]#011train-merror:0.088657#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[146]#011train-merror:0.088567#011validation-merror:0.147096\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[147]#011train-merror:0.088567#011validation-merror:0.147237\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[148]#011train-merror:0.088115#011validation-merror:0.147307\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[149]#011train-merror:0.087934#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[150]#011train-merror:0.087633#011validation-merror:0.147307\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[151]#011train-merror:0.087392#011validation-merror:0.147518\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[152]#011train-merror:0.08712#011validation-merror:0.147448\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[153]#011train-merror:0.08709#011validation-merror:0.147729\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[154]#011train-merror:0.08697#011validation-merror:0.147659\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[155]#011train-merror:0.086879#011validation-merror:0.147588\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[156]#011train-merror:0.086608#011validation-merror:0.147096\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[157]#011train-merror:0.086066#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[158]#011train-merror:0.085493#011validation-merror:0.147096\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[159]#011train-merror:0.085252#011validation-merror:0.146955\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[160]#011train-merror:0.085162#011validation-merror:0.146674\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[161]#011train-merror:0.085222#011validation-merror:0.146674\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[162]#011train-merror:0.08486#011validation-merror:0.146393\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[163]#011train-merror:0.084709#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[164]#011train-merror:0.084529#011validation-merror:0.146955\u001b[0m\n",
      "\u001b[34m[02:32:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[165]#011train-merror:0.084288#011validation-merror:0.147026\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[166]#011train-merror:0.083745#011validation-merror:0.147237\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[167]#011train-merror:0.083534#011validation-merror:0.147237\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[168]#011train-merror:0.083173#011validation-merror:0.146955\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[169]#011train-merror:0.083022#011validation-merror:0.146744\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[170]#011train-merror:0.083052#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[171]#011train-merror:0.082751#011validation-merror:0.146955\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[172]#011train-merror:0.08248#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[173]#011train-merror:0.082299#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[174]#011train-merror:0.082208#011validation-merror:0.146534\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[175]#011train-merror:0.082058#011validation-merror:0.146182\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[176]#011train-merror:0.081847#011validation-merror:0.146252\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[177]#011train-merror:0.081365#011validation-merror:0.146393\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[178]#011train-merror:0.081093#011validation-merror:0.146604\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[179]#011train-merror:0.080732#011validation-merror:0.146393\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[180]#011train-merror:0.08031#011validation-merror:0.146674\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[181]#011train-merror:0.080159#011validation-merror:0.146885\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[182]#011train-merror:0.080159#011validation-merror:0.146674\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[183]#011train-merror:0.079978#011validation-merror:0.146674\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[184]#011train-merror:0.079677#011validation-merror:0.146534\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[185]#011train-merror:0.079345#011validation-merror:0.146252\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[186]#011train-merror:0.079195#011validation-merror:0.146323\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[187]#011train-merror:0.079104#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[188]#011train-merror:0.079074#011validation-merror:0.146955\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[189]#011train-merror:0.079044#011validation-merror:0.147307\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[190]#011train-merror:0.078893#011validation-merror:0.14801\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[191]#011train-merror:0.078924#011validation-merror:0.148291\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[192]#011train-merror:0.078652#011validation-merror:0.14808\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[193]#011train-merror:0.078381#011validation-merror:0.148221\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[194]#011train-merror:0.077989#011validation-merror:0.14808\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[195]#011train-merror:0.077959#011validation-merror:0.148151\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[196]#011train-merror:0.077839#011validation-merror:0.14794\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[197]#011train-merror:0.077688#011validation-merror:0.147869\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[198]#011train-merror:0.077447#011validation-merror:0.147799\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[199]#011train-merror:0.077115#011validation-merror:0.147869\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[200]#011train-merror:0.076874#011validation-merror:0.147518\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[201]#011train-merror:0.076392#011validation-merror:0.14801\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[202]#011train-merror:0.07597#011validation-merror:0.14808\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[203]#011train-merror:0.075398#011validation-merror:0.148502\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[204]#011train-merror:0.075458#011validation-merror:0.148362\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[205]#011train-merror:0.075338#011validation-merror:0.148362\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[206]#011train-merror:0.075157#011validation-merror:0.148151\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[207]#011train-merror:0.075066#011validation-merror:0.148291\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[208]#011train-merror:0.074976#011validation-merror:0.147869\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[209]#011train-merror:0.074885#011validation-merror:0.147729\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[210]#011train-merror:0.074795#011validation-merror:0.147659\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[211]#011train-merror:0.074644#011validation-merror:0.147377\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[212]#011train-merror:0.074343#011validation-merror:0.146815\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[213]#011train-merror:0.074132#011validation-merror:0.147799\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[214]#011train-merror:0.074162#011validation-merror:0.147799\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[215]#011train-merror:0.074012#011validation-merror:0.147518\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[216]#011train-merror:0.07368#011validation-merror:0.147448\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[217]#011train-merror:0.073499#011validation-merror:0.147659\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[218]#011train-merror:0.073469#011validation-merror:0.147869\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[219]#011train-merror:0.073138#011validation-merror:0.147518\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[220]#011train-merror:0.072836#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[221]#011train-merror:0.072716#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[222]#011train-merror:0.072475#011validation-merror:0.147166\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[223]#011train-merror:0.072324#011validation-merror:0.147588\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[224]#011train-merror:0.071842#011validation-merror:0.147307\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[225]#011train-merror:0.07133#011validation-merror:0.147307\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[226]#011train-merror:0.071179#011validation-merror:0.147377\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[227]#011train-merror:0.071119#011validation-merror:0.147448\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[228]#011train-merror:0.070968#011validation-merror:0.147518\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[229]#011train-merror:0.070878#011validation-merror:0.147659\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[230]#011train-merror:0.070787#011validation-merror:0.147729\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[231]#011train-merror:0.070667#011validation-merror:0.14801\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[232]#011train-merror:0.070546#011validation-merror:0.148221\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[233]#011train-merror:0.070365#011validation-merror:0.14801\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[234]#011train-merror:0.070124#011validation-merror:0.148221\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[235]#011train-merror:0.069883#011validation-merror:0.14801\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[236]#011train-merror:0.069853#011validation-merror:0.148221\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[237]#011train-merror:0.069702#011validation-merror:0.148502\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[238]#011train-merror:0.069672#011validation-merror:0.148362\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[239]#011train-merror:0.069702#011validation-merror:0.148432\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[240]#011train-merror:0.069612#011validation-merror:0.148221\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[241]#011train-merror:0.069491#011validation-merror:0.148643\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[242]#011train-merror:0.06925#011validation-merror:0.148713\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[243]#011train-merror:0.069341#011validation-merror:0.148573\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[244]#011train-merror:0.0691#011validation-merror:0.148502\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[245]#011train-merror:0.069039#011validation-merror:0.148854\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[246]#011train-merror:0.068889#011validation-merror:0.148924\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[247]#011train-merror:0.068678#011validation-merror:0.149205\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[248]#011train-merror:0.068376#011validation-merror:0.149416\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[249]#011train-merror:0.068527#011validation-merror:0.149276\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[250]#011train-merror:0.068045#011validation-merror:0.149135\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[251]#011train-merror:0.067774#011validation-merror:0.148995\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[252]#011train-merror:0.067382#011validation-merror:0.148995\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[253]#011train-merror:0.067171#011validation-merror:0.148924\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[254]#011train-merror:0.067291#011validation-merror:0.148854\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[255]#011train-merror:0.067352#011validation-merror:0.148784\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[256]#011train-merror:0.06699#011validation-merror:0.148502\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[257]#011train-merror:0.066839#011validation-merror:0.148573\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[258]#011train-merror:0.066659#011validation-merror:0.149065\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[259]#011train-merror:0.066508#011validation-merror:0.148784\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[260]#011train-merror:0.066508#011validation-merror:0.148924\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[261]#011train-merror:0.066056#011validation-merror:0.149065\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[262]#011train-merror:0.065875#011validation-merror:0.149135\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[263]#011train-merror:0.065604#011validation-merror:0.149276\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[264]#011train-merror:0.065333#011validation-merror:0.149487\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[265]#011train-merror:0.065001#011validation-merror:0.149698\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[266]#011train-merror:0.065001#011validation-merror:0.149698\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[267]#011train-merror:0.065092#011validation-merror:0.149979\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[268]#011train-merror:0.064971#011validation-merror:0.150049\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[269]#011train-merror:0.06476#011validation-merror:0.149768\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[270]#011train-merror:0.064609#011validation-merror:0.149698\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[271]#011train-merror:0.064399#011validation-merror:0.148854\u001b[0m\n",
      "\u001b[34m[02:32:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[272]#011train-merror:0.064248#011validation-merror:0.149276\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[273]#011train-merror:0.064218#011validation-merror:0.149135\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[274]#011train-merror:0.064308#011validation-merror:0.149135\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[275]#011train-merror:0.064278#011validation-merror:0.149346\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[276]#011train-merror:0.064157#011validation-merror:0.149065\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[277]#011train-merror:0.063856#011validation-merror:0.149416\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[278]#011train-merror:0.063615#011validation-merror:0.149698\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[279]#011train-merror:0.063555#011validation-merror:0.150049\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[280]#011train-merror:0.063163#011validation-merror:0.149979\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[281]#011train-merror:0.063253#011validation-merror:0.149557\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[282]#011train-merror:0.063404#011validation-merror:0.149557\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[283]#011train-merror:0.063193#011validation-merror:0.149627\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[284]#011train-merror:0.062771#011validation-merror:0.149909\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[285]#011train-merror:0.062621#011validation-merror:0.15012\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[286]#011train-merror:0.06241#011validation-merror:0.150049\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[287]#011train-merror:0.062108#011validation-merror:0.15019\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[288]#011train-merror:0.062018#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[289]#011train-merror:0.062078#011validation-merror:0.150541\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[290]#011train-merror:0.061867#011validation-merror:0.15019\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[291]#011train-merror:0.061747#011validation-merror:0.150049\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[292]#011train-merror:0.061747#011validation-merror:0.149698\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[293]#011train-merror:0.061506#011validation-merror:0.15019\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[294]#011train-merror:0.061475#011validation-merror:0.15033\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[295]#011train-merror:0.061355#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[296]#011train-merror:0.061264#011validation-merror:0.150752\u001b[0m\n",
      "\u001b[34m[02:32:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[297]#011train-merror:0.061264#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[298]#011train-merror:0.061234#011validation-merror:0.150471\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[299]#011train-merror:0.060873#011validation-merror:0.15026\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[300]#011train-merror:0.060571#011validation-merror:0.15033\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[301]#011train-merror:0.06036#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[302]#011train-merror:0.06021#011validation-merror:0.150541\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[303]#011train-merror:0.060089#011validation-merror:0.150541\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[304]#011train-merror:0.059908#011validation-merror:0.15026\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[305]#011train-merror:0.059818#011validation-merror:0.15012\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[306]#011train-merror:0.059637#011validation-merror:0.150612\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[307]#011train-merror:0.059637#011validation-merror:0.150612\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[308]#011train-merror:0.059547#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[309]#011train-merror:0.059366#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[310]#011train-merror:0.059185#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[311]#011train-merror:0.059125#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[312]#011train-merror:0.058974#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[313]#011train-merror:0.058793#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[314]#011train-merror:0.058733#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[315]#011train-merror:0.058402#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[316]#011train-merror:0.058311#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[317]#011train-merror:0.05801#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[318]#011train-merror:0.05798#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[319]#011train-merror:0.057829#011validation-merror:0.15026\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[320]#011train-merror:0.057618#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[321]#011train-merror:0.057317#011validation-merror:0.150682\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[322]#011train-merror:0.057196#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[323]#011train-merror:0.057257#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[324]#011train-merror:0.056774#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[325]#011train-merror:0.056594#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[326]#011train-merror:0.056473#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[327]#011train-merror:0.056383#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[328]#011train-merror:0.056232#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[329]#011train-merror:0.05584#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[330]#011train-merror:0.05578#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[331]#011train-merror:0.05572#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[332]#011train-merror:0.055479#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[333]#011train-merror:0.055539#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[334]#011train-merror:0.055328#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[335]#011train-merror:0.055237#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[336]#011train-merror:0.055147#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[337]#011train-merror:0.055298#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[338]#011train-merror:0.055268#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[339]#011train-merror:0.055237#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[340]#011train-merror:0.055117#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[341]#011train-merror:0.055087#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[342]#011train-merror:0.055027#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[343]#011train-merror:0.054876#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[344]#011train-merror:0.054816#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[345]#011train-merror:0.054695#011validation-merror:0.151526\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[346]#011train-merror:0.054394#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[347]#011train-merror:0.054484#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[348]#011train-merror:0.053881#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[349]#011train-merror:0.053972#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[350]#011train-merror:0.053791#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[351]#011train-merror:0.053701#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[352]#011train-merror:0.05349#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[353]#011train-merror:0.053399#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[354]#011train-merror:0.053429#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[355]#011train-merror:0.05349#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[356]#011train-merror:0.053399#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[357]#011train-merror:0.053309#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[358]#011train-merror:0.053068#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[359]#011train-merror:0.052736#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[360]#011train-merror:0.052555#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[361]#011train-merror:0.052314#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[362]#011train-merror:0.052164#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[363]#011train-merror:0.052073#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[364]#011train-merror:0.051923#011validation-merror:0.151807\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[365]#011train-merror:0.051682#011validation-merror:0.151877\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[366]#011train-merror:0.051621#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[367]#011train-merror:0.051471#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[368]#011train-merror:0.05135#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[369]#011train-merror:0.05129#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[370]#011train-merror:0.05126#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[371]#011train-merror:0.050958#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[372]#011train-merror:0.050988#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[373]#011train-merror:0.050988#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[374]#011train-merror:0.050687#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[375]#011train-merror:0.050597#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[376]#011train-merror:0.050536#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[377]#011train-merror:0.050506#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[378]#011train-merror:0.050446#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[379]#011train-merror:0.050446#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[380]#011train-merror:0.050476#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[381]#011train-merror:0.050325#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[382]#011train-merror:0.050115#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[383]#011train-merror:0.050175#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[384]#011train-merror:0.050054#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[385]#011train-merror:0.050145#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[386]#011train-merror:0.049934#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[387]#011train-merror:0.049572#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[388]#011train-merror:0.049391#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[389]#011train-merror:0.049361#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[390]#011train-merror:0.049331#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[391]#011train-merror:0.049301#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[392]#011train-merror:0.049331#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[393]#011train-merror:0.049#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[394]#011train-merror:0.048909#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[395]#011train-merror:0.048819#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[396]#011train-merror:0.048789#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[397]#011train-merror:0.048638#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[398]#011train-merror:0.048578#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[399]#011train-merror:0.048487#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[400]#011train-merror:0.048367#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[401]#011train-merror:0.048367#011validation-merror:0.150682\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[402]#011train-merror:0.048337#011validation-merror:0.150541\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[403]#011train-merror:0.048276#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[404]#011train-merror:0.048095#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[405]#011train-merror:0.048005#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[406]#011train-merror:0.047945#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[407]#011train-merror:0.047915#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[408]#011train-merror:0.047312#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[409]#011train-merror:0.047131#011validation-merror:0.150401\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[410]#011train-merror:0.047041#011validation-merror:0.150541\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[411]#011train-merror:0.047071#011validation-merror:0.150541\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[412]#011train-merror:0.047131#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[413]#011train-merror:0.047041#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[414]#011train-merror:0.04686#011validation-merror:0.150823\u001b[0m\n",
      "\u001b[34m[02:32:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[415]#011train-merror:0.046709#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[416]#011train-merror:0.046589#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[417]#011train-merror:0.046559#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[418]#011train-merror:0.046559#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[419]#011train-merror:0.046559#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[420]#011train-merror:0.046679#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[421]#011train-merror:0.046528#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[422]#011train-merror:0.046468#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[423]#011train-merror:0.046378#011validation-merror:0.151807\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[424]#011train-merror:0.046348#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[425]#011train-merror:0.046257#011validation-merror:0.151737\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[426]#011train-merror:0.046076#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[427]#011train-merror:0.045956#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[428]#011train-merror:0.045715#011validation-merror:0.151104\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[429]#011train-merror:0.045655#011validation-merror:0.151034\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[430]#011train-merror:0.045564#011validation-merror:0.150963\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[431]#011train-merror:0.045474#011validation-merror:0.150893\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[432]#011train-merror:0.045233#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[433]#011train-merror:0.045142#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[434]#011train-merror:0.045112#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[435]#011train-merror:0.045112#011validation-merror:0.151455\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[436]#011train-merror:0.044931#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[437]#011train-merror:0.044901#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[438]#011train-merror:0.044871#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[439]#011train-merror:0.044871#011validation-merror:0.151174\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[440]#011train-merror:0.044961#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[441]#011train-merror:0.044781#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[442]#011train-merror:0.04466#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[443]#011train-merror:0.04472#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[444]#011train-merror:0.04457#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[445]#011train-merror:0.04469#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[446]#011train-merror:0.044419#011validation-merror:0.151737\u001b[0m\n",
      "\u001b[34m[02:32:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[447]#011train-merror:0.044057#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[448]#011train-merror:0.043726#011validation-merror:0.151245\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[449]#011train-merror:0.043666#011validation-merror:0.151315\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[450]#011train-merror:0.043425#011validation-merror:0.151385\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[451]#011train-merror:0.043334#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[452]#011train-merror:0.043425#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[453]#011train-merror:0.043304#011validation-merror:0.151737\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[454]#011train-merror:0.043304#011validation-merror:0.151877\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[455]#011train-merror:0.043304#011validation-merror:0.151737\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[456]#011train-merror:0.043304#011validation-merror:0.151877\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[457]#011train-merror:0.043183#011validation-merror:0.151877\u001b[0m\n",
      "\u001b[34m[02:32:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[458]#011train-merror:0.043063#011validation-merror:0.151737\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[459]#011train-merror:0.042942#011validation-merror:0.151526\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[460]#011train-merror:0.042882#011validation-merror:0.151737\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[461]#011train-merror:0.042792#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[462]#011train-merror:0.042762#011validation-merror:0.151596\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[463]#011train-merror:0.042611#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[464]#011train-merror:0.042671#011validation-merror:0.151877\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[465]#011train-merror:0.042641#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[466]#011train-merror:0.042641#011validation-merror:0.151666\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[467]#011train-merror:0.042611#011validation-merror:0.151807\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[468]#011train-merror:0.0424#011validation-merror:0.152159\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[469]#011train-merror:0.04237#011validation-merror:0.15244\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[470]#011train-merror:0.042219#011validation-merror:0.152088\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[471]#011train-merror:0.04231#011validation-merror:0.152299\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[472]#011train-merror:0.042189#011validation-merror:0.15244\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[473]#011train-merror:0.042159#011validation-merror:0.151948\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[474]#011train-merror:0.042189#011validation-merror:0.152018\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[475]#011train-merror:0.042068#011validation-merror:0.152018\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[476]#011train-merror:0.042129#011validation-merror:0.152018\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[477]#011train-merror:0.042038#011validation-merror:0.152299\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[478]#011train-merror:0.041978#011validation-merror:0.152299\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[479]#011train-merror:0.042099#011validation-merror:0.15244\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[480]#011train-merror:0.041888#011validation-merror:0.15251\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[481]#011train-merror:0.042038#011validation-merror:0.152299\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[482]#011train-merror:0.041978#011validation-merror:0.15244\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[483]#011train-merror:0.041948#011validation-merror:0.15244\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[484]#011train-merror:0.041797#011validation-merror:0.152862\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[485]#011train-merror:0.041797#011validation-merror:0.152721\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[486]#011train-merror:0.041797#011validation-merror:0.15251\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[487]#011train-merror:0.041797#011validation-merror:0.152721\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[488]#011train-merror:0.041677#011validation-merror:0.152721\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[489]#011train-merror:0.041556#011validation-merror:0.15251\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[490]#011train-merror:0.041436#011validation-merror:0.152651\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[491]#011train-merror:0.041375#011validation-merror:0.152581\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[492]#011train-merror:0.041375#011validation-merror:0.152721\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[493]#011train-merror:0.041436#011validation-merror:0.152651\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[494]#011train-merror:0.041134#011validation-merror:0.152581\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[495]#011train-merror:0.041225#011validation-merror:0.15251\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[496]#011train-merror:0.041164#011validation-merror:0.15237\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[497]#011train-merror:0.041195#011validation-merror:0.15251\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[498]#011train-merror:0.041044#011validation-merror:0.152721\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[02:32:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[499]#011train-merror:0.040863#011validation-merror:0.152862\u001b[0m\n",
      "\n",
      "2022-08-25 02:32:55 Uploading - Uploading generated training model\n",
      "2022-08-25 02:33:32 Completed - Training job completed\n",
      "Training seconds: 132\n",
      "Billable seconds: 132\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "xgb.fit({'train': s3_input_train,'validation': s3_input_test},wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "# Deploying the xgb model\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "xgb_predictor = xgb.deploy(endpoint_name='xgb-test-2',\n",
    "\tinitial_instance_count = 1,\n",
    "\tinstance_type = 'ml.m4.xlarge',\n",
    "\tserializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb-test-2'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0,0.0,0.0,0.0,1.0,\n",
      "(14222,)\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test data\n",
    "test_data_array = test_data.drop(['target_encoded'], axis=1).values #load the data into an array\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "print(predictions[:20])\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)\n",
    "print(predictions_array[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14222, 37)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:--------------------------------------\n",
      "Accuracy: 0.8471382365349459\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88      8412\n",
      "           1       0.74      0.84      0.79      4489\n",
      "           2       0.77      0.70      0.73       742\n",
      "           3       1.00      1.00      1.00       579\n",
      "\n",
      "    accuracy                           0.85     14222\n",
      "   macro avg       0.86      0.85      0.85     14222\n",
      "weighted avg       0.85      0.85      0.85     14222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Test Data:--------------------------------------\")\n",
    "accuracy = metrics.accuracy_score(test_data.target_encoded.values,predictions_array)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(metrics.classification_report(test_data.target_encoded.values,predictions_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking the endpoint using Boto3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb-test-2'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the runtime object\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = 'xgb-test-2'\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24640</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35381</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33726</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_encoded  age_years  insurance_grp  no_fam_member  \\\n",
       "24640               0         15           47.0            1.0   \n",
       "35381               0         88           50.0            1.0   \n",
       "33726               0          0           10.0            1.0   \n",
       "7096                0         13           32.0            1.0   \n",
       "34102               1         34           47.0            1.0   \n",
       "\n",
       "       total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "24640                1.0              52.0              -1.0   \n",
       "35381                2.0              62.0              -1.0   \n",
       "33726                4.0              59.0              76.0   \n",
       "7096                 2.0              62.0              -1.0   \n",
       "34102                1.0              59.0              82.0   \n",
       "\n",
       "       diagnosis_code_3      p1      p2   p3  alcohol  drug  fire  sex_M  \\\n",
       "24640              -1.0  3287.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "35381              -1.0  1807.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "33726              58.0  1519.0  1679.0  0.0      0.0   0.0   0.0    1.0   \n",
       "7096               -1.0  1211.0     0.0  0.0      0.0   0.0   0.0    1.0   \n",
       "34102              59.0  4014.0     0.0  0.0      0.0   0.0   0.0    1.0   \n",
       "\n",
       "       sex_F  country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "24640    1.0                  0.0                  1.0                  0.0   \n",
       "35381    1.0                  0.0                  0.0                  1.0   \n",
       "33726    0.0                  0.0                  1.0                  0.0   \n",
       "7096     0.0                  0.0                  0.0                  1.0   \n",
       "34102    0.0                  0.0                  1.0                  0.0   \n",
       "\n",
       "       country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "24640                  0.0                  0.0               1.0   \n",
       "35381                  0.0                  0.0               1.0   \n",
       "33726                  0.0                  0.0               1.0   \n",
       "7096                   0.0                  0.0               0.0   \n",
       "34102                  0.0                  0.0               1.0   \n",
       "\n",
       "       place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "24640               0.0               0.0                     0.0   \n",
       "35381               0.0               0.0                     1.0   \n",
       "33726               0.0               0.0                     0.0   \n",
       "7096                1.0               0.0                     1.0   \n",
       "34102               0.0               0.0                     0.0   \n",
       "\n",
       "       place_of_incident_Not recorded  \\\n",
       "24640                             0.0   \n",
       "35381                             0.0   \n",
       "33726                             0.0   \n",
       "7096                              0.0   \n",
       "34102                             1.0   \n",
       "\n",
       "       place_of_incident_School/ Sports Complex  \\\n",
       "24640                                       0.0   \n",
       "35381                                       0.0   \n",
       "33726                                       0.0   \n",
       "7096                                        0.0   \n",
       "34102                                       0.0   \n",
       "\n",
       "       place_of_incident_Public property  place_of_incident_Street  \\\n",
       "24640                                0.0                       1.0   \n",
       "35381                                0.0                       0.0   \n",
       "33726                                1.0                       0.0   \n",
       "7096                                 0.0                       0.0   \n",
       "34102                                0.0                       0.0   \n",
       "\n",
       "       place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "24640                        0.0                                0.0   \n",
       "35381                        0.0                                0.0   \n",
       "33726                        0.0                                0.0   \n",
       "7096                         0.0                                0.0   \n",
       "34102                        0.0                                0.0   \n",
       "\n",
       "       age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "24640                    1.0                0.0                0.0   \n",
       "35381                    0.0                1.0                0.0   \n",
       "33726                    1.0                0.0                0.0   \n",
       "7096                     1.0                0.0                0.0   \n",
       "34102                    0.0                0.0                1.0   \n",
       "\n",
       "       age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "24640                0.0                             1.0   \n",
       "35381                0.0                             0.0   \n",
       "33726                0.0                             1.0   \n",
       "7096                 0.0                             1.0   \n",
       "34102                0.0                             1.0   \n",
       "\n",
       "       insurance_grp_bin_greater than 50  \n",
       "24640                                0.0  \n",
       "35381                                1.0  \n",
       "33726                                0.0  \n",
       "7096                                 0.0  \n",
       "34102                                0.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'15,47.0,1.0,1.0,52.0,-1.0,-1.0,3287.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n88,50.0,1.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the data to bytes array format to make it work with invoke_endpoint method\n",
    "csv_object = test_data.iloc[:,1:].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "csv_object[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=csv_object,\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "output_ = np.array(response[\"Body\"].read().decode('utf-8'))\n",
    "print(type(output_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '9d15b489-711d-4456-83d9-59cbf2d88983', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9d15b489-711d-4456-83d9-59cbf2d88983', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Thu, 25 Aug 2022 03:00:45 GMT', 'content-type': 'text/csv; charset=utf-8', 'content-length': '56887'}, 'RetryAttempts': 0}, 'ContentType': 'text/csv; charset=utf-8', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7f49a75b4910>}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ = output_.reshape(-1)[0].split(',')\n",
    "output_ = [float(i) for i in output_]\n",
    "output_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:--------------------------------------\n",
      "Accuracy: 0.8471382365349459\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88      8412\n",
      "           1       0.74      0.84      0.79      4489\n",
      "           2       0.77      0.70      0.73       742\n",
      "           3       1.00      1.00      1.00       579\n",
      "\n",
      "    accuracy                           0.85     14222\n",
      "   macro avg       0.86      0.85      0.85     14222\n",
      "weighted avg       0.85      0.85      0.85     14222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_output = test_data['target_encoded'].values\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Test Data:--------------------------------------\")\n",
    "accuracy = metrics.accuracy_score(actual_output,output_)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(metrics.classification_report(actual_output,output_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Automatic Hyper parameter tuning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. For example, suppose that you want to solve a binary classification problem on this marketing dataset. Your goal is to maximize the area under the curve (auc) metric of the algorithm by training an XGBoost Algorithm model. You don't know which values of the eta, alpha, min_child_weight, and max_depth hyperparameters to use to train the best model. To find the best values for these hyperparameters, you can specify ranges of values that Amazon SageMaker hyperparameter tuning searches to find the combination of values that results in the training job that performs the best as measured by the objective metric that you chose. Hyperparameter tuning launches training jobs that use hyperparameter values in the ranges that you specified, and returns the training job with highest auc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We will tune four hyperparameters in this example:\n",
    "* **eta:** Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative.\n",
    "* **min_child_weight:** Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this simply corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is.\n",
    "* **alpha:** L1 regularization term on weights. Increasing this value makes models more conservative.\n",
    "* **max_depth:** Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_range = {'eta': ContinuousParameter(0,1),\n",
    "                        'min_child_weight': ContinuousParameter(1,30),\n",
    "                         'alpha': ContinuousParameter(0,10),\n",
    "                         'max_depth': IntegerParameter(1,10)\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. Since we are using built-in XGBoost algorithm here, it emits two predefined metrics: validation:merror and train:merror, and we elected to monitor validation:merror as you can see below. In this case, we only need to specify the metric name and do not need to provide regex. If you bring your own algorithm, your algorithm emits metrics by itself. In that case, you'll need to add a MetricDefinition object here to define the format of those metrics through regex, so that SageMaker knows how to extract those metrics from your CloudWatch logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:merror'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, we'll create a HyperparameterTuner object, to which we pass:\n",
    "* The XGBoost estimator we created above\n",
    "* Our hyperparameter ranges\n",
    "* Objective metric name and definition\n",
    "* Tuning resource configurations such as Number of training jobs to run in total and how many training jobs can be run in parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_range,\n",
    "                            max_jobs=12,\n",
    "                            max_parallel_jobs=3,\n",
    "                            base_tuning_job_name = 'xgbtest2',\n",
    "                            objective_type = 'Minimize'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.tuner.HyperparameterTuner at 0x7f49a7611910>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now we can launch a hyperparameter tuning job by calling fit() function. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Fit the tuning job\n",
    "tuner.fit({'train': s3_input_train,'validation': s3_input_test},wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'xgbtest2-220825-0315',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:143176219551:hyper-parameter-tuning-job/xgbtest2-220825-0315',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'validation:merror'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 12,\n",
       "   'MaxParallelTrainingJobs': 3},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'max_depth',\n",
       "     'MinValue': '1',\n",
       "     'MaxValue': '10',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [{'Name': 'eta',\n",
       "     'MinValue': '0',\n",
       "     'MaxValue': '1',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'min_child_weight',\n",
       "     'MinValue': '1',\n",
       "     'MaxValue': '30',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'alpha',\n",
       "     'MinValue': '0',\n",
       "     'MaxValue': '10',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'CategoricalParameterRanges': []},\n",
       "  'TrainingJobEarlyStoppingType': 'Off'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'validation:merror',\n",
       "   'num_class': '4',\n",
       "   'num_round': '500',\n",
       "   'objective': 'multi:softmax'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'train:mae',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:merror',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-merror:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:mae',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:logloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:macro_precision',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-macro_precision:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:mlogloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mlogloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:binary_f_beta',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-binary_f_beta:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:recall',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-recall:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:precision',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-precision:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:error',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:ndcg',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:map',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:auc',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:auc',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:error',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:merror',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-merror:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:rmse',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:logloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:balanced_accuracy',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-balanced_accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:rmse',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:mse',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:ndcg',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:macro_recall',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-macro_recall:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:r2',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-r2:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:mlogloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mlogloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:map',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:macro_f_beta',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-macro_f_beta:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'ObjectiveMetric',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-merror:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'}]},\n",
       "  'RoleArn': 'arn:aws:iam::143176219551:role/service-role/AmazonSageMaker-ExecutionRole-20211115T211961',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://accidentbucket/data/train/train.csv',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'csv'},\n",
       "   {'ChannelName': 'validation',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://accidentbucket/data/test/test.csv',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'csv'}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://accidentbucket/model/training/output'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 4},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2022, 8, 25, 3, 15, 50, 974000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2022, 8, 25, 3, 25, 59, 96000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 8, 25, 3, 25, 59, 96000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 12,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 12, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'xgbtest2-220825-0315-006-10eba8fa',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:143176219551:training-job/xgbtest2-220825-0315-006-10eba8fa',\n",
       "  'CreationTime': datetime.datetime(2022, 8, 25, 3, 19, 50, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2022, 8, 25, 3, 19, 57, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2022, 8, 25, 3, 20, 49, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'alpha': '7.477673975482768',\n",
       "   'eta': '0.9722133326969217',\n",
       "   'max_depth': '2',\n",
       "   'min_child_weight': '21.255750439116163'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'validation:merror',\n",
       "   'Value': 0.14498700201511383},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': 'fb440d19-ba94-4c5d-b7c2-5475bec16cd3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fb440d19-ba94-4c5d-b7c2-5475bec16cd3',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '6416',\n",
       "   'date': 'Thu, 25 Aug 2022 03:28:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuner summary\n",
    "tuner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgbtest2-220825-0315-006-10eba8fa'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Training job name\n",
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Data Monitor : Capturing, Baselining and Continuous monitoring:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 steps to do the Model & Data monitoring in AWS:\n",
    "\n",
    "1. Capturing the data that will be sent to the deployed endpoint (Data Capturing)\n",
    "2. Creating a baseline for the data on which the model is trained (Baselining)\n",
    "3. Creating a monitoring schedule which compares the captured data with the baseline data statistics for any deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Data Capturing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deploying the model with Data Capture:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://accidentbucket/model_monitor/datacapture\n",
      "EndpointName=tuned-xgboost-3\n"
     ]
    }
   ],
   "source": [
    "# Data capture config\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "# Path where we need to store the data that will be captured after the model is deployed\n",
    "data_capture_prefix = 'model_monitor/datacapture'\n",
    "s3_capture_upload_path = 's3://{}/{}'.format(bucket, data_capture_prefix)\n",
    "print(s3_capture_upload_path)\n",
    "\n",
    "endpoint_name = 'tuned-xgboost-3'\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture=True,\n",
    "                        sampling_percentage=100,\n",
    "                        destination_s3_uri=s3_capture_upload_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-25 03:21:02 Starting - Found matching resource for reuse\n",
      "2022-08-25 03:21:02 Downloading - Downloading input data\n",
      "2022-08-25 03:21:02 Training - Training image download completed. Training in progress.\n",
      "2022-08-25 03:21:02 Uploading - Uploading generated training model\n",
      "2022-08-25 03:21:02 Completed - Resource reused by training job: xgbtest2-220825-0315-007-051ca6c0\n",
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the best trained model\n",
    "tuner_predictor = tuner.deploy(initial_instance_count=1,\n",
    "                               endpoint_name=endpoint_name,\n",
    "                               instance_type = 'ml.m4.xlarge',\n",
    "                               serializer = CSVSerializer(),\n",
    "                               data_capture_config=data_capture_config\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuned-xgboost-3'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14222,)\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test data\n",
    "\n",
    "test_data_array = test_data.drop(['target_encoded'], axis=1).values #load the data into an array\n",
    "predictions = tuner_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:--------------------------------------\n",
      "Accuracy: 0.8550133595837435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.89      8412\n",
      "           1       0.74      0.88      0.80      4489\n",
      "           2       0.76      0.73      0.74       742\n",
      "           3       1.00      1.00      1.00       579\n",
      "\n",
      "    accuracy                           0.86     14222\n",
      "   macro avg       0.86      0.86      0.86     14222\n",
      "weighted avg       0.87      0.86      0.86     14222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Test Data:--------------------------------------\")\n",
    "accuracy = metrics.accuracy_score(test_data.target_encoded.values,predictions_array)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(metrics.classification_report(test_data.target_encoded.values,predictions_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24640</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35381</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33726</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_encoded  age_years  insurance_grp  no_fam_member  \\\n",
       "24640               0         15           47.0            1.0   \n",
       "35381               0         88           50.0            1.0   \n",
       "33726               0          0           10.0            1.0   \n",
       "7096                0         13           32.0            1.0   \n",
       "34102               1         34           47.0            1.0   \n",
       "\n",
       "       total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "24640                1.0              52.0              -1.0   \n",
       "35381                2.0              62.0              -1.0   \n",
       "33726                4.0              59.0              76.0   \n",
       "7096                 2.0              62.0              -1.0   \n",
       "34102                1.0              59.0              82.0   \n",
       "\n",
       "       diagnosis_code_3      p1      p2   p3  alcohol  drug  fire  sex_M  \\\n",
       "24640              -1.0  3287.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "35381              -1.0  1807.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "33726              58.0  1519.0  1679.0  0.0      0.0   0.0   0.0    1.0   \n",
       "7096               -1.0  1211.0     0.0  0.0      0.0   0.0   0.0    1.0   \n",
       "34102              59.0  4014.0     0.0  0.0      0.0   0.0   0.0    1.0   \n",
       "\n",
       "       sex_F  country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "24640    1.0                  0.0                  1.0                  0.0   \n",
       "35381    1.0                  0.0                  0.0                  1.0   \n",
       "33726    0.0                  0.0                  1.0                  0.0   \n",
       "7096     0.0                  0.0                  0.0                  1.0   \n",
       "34102    0.0                  0.0                  1.0                  0.0   \n",
       "\n",
       "       country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "24640                  0.0                  0.0               1.0   \n",
       "35381                  0.0                  0.0               1.0   \n",
       "33726                  0.0                  0.0               1.0   \n",
       "7096                   0.0                  0.0               0.0   \n",
       "34102                  0.0                  0.0               1.0   \n",
       "\n",
       "       place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "24640               0.0               0.0                     0.0   \n",
       "35381               0.0               0.0                     1.0   \n",
       "33726               0.0               0.0                     0.0   \n",
       "7096                1.0               0.0                     1.0   \n",
       "34102               0.0               0.0                     0.0   \n",
       "\n",
       "       place_of_incident_Not recorded  \\\n",
       "24640                             0.0   \n",
       "35381                             0.0   \n",
       "33726                             0.0   \n",
       "7096                              0.0   \n",
       "34102                             1.0   \n",
       "\n",
       "       place_of_incident_School/ Sports Complex  \\\n",
       "24640                                       0.0   \n",
       "35381                                       0.0   \n",
       "33726                                       0.0   \n",
       "7096                                        0.0   \n",
       "34102                                       0.0   \n",
       "\n",
       "       place_of_incident_Public property  place_of_incident_Street  \\\n",
       "24640                                0.0                       1.0   \n",
       "35381                                0.0                       0.0   \n",
       "33726                                1.0                       0.0   \n",
       "7096                                 0.0                       0.0   \n",
       "34102                                0.0                       0.0   \n",
       "\n",
       "       place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "24640                        0.0                                0.0   \n",
       "35381                        0.0                                0.0   \n",
       "33726                        0.0                                0.0   \n",
       "7096                         0.0                                0.0   \n",
       "34102                        0.0                                0.0   \n",
       "\n",
       "       age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "24640                    1.0                0.0                0.0   \n",
       "35381                    0.0                1.0                0.0   \n",
       "33726                    1.0                0.0                0.0   \n",
       "7096                     1.0                0.0                0.0   \n",
       "34102                    0.0                0.0                1.0   \n",
       "\n",
       "       age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "24640                0.0                             1.0   \n",
       "35381                0.0                             0.0   \n",
       "33726                0.0                             1.0   \n",
       "7096                 0.0                             1.0   \n",
       "34102                0.0                             1.0   \n",
       "\n",
       "       insurance_grp_bin_greater than 50  \n",
       "24640                                0.0  \n",
       "35381                                1.0  \n",
       "33726                                0.0  \n",
       "7096                                 0.0  \n",
       "34102                                0.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Invoking the endpoint using Boto3: (way-1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuned-xgboost-3'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the runtime object\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = 'tuned-xgboost-3'\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>age_years</th>\n",
       "      <th>insurance_grp</th>\n",
       "      <th>no_fam_member</th>\n",
       "      <th>total_visit_count</th>\n",
       "      <th>diagnosis_code_1</th>\n",
       "      <th>diagnosis_code_2</th>\n",
       "      <th>diagnosis_code_3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>fire</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>country_of_origin_V</th>\n",
       "      <th>country_of_origin_C</th>\n",
       "      <th>country_of_origin_L</th>\n",
       "      <th>country_of_origin_S</th>\n",
       "      <th>country_of_origin_M</th>\n",
       "      <th>place_of_death_2</th>\n",
       "      <th>place_of_death_0</th>\n",
       "      <th>place_of_death_1</th>\n",
       "      <th>place_of_incident_Home</th>\n",
       "      <th>place_of_incident_Not recorded</th>\n",
       "      <th>place_of_incident_School/ Sports Complex</th>\n",
       "      <th>place_of_incident_Public property</th>\n",
       "      <th>place_of_incident_Street</th>\n",
       "      <th>place_of_incident_Unknown</th>\n",
       "      <th>place_of_incident_Industrial area</th>\n",
       "      <th>age_bins_less than 20</th>\n",
       "      <th>age_bins_60 above</th>\n",
       "      <th>age_bins_20 to 40</th>\n",
       "      <th>age_bins_41 to 60</th>\n",
       "      <th>insurance_grp_bin_less than 50</th>\n",
       "      <th>insurance_grp_bin_greater than 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24640</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35381</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33726</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_encoded  age_years  insurance_grp  no_fam_member  \\\n",
       "24640               0         15           47.0            1.0   \n",
       "35381               0         88           50.0            1.0   \n",
       "33726               0          0           10.0            1.0   \n",
       "7096                0         13           32.0            1.0   \n",
       "34102               1         34           47.0            1.0   \n",
       "\n",
       "       total_visit_count  diagnosis_code_1  diagnosis_code_2  \\\n",
       "24640                1.0              52.0              -1.0   \n",
       "35381                2.0              62.0              -1.0   \n",
       "33726                4.0              59.0              76.0   \n",
       "7096                 2.0              62.0              -1.0   \n",
       "34102                1.0              59.0              82.0   \n",
       "\n",
       "       diagnosis_code_3      p1      p2   p3  alcohol  drug  fire  sex_M  \\\n",
       "24640              -1.0  3287.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "35381              -1.0  1807.0     0.0  0.0      0.0   0.0   0.0    0.0   \n",
       "33726              58.0  1519.0  1679.0  0.0      0.0   0.0   0.0    1.0   \n",
       "7096               -1.0  1211.0     0.0  0.0      0.0   0.0   0.0    1.0   \n",
       "34102              59.0  4014.0     0.0  0.0      0.0   0.0   0.0    1.0   \n",
       "\n",
       "       sex_F  country_of_origin_V  country_of_origin_C  country_of_origin_L  \\\n",
       "24640    1.0                  0.0                  1.0                  0.0   \n",
       "35381    1.0                  0.0                  0.0                  1.0   \n",
       "33726    0.0                  0.0                  1.0                  0.0   \n",
       "7096     0.0                  0.0                  0.0                  1.0   \n",
       "34102    0.0                  0.0                  1.0                  0.0   \n",
       "\n",
       "       country_of_origin_S  country_of_origin_M  place_of_death_2  \\\n",
       "24640                  0.0                  0.0               1.0   \n",
       "35381                  0.0                  0.0               1.0   \n",
       "33726                  0.0                  0.0               1.0   \n",
       "7096                   0.0                  0.0               0.0   \n",
       "34102                  0.0                  0.0               1.0   \n",
       "\n",
       "       place_of_death_0  place_of_death_1  place_of_incident_Home  \\\n",
       "24640               0.0               0.0                     0.0   \n",
       "35381               0.0               0.0                     1.0   \n",
       "33726               0.0               0.0                     0.0   \n",
       "7096                1.0               0.0                     1.0   \n",
       "34102               0.0               0.0                     0.0   \n",
       "\n",
       "       place_of_incident_Not recorded  \\\n",
       "24640                             0.0   \n",
       "35381                             0.0   \n",
       "33726                             0.0   \n",
       "7096                              0.0   \n",
       "34102                             1.0   \n",
       "\n",
       "       place_of_incident_School/ Sports Complex  \\\n",
       "24640                                       0.0   \n",
       "35381                                       0.0   \n",
       "33726                                       0.0   \n",
       "7096                                        0.0   \n",
       "34102                                       0.0   \n",
       "\n",
       "       place_of_incident_Public property  place_of_incident_Street  \\\n",
       "24640                                0.0                       1.0   \n",
       "35381                                0.0                       0.0   \n",
       "33726                                1.0                       0.0   \n",
       "7096                                 0.0                       0.0   \n",
       "34102                                0.0                       0.0   \n",
       "\n",
       "       place_of_incident_Unknown  place_of_incident_Industrial area  \\\n",
       "24640                        0.0                                0.0   \n",
       "35381                        0.0                                0.0   \n",
       "33726                        0.0                                0.0   \n",
       "7096                         0.0                                0.0   \n",
       "34102                        0.0                                0.0   \n",
       "\n",
       "       age_bins_less than 20  age_bins_60 above  age_bins_20 to 40  \\\n",
       "24640                    1.0                0.0                0.0   \n",
       "35381                    0.0                1.0                0.0   \n",
       "33726                    1.0                0.0                0.0   \n",
       "7096                     1.0                0.0                0.0   \n",
       "34102                    0.0                0.0                1.0   \n",
       "\n",
       "       age_bins_41 to 60  insurance_grp_bin_less than 50  \\\n",
       "24640                0.0                             1.0   \n",
       "35381                0.0                             0.0   \n",
       "33726                0.0                             1.0   \n",
       "7096                 0.0                             1.0   \n",
       "34102                0.0                             1.0   \n",
       "\n",
       "       insurance_grp_bin_greater than 50  \n",
       "24640                                0.0  \n",
       "35381                                1.0  \n",
       "33726                                0.0  \n",
       "7096                                 0.0  \n",
       "34102                                0.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'15,47.0,1.0,1.0,52.0,-1.0,-1.0,3287.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n88,50.0,1.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0\\n0,10.0,1.0,4.0,59.0,76.0,58.0,1519.0,1679.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n13,32.0,1.0,2.0,62.0,-1.0,-1.0,1211.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n34,47.0,1.0,1.0,59.0,82.0,59.0,4014.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0\\n91,3.0,4.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n60,78.0,1.0,1.0,58.0,-1.0,-1.0,3299.0,4057.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0\\n82,47.0,4.0,1.0,59.0,82.0,72.0,649.0,4056.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n74,41.0,1.0,2.0,71.0,-1.0,-1.0,611.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n3,90.0,1.0,1.0,56.0,-1.0,-1.0,1345.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the data to bytes array format to make it work with invoke_endpoint method (only for 10 rows)\n",
    "csv_object = test_data.iloc[:10,1:].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "csv_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Bulk/Batch prediction\n",
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=csv_object,\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "output_ = np.array(response[\"Body\"].read().decode('utf-8'))\n",
    "print(type(output_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ = output_.reshape(-1)[0].split(',')\n",
    "output_ = [float(i) for i in output_]\n",
    "output_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:--------------------------------------\n",
      "Accuracy: 0.8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_output = test_data['target_encoded'].values\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Test Data:--------------------------------------\")\n",
    "accuracy = metrics.accuracy_score(actual_output[:10],output_)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(metrics.classification_report(actual_output[:10],output_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Invoking the Endpoint: (way-2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sagemaker.predictor import Predictor\n",
    "# import sagemaker\n",
    "# import time\n",
    "\n",
    "# predictor = Predictor(endpoint_name=endpoint_name, serializer=sagemaker.serializers.CSVSerializer())\n",
    "# test_out = predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "# print(test_out[:10])\n",
    "\n",
    "# test_predictions_array = np.fromstring(test_out[:], sep=',') # and turn the prediction into an array\n",
    "# print(test_predictions_array.shape)\n",
    "\n",
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "# print(\"Test Data:--------------------------------------\")\n",
    "# accuracy = metrics.accuracy_score(test_data.target_encoded.values,test_predictions_array)\n",
    "# print(f\"Accuracy: {accuracy}\\n\")\n",
    "# print(metrics.classification_report(test_data.target_encoded.values,test_predictions_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explore the captured data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now list the data capture files stored in Amazon S3. You should expect to see different files from different time periods organized based on the hour in which the invocation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Capture Files:\n",
      "model_monitor/datacapture/tuned-xgboost-3/AllTraffic/2022/08/25/06/12-59-860-35037ddb-283e-46ec-909f-c4aac5f8f6a9.jsonl\n",
      " model_monitor/datacapture/tuned-xgboost-3/AllTraffic/2022/08/25/06/20-08-455-de16662c-0886-4ee0-b428-1c15e15b2059.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Listing the files in the data capture path using boto3\n",
    "s3_client = boto3.Session().client('s3')\n",
    "current_endpoint_capture_prefix = '{}/{}'.format(data_capture_prefix, endpoint_name)\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get('Contents')]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, view the contents of a single capture file. Here you should see all the data captured in an Amazon SageMaker specific JSON-line formatted file. Take a quick peek at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"15,47.0,1.0,1.0,52.0,-1.0,-1.0,3287.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n88,50.0,1.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0\\n0,10.0,1.0,4.0,59.0,76.0,58.0,1519.0,1679.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n13,32.0,1.0,2.0,62.0,-1.0,-1.0,1211.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n34,47.0,1.0,1.0,59.0,82.0,59.0,4014.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0\\n91,3.0,4.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n60,78.0,1.0,1.0,58.0,-1.0,-1.0,3299.0,4057.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0\\n82,47.0,4.0,1.0,59.0,82.0,72.0,649.0,4056.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n74,41.0,1.0,2.0,71.0,-1.0,-1.0,611.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n3,90.0,1.0,1.0,56.0,-1.0,-1.0,1345.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0\\n\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"570df349-1ceb-43af-832d-592bd9332feb\",\"inferenceTime\":\"2022-08-25T06:20:08Z\"},\"eventVersion\":\"0\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket, Key=obj_key).get('Body').read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** If you send one row at a time to the endpoint for prediction then the json structure you see above will have INPUT and OUTPUT details for single row only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"text/csv\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"15,47.0,1.0,1.0,52.0,-1.0,-1.0,3287.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n88,50.0,1.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0\\n0,10.0,1.0,4.0,59.0,76.0,58.0,1519.0,1679.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n13,32.0,1.0,2.0,62.0,-1.0,-1.0,1211.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0\\n34,47.0,1.0,1.0,59.0,82.0,59.0,4014.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0\\n91,3.0,4.0,2.0,62.0,-1.0,-1.0,1807.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n60,78.0,1.0,1.0,58.0,-1.0,-1.0,3299.0,4057.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0\\n82,47.0,4.0,1.0,59.0,82.0,72.0,649.0,4056.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n74,41.0,1.0,2.0,71.0,-1.0,-1.0,611.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\\n3,90.0,1.0,1.0,56.0,-1.0,-1.0,1345.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0\\n\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"text/csv; charset=utf-8\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"570df349-1ceb-43af-832d-592bd9332feb\",\n",
      "    \"inferenceTime\": \"2022-08-25T06:20:08Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Beautification of the json using json library\n",
    "import json\n",
    "print(json.dumps(json.loads(capture_file.split('\\n')[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # **Model Data Monitor : Baselining and continuous monitoring:** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Constraint suggestion with baseline/training dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to collecting the data, Amazon SageMaker provides the capability for you to monitor and evaluate the data observed by the endpoints. For this:\n",
    "1. Create a baseline with which you compare the realtime traffic. \n",
    "1. Once a baseline is ready, setup a schedule to continously evaluate and compare against the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset with which you trained the model is usually a good baseline dataset. Note that the training dataset data schema and the inference dataset schema should exactly match (i.e. the number and order of the features).\n",
    "\n",
    "From the training dataset you can ask Amazon SageMaker to suggest a set of baseline `constraints` and generate descriptive `statistics` to explore the data. For this example, upload the training dataset that was used to train the pre-trained model included in this example. If you already have it in Amazon S3, you can directly point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://accidentbucket/model_monitor/baselining/data\n",
      "Baseline results uri: s3://accidentbucket/model_monitor/baselining/results\n"
     ]
    }
   ],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "baseline_prefix = 'model_monitor/baselining'\n",
    "baseline_data_prefix = baseline_prefix + '/data'\n",
    "baseline_results_prefix = baseline_prefix + '/results'\n",
    "\n",
    "baseline_data_uri = 's3://{}/{}'.format(bucket,baseline_data_prefix)\n",
    "baseline_results_uri = 's3://{}/{}'.format(bucket, baseline_results_prefix)\n",
    "print('Baseline data uri: {}'.format(baseline_data_uri))\n",
    "print('Baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading the train data to s3 bucket\n",
    "import os\n",
    "\n",
    "train_data.drop('target_encoded',axis=1).to_csv(\"train_data_with_header.csv\")\n",
    "\n",
    "training_data_file = open(\"train_data_with_header.csv\", 'rb')\n",
    "s3_key = os.path.join(baseline_prefix, 'data', 'training-dataset-with-header.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_key).upload_fileobj(training_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a baselining job with training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the training data ready in Amazon S3, start a job to `suggest` constraints. `DefaultModelMonitor.suggest_baseline(..)` starts a `ProcessingJob` using an Amazon SageMaker provided Model Monitor container to generate the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2022-08-20-11-52-18-726\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://accidentbucket/model_monitor/baselining/data/training-dataset-with-header.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://accidentbucket/model_monitor/baselining/results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".........................\u001b[34m2022-08-20 11:56:19,048 - matplotlib.font_manager - INFO - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:19.585712: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:19.585739: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:21.222967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:21.222998: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:21.223019: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-243-53.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:21.223289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,788 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:143176219551:processing-job/baseline-suggestion-job-2022-08-20-11-52-18-726', 'ProcessingJobName': 'baseline-suggestion-job-2022-08-20-11-52-18-726', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://accidentbucket/model_monitor/baselining/data/training-dataset-with-header.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://accidentbucket/model_monitor/baselining/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 5, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::143176219551:role/service-role/AmazonSageMaker-ExecutionRole-20211115T211961', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,789 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,789 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,789 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,789 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,847 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,847 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,848 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,857 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,857 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:22,857 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,330 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.243.53\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoo\u001b[0m\n",
      "\u001b[34mp-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,340 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,345 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-bf885491-6dfc-4d16-bbbc-15a7fe202449\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,825 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,840 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,841 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,844 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,849 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,849 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,849 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,850 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,888 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,906 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,906 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,911 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,912 INFO blockmanagement.BlockManager: The block deletion will start around 2022 Aug 20 11:56:23\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,913 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,913 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,915 INFO util.GSet: 2.0% max memory 3.1 GB = 63.5 MB\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,915 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,954 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,958 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,987 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,987 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,988 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,988 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,990 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,990 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,990 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,990 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:23,996 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,001 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,001 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,001 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,001 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,047 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,047 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,047 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,050 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,050 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,052 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,052 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,052 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 976.0 KB\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,052 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,077 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1590653882-10.0.243.53-1660996584068\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,092 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,100 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,187 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,200 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,203 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.243.53\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:24,216 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:26,279 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:26,279 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:28,349 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:28,349 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:30,430 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:30,430 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:32,562 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:32,563 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:34,674 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:34,675 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:44,683 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:45 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:45 INFO  Main:28 - Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:45 INFO  Main:31 - Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:45 INFO  FileUtil:66 - Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SparkContext:54 - Running Spark version 2.3.1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SparkContext:54 - Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43203.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SparkEnv:54 - Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SparkEnv:54 - Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-a5855a61-19e1-44bc-8df2-0737394445af\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  MemoryStore:54 - MemoryStore started with capacity 1458.6 MB\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:46 INFO  SparkContext:54 - Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.243.53:43203/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1660996606728\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  RMProxy:133 - Connecting to ResourceManager at /10.0.243.53:8032\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Client:54 - Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Configuration:2636 - resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  ResourceUtils:427 - Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (15743 MB per container)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Client:54 - Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Client:54 - Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:47 INFO  Client:54 - Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:49 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:50 INFO  Client:54 - Uploading resource file:/tmp/spark-22d1a424-5423-4821-bbd7-d810af8a3dea/__spark_libs__1572764216739970666.zip -> hdfs://10.0.243.53/user/root/.sparkStaging/application_1660996589959_0001/__spark_libs__1572764216739970666.zip\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  Client:54 - Uploading resource file:/tmp/spark-22d1a424-5423-4821-bbd7-d810af8a3dea/__spark_conf__522356741186112880.zip -> hdfs://10.0.243.53/user/root/.sparkStaging/application_1660996589959_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:51 INFO  Client:54 - Submitting application application_1660996589959_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:52 INFO  YarnClientImpl:310 - Submitted application application_1660996589959_0001\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:52 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1660996589959_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:53 INFO  Client:54 - Application report for application_1660996589959_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:53 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Sat Aug 20 11:56:52 +0000 2022] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1660996612089\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1660996589959_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:54 INFO  Client:54 - Application report for application_1660996589959_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:55 INFO  Client:54 - Application report for application_1660996589959_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:56 INFO  Client:54 - Application report for application_1660996589959_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:57 INFO  Client:54 - Application report for application_1660996589959_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:57 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1660996589959_0001), /proxy/application_1660996589959_0001\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:57 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  Client:54 - Application report for application_1660996589959_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.243.53\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1660996612089\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1660996589959_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  YarnClientSchedulerBackend:54 - Application application_1660996589959_0001 has started running.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37225.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  NettyBlockTransferService:54 - Server created on 10.0.243.53:37225\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.243.53, 37225, None)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.243.53:37225 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.243.53, 37225, None)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.243.53, 37225, None)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.0.243.53, 37225, None)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:56:58 INFO  log:192 - Logging initialized @13507ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:00 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.243.53:33774) with ID 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:00 INFO  BlockManagerMasterEndpoint:54 - Registering block manager algo-1:42111 with 5.8 GB RAM, BlockManagerId(1, algo-1, 42111, None)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:16 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:16 WARN  SparkContext:66 - Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:16 INFO  DatasetReader:132 - Files to process:List(file:///opt/ml/processing/input/baseline_dataset_input/training-dataset-with-header.csv)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:16 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.3.1/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:16 INFO  SharedState:54 - Warehouse path is 'file:/usr/spark-2.3.1/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:17 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  CodeGenerator:54 - Code generated in 182.184965 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  CodeGenerator:54 - Code generated in 22.18996 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 429.7 KB, free 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.243.53:37225 (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  SparkContext:54 - Created broadcast 0 from csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  SparkContext:54 - Starting job: csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  DAGScheduler:54 - Got job 0 (csv at DatasetReader.scala:83) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at DatasetReader.scala:83)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:83), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.243.53:37225 (size: 4.5 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:83) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:18 INFO  YarnScheduler:54 - Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:19 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on algo-1:42111 (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on algo-1:42111 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1770 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  DAGScheduler:54 - ResultStage 0 (csv at DatasetReader.scala:83) finished in 1.851 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  DAGScheduler:54 - Job 0 finished: csv at DatasetReader.scala:83, took 1.893062 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  CodeGenerator:54 - Code generated in 9.222942 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 429.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.243.53:37225 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  SparkContext:54 - Created broadcast 2 from csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceStrategy:54 - Output Data Schema: struct<_c0: string, age_years: string, insurance_grp: string, no_fam_member: string, total_visit_count: string ... 35 more fields>\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:20 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 429.7 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.243.53:37225 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  SparkContext:54 - Created broadcast 3 from cache at DataAnalyzer.scala:78\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  CodeGenerator:54 - Code generated in 64.028419 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  CodeGenerator:54 - Code generated in 45.334816 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  SparkContext:54 - Starting job: head at DataAnalyzer.scala:81\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  DAGScheduler:54 - Got job 1 (head at DataAnalyzer.scala:81) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (head at DataAnalyzer.scala:81)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 54.1 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.0 KB, free 1457.1 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.243.53:37225 (size: 19.0 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  YarnScheduler:54 - Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on algo-1:42111 (size: 19.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:21 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on algo-1:42111 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Added rdd_11_0 in memory on algo-1:42111 (size: 1861.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 1353 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  DAGScheduler:54 - ResultStage 1 (head at DataAnalyzer.scala:81) finished in 1.410 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  DAGScheduler:54 - Job 1 finished: head at DataAnalyzer.scala:81, took 1.415241 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  DataAnalyzer:89 - The number of columns in the dataframe is 37\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  DataAnalyzer:116 - Number of shards is: 8\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  YarnScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 18\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 63\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 20\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 62\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 69\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 54\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on 10.0.243.53:37225 in memory (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on algo-1:42111 in memory (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 60\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 25\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 10.0.243.53:37225 in memory (size: 19.0 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on algo-1:42111 in memory (size: 19.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 9\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 21\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 34\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 45\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 61\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 47\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 10\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 10.0.243.53:37225 in memory (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 53\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 13\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 51\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 12\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 52\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 0\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 8\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 48\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 58\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 30\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 26\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 14\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 29\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 22\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 64\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 19\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 35\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 66\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 59\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 27\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 49\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 42\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 24\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 32\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 28\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 17\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 31\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 23\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 56\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 50\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 33\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 65\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 7\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 46\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 55\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 16\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 68\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on algo-1:42111 in memory (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 10.0.243.53:37225 in memory (size: 4.5 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 57\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 44\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 11\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 43\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 15\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:22 INFO  ContextCleaner:54 - Cleaned accumulator 67\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  CodeGenerator:54 - Code generated in 15.888938 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Registering RDD 22 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Got job 2 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 88.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.243.53:37225 (size: 30.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  YarnScheduler:54 - Adding task set 2.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 3, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on algo-1:42111 (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:23 INFO  BlockManagerInfo:54 - Added rdd_11_1 in memory on algo-1:42111 (size: 438.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 3) in 1570 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 1639 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  YarnScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - ShuffleMapStage 2 (collect at AnalysisRunner.scala:313) finished in 1.661 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 100.9 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 35.5 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.243.53:37225 (size: 35.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  YarnScheduler:54 - Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 4, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:24 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on algo-1:42111 (size: 35.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 4) in 264 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  YarnScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - ResultStage 3 (collect at AnalysisRunner.scala:313) finished in 0.278 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Job 2 finished: collect at AnalysisRunner.scala:313, took 1.960416 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  CodeGenerator:54 - Code generated in 18.033924 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Got job 3 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 48.5 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.4 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.243.53:37225 (size: 19.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  YarnScheduler:54 - Adding task set 4.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 5, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 6, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on algo-1:42111 (size: 19.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:25 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 6) in 472 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 5) in 850 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  YarnScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - ResultStage 4 (treeReduce at KLLRunner.scala:107) finished in 0.861 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Job 3 finished: treeReduce at KLLRunner.scala:107, took 0.945961 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  CodeGenerator:54 - Code generated in 52.370722 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  CodeGenerator:54 - Code generated in 87.185944 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  CodeGenerator:54 - Code generated in 61.974517 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 86\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 113\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 114\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 125\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 82\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 143\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 118\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 74\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 129\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 108\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 136\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 126\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 161\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 150\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 157\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 103\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 109\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 115\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 99\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 154\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 156\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 147\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 151\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 120\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 92\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 122\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 127\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 83\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned shuffle 0\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 97\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 111\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 87\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Registering RDD 39 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 160\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 117\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 149\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 116\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Got job 4 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 152\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 87.5 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 148\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 144\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 10.0.243.53:37225 in memory (size: 30.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on algo-1:42111 in memory (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 30.4 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.243.53:37225 (size: 30.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 138\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 130\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  YarnScheduler:54 - Adding task set 5.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 10.0.243.53:37225 in memory (size: 35.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 7, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  TaskSetManager:54 - Starting task 1.0 in stage 5.0 (TID 8, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on algo-1:42111 in memory (size: 35.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 131\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 88\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 140\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 78\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 70\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 10.0.243.53:37225 in memory (size: 19.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on algo-1:42111 in memory (size: 19.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on algo-1:42111 (size: 30.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 77\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 128\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 159\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 79\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 100\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 155\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 119\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 112\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 98\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 73\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 96\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 102\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 75\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 132\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 110\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 94\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 139\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 137\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 76\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 158\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 72\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 101\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 124\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 141\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 81\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 123\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 90\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 142\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 91\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 153\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 105\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 84\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 146\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 93\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 80\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 85\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 106\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 104\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 71\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 89\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 95\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 145\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:26 INFO  ContextCleaner:54 - Cleaned accumulator 121\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  TaskSetManager:54 - Finished task 1.0 in stage 5.0 (TID 8) in 229 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 7) in 278 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  YarnScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - ShuffleMapStage 5 (collect at AnalysisRunner.scala:313) finished in 0.293 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - waiting: Set(ResultStage 6)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 54.3 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 16.6 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.243.53:37225 (size: 16.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  YarnScheduler:54 - Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 9, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on algo-1:42111 (size: 16.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 9) in 99 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  YarnScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - ResultStage 6 (collect at AnalysisRunner.scala:313) finished in 0.115 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Job 4 finished: collect at AnalysisRunner.scala:313, took 0.417187 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Registering RDD 49 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Got job 5 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 43.1 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  YarnScheduler:54 - Adding task set 7.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 10, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  TaskSetManager:54 - Starting task 1.0 in stage 7.0 (TID 11, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:27 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 7.0 (TID 11) in 1120 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 10) in 1262 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  YarnScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - ShuffleMapStage 7 (countByKey at ColumnProfiler.scala:566) finished in 1.278 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - waiting: Set(ResultStage 8)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - Submitting ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1921.0 B, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 10.0.243.53:37225 (size: 1921.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  YarnScheduler:54 - Adding task set 8.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 12, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  TaskSetManager:54 - Starting task 1.0 in stage 8.0 (TID 13, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on algo-1:42111 (size: 1921.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 12) in 67 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  TaskSetManager:54 - Finished task 1.0 in stage 8.0 (TID 13) in 78 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  YarnScheduler:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - ResultStage 8 (countByKey at ColumnProfiler.scala:566) finished in 0.090 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:28 INFO  DAGScheduler:54 - Job 5 finished: countByKey at ColumnProfiler.scala:566, took 1.380674 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Registering RDD 55 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Got job 6 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[55] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 88.4 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on 10.0.243.53:37225 (size: 30.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  SparkContext:54 - Created broadcast 12 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[55] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  YarnScheduler:54 - Adding task set 9.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 14, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 9.0 (TID 15, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on algo-1:42111 (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Finished task 1.0 in stage 9.0 (TID 15) in 358 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 14) in 605 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  YarnScheduler:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - ShuffleMapStage 9 (collect at AnalysisRunner.scala:313) finished in 0.617 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Submitting ResultStage 10 (MapPartitionsRDD[58] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 100.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 35.3 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on 10.0.243.53:37225 (size: 35.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  YarnScheduler:54 - Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 16, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on algo-1:42111 (size: 35.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 3 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 16) in 96 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  YarnScheduler:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - ResultStage 10 (collect at AnalysisRunner.scala:313) finished in 0.108 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Job 6 finished: collect at AnalysisRunner.scala:313, took 0.731392 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  CodeGenerator:54 - Code generated in 12.793467 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Got job 7 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[67] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 48.3 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.3 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on 10.0.243.53:37225 (size: 19.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[67] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  YarnScheduler:54 - Adding task set 11.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 17, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  TaskSetManager:54 - Starting task 1.0 in stage 11.0 (TID 18, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:29 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on algo-1:42111 (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:30 INFO  TaskSetManager:54 - Finished task 1.0 in stage 11.0 (TID 18) in 266 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 17) in 775 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:30 INFO  YarnScheduler:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:30 INFO  DAGScheduler:54 - ResultStage 11 (treeReduce at KLLRunner.scala:107) finished in 0.785 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:30 INFO  DAGScheduler:54 - Job 7 finished: treeReduce at KLLRunner.scala:107, took 0.854133 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:30 INFO  CodeGenerator:54 - Code generated in 51.768785 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  CodeGenerator:54 - Code generated in 39.255958 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Registering RDD 72 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Got job 8 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 86.5 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on 10.0.243.53:37225 (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  SparkContext:54 - Created broadcast 15 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Adding task set 12.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 19, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 1.0 in stage 12.0 (TID 20, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on algo-1:42111 (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 1.0 in stage 12.0 (TID 20) in 170 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 19) in 227 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - ShuffleMapStage 12 (collect at AnalysisRunner.scala:313) finished in 0.238 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - waiting: Set(ResultStage 13)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[75] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 53.8 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on 10.0.243.53:37225 (size: 16.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[75] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Adding task set 13.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 21, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on algo-1:42111 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 4 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 21) in 69 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - ResultStage 13 (collect at AnalysisRunner.scala:313) finished in 0.078 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Job 8 finished: collect at AnalysisRunner.scala:313, took 0.322682 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Registering RDD 82 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Got job 9 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Final stage: ResultStage 15 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[82] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 43.1 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[82] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Adding task set 14.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 14.0 (TID 22, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 1.0 in stage 14.0 (TID 23, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 1.0 in stage 14.0 (TID 23) in 143 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 14.0 (TID 22) in 277 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - ShuffleMapStage 14 (countByKey at ColumnProfiler.scala:566) finished in 0.298 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - waiting: Set(ResultStage 15)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting ResultStage 15 (ShuffledRDD[83] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 3.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 1923.0 B, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on 10.0.243.53:37225 (size: 1923.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  SparkContext:54 - Created broadcast 18 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[83] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Adding task set 15.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 15.0 (TID 24, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Starting task 1.0 in stage 15.0 (TID 25, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on algo-1:42111 (size: 1923.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 5 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 1.0 in stage 15.0 (TID 25) in 36 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 15.0 (TID 24) in 58 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  YarnScheduler:54 - Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - ResultStage 15 (countByKey at ColumnProfiler.scala:566) finished in 0.078 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:31 INFO  DAGScheduler:54 - Job 9 finished: countByKey at ColumnProfiler.scala:566, took 0.382911 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Registering RDD 88 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Got job 10 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Final stage: ResultStage 17 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[88] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 88.4 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 273\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 174\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 191\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 420\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 213\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 413\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 257\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 178\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 225\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 268\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 236\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 336\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 169\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 233\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 375\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 358\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 246\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 376\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 231\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 240\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 457\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 425\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on 10.0.243.53:37225 in memory (size: 35.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on 10.0.243.53:37225 (size: 30.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[88] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  YarnScheduler:54 - Adding task set 16.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on algo-1:42111 in memory (size: 35.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 16.0 (TID 26, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Starting task 1.0 in stage 16.0 (TID 27, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 436\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 337\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 465\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 301\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned shuffle 5\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 278\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 315\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 344\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on 10.0.243.53:37225 in memory (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on algo-1:42111 in memory (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 311\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on algo-1:42111 (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 243\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 281\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 229\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 400\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 217\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 260\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 444\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 355\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 422\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 283\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 427\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 441\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 10.0.243.53:37225 in memory (size: 1921.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on algo-1:42111 in memory (size: 1921.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 388\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 328\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 409\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 298\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 175\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 486\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 346\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 446\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 334\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 245\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 237\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 448\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 310\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 430\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 251\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 267\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 398\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 390\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 204\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 10.0.243.53:37225 in memory (size: 16.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on algo-1:42111 in memory (size: 16.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 357\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 179\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 341\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 396\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 307\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 279\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 254\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned shuffle 3\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 230\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 468\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 227\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 445\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 133\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 181\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 210\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 176\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 185\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 192\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 474\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 415\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 332\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 455\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 212\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 450\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 190\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 259\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 166\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 481\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 276\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 410\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 466\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 421\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 202\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 235\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 223\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 318\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 411\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 309\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 408\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 387\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 224\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 372\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 451\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 201\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 197\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 198\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 424\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 300\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 271\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 297\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 472\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 401\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 303\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 469\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 211\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 432\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 289\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 477\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 373\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 320\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 199\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 359\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 253\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 389\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 184\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 367\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 443\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 418\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 239\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 290\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 471\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on 10.0.243.53:37225 in memory (size: 1923.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on algo-1:42111 in memory (size: 1923.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 393\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 460\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 379\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 442\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 319\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 484\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 475\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 272\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 220\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 347\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 164\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 214\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 483\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 434\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 369\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 287\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 162\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 317\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 196\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 305\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 302\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 249\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 183\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 171\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 312\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 345\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 232\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 186\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 275\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 479\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 282\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 323\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 329\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 353\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 296\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 377\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 380\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 322\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 342\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 416\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 288\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 382\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 304\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 244\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 209\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 261\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 343\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 419\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on 10.0.243.53:37225 in memory (size: 19.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on algo-1:42111 in memory (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 456\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 205\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 252\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 391\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 333\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 381\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 264\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 324\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 207\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 402\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 206\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 203\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 285\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 394\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 291\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 426\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 459\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 370\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 487\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 395\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 269\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 403\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 316\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 368\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 423\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 238\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 340\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 366\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 356\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 241\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 193\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 321\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 360\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 242\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 263\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 247\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 406\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 258\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 435\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 338\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 374\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 476\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 363\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 188\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 412\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 449\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 364\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 234\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 165\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 195\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 384\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 248\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 172\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 339\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 414\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned shuffle 1\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 168\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 458\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 371\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 361\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on 10.0.243.53:37225 in memory (size: 30.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on algo-1:42111 in memory (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 216\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 299\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 385\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 407\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 163\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 286\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 189\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 292\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 428\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 452\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 480\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 447\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 397\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 218\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 308\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on 10.0.243.53:37225 in memory (size: 16.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on algo-1:42111 in memory (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 167\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 173\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 295\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 463\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 314\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 440\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 473\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 464\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned shuffle 4\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 331\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 354\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 326\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 461\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 335\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 453\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 351\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 200\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 348\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 404\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 437\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 433\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 485\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 392\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 215\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 470\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned shuffle 2\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 280\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 330\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 250\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 399\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 266\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 327\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 362\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 187\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 349\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 439\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 482\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 306\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 10.0.243.53:37225 in memory (size: 30.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on algo-1:42111 in memory (size: 30.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 462\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 170\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 386\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 325\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 208\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 352\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 221\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 478\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 438\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 383\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 222\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 350\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 431\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 182\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 262\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 135\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 134\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 255\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 365\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 294\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 277\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 194\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 265\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 228\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 284\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 454\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 378\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 177\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 467\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 219\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 293\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 180\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 405\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 429\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 226\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 256\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 417\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 274\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  ContextCleaner:54 - Cleaned accumulator 270\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Finished task 1.0 in stage 16.0 (TID 27) in 280 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 16.0 (TID 26) in 393 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  YarnScheduler:54 - Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - ShuffleMapStage 16 (collect at AnalysisRunner.scala:313) finished in 0.447 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 17)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Submitting ResultStage 17 (MapPartitionsRDD[91] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 100.6 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 35.3 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on 10.0.243.53:37225 (size: 35.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  SparkContext:54 - Created broadcast 20 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[91] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  YarnScheduler:54 - Adding task set 17.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 17.0 (TID 28, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on algo-1:42111 (size: 35.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 6 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 17.0 (TID 28) in 113 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  YarnScheduler:54 - Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - ResultStage 17 (collect at AnalysisRunner.scala:313) finished in 0.125 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Job 10 finished: collect at AnalysisRunner.scala:313, took 0.579734 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  CodeGenerator:54 - Code generated in 8.129889 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Got job 11 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Final stage: ResultStage 18 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Submitting ResultStage 18 (MapPartitionsRDD[100] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 48.3 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 19.3 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on 10.0.243.53:37225 (size: 19.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  SparkContext:54 - Created broadcast 21 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[100] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  YarnScheduler:54 - Adding task set 18.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 18.0 (TID 29, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Starting task 1.0 in stage 18.0 (TID 30, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on algo-1:42111 (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:32 INFO  TaskSetManager:54 - Finished task 1.0 in stage 18.0 (TID 30) in 201 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 18.0 (TID 29) in 569 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - ResultStage 18 (treeReduce at KLLRunner.scala:107) finished in 0.578 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Job 11 finished: treeReduce at KLLRunner.scala:107, took 0.616410 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  CodeGenerator:54 - Code generated in 35.114068 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Registering RDD 105 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Got job 12 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Final stage: ResultStage 20 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[105] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 86.5 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on 10.0.243.53:37225 (size: 29.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  SparkContext:54 - Created broadcast 22 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[105] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Adding task set 19.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 19.0 (TID 31, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 1.0 in stage 19.0 (TID 32, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on algo-1:42111 (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 1.0 in stage 19.0 (TID 32) in 111 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 19.0 (TID 31) in 174 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - ShuffleMapStage 19 (collect at AnalysisRunner.scala:313) finished in 0.186 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - waiting: Set(ResultStage 20)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting ResultStage 20 (MapPartitionsRDD[108] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 53.8 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on 10.0.243.53:37225 (size: 16.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[108] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Adding task set 20.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 20.0 (TID 33, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on algo-1:42111 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 7 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 20.0 (TID 33) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - ResultStage 20 (collect at AnalysisRunner.scala:313) finished in 0.033 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Job 12 finished: collect at AnalysisRunner.scala:313, took 0.223638 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Registering RDD 115 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Got job 13 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Final stage: ResultStage 22 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 21 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 43.1 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  SparkContext:54 - Created broadcast 24 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Adding task set 21.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 21.0 (TID 34, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 1.0 in stage 21.0 (TID 35, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 1.0 in stage 21.0 (TID 35) in 62 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 21.0 (TID 34) in 91 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Removed TaskSet 21.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - ShuffleMapStage 21 (countByKey at ColumnProfiler.scala:566) finished in 0.112 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - waiting: Set(ResultStage 22)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting ResultStage 22 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 3.2 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1925.0 B, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on 10.0.243.53:37225 (size: 1925.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  SparkContext:54 - Created broadcast 25 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 22 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Adding task set 22.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 22.0 (TID 36, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Starting task 1.0 in stage 22.0 (TID 37, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on algo-1:42111 (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 8 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 1.0 in stage 22.0 (TID 37) in 28 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 22.0 (TID 36) in 36 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  YarnScheduler:54 - Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - ResultStage 22 (countByKey at ColumnProfiler.scala:566) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:33 INFO  DAGScheduler:54 - Job 13 finished: countByKey at ColumnProfiler.scala:566, took 0.162040 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Registering RDD 121 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Got job 14 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Final stage: ResultStage 24 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 23 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 88.4 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on 10.0.243.53:37225 (size: 30.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  SparkContext:54 - Created broadcast 26 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  YarnScheduler:54 - Adding task set 23.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 23.0 (TID 38, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Starting task 1.0 in stage 23.0 (TID 39, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on algo-1:42111 (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Finished task 1.0 in stage 23.0 (TID 39) in 194 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Finished task 0.0 in stage 23.0 (TID 38) in 272 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  YarnScheduler:54 - Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - ShuffleMapStage 23 (collect at AnalysisRunner.scala:313) finished in 0.289 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - waiting: Set(ResultStage 24)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Submitting ResultStage 24 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 101.2 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 35.4 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on 10.0.243.53:37225 (size: 35.4 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  SparkContext:54 - Created broadcast 27 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  YarnScheduler:54 - Adding task set 24.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 24.0 (TID 40, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on algo-1:42111 (size: 35.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 9 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Finished task 0.0 in stage 24.0 (TID 40) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  YarnScheduler:54 - Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - ResultStage 24 (collect at AnalysisRunner.scala:313) finished in 0.139 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Job 14 finished: collect at AnalysisRunner.scala:313, took 0.437678 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  CodeGenerator:54 - Code generated in 11.249186 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Got job 15 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Final stage: ResultStage 25 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Submitting ResultStage 25 (MapPartitionsRDD[133] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 48.3 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 19.3 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on 10.0.243.53:37225 (size: 19.3 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  SparkContext:54 - Created broadcast 28 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 25 (MapPartitionsRDD[133] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  YarnScheduler:54 - Adding task set 25.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 25.0 (TID 41, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Starting task 1.0 in stage 25.0 (TID 42, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on algo-1:42111 (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:34 INFO  TaskSetManager:54 - Finished task 1.0 in stage 25.0 (TID 42) in 187 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 25.0 (TID 41) in 568 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Removed TaskSet 25.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - ResultStage 25 (treeReduce at KLLRunner.scala:107) finished in 0.578 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 753\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 670\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 565\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 740\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 728\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 659\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 692\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 745\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 622\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 741\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Job 15 finished: treeReduce at KLLRunner.scala:107, took 0.632563 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 743\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 739\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on 10.0.243.53:37225 in memory (size: 16.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on algo-1:42111 in memory (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 525\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 588\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 626\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 713\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 556\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 754\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 648\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 671\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 708\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 704\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 744\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 560\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned shuffle 9\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 507\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 537\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 575\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 516\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 634\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 679\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on 10.0.243.53:37225 in memory (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on algo-1:42111 in memory (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 758\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 573\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 540\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned shuffle 8\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 710\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 585\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 690\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 552\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 590\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 701\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 734\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 702\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 545\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 582\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 602\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 538\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 750\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 539\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 657\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 603\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 600\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 619\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 612\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 675\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 638\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 571\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 686\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 689\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 606\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 712\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 662\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 630\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 614\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 676\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 514\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 586\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 491\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 691\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 661\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 513\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 651\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 524\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 725\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 687\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 635\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 527\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 726\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 755\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 558\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 629\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 644\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 658\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 557\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 647\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 497\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 581\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 578\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned shuffle 7\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 515\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 526\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 724\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 681\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 735\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 607\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 509\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 608\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 673\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 512\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 698\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 641\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 697\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 674\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 534\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 730\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 510\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on 10.0.243.53:37225 in memory (size: 30.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on algo-1:42111 in memory (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 685\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 694\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 628\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 576\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 489\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 563\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 549\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 736\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 577\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 716\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 623\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 505\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 727\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 611\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 536\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 665\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 550\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 703\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 570\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 719\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 748\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 620\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 664\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 618\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 723\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 546\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 490\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 656\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 621\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 667\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 553\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 640\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 520\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 625\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 669\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 756\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 650\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 721\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 637\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 523\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 604\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 699\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 564\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 592\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 749\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 645\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 738\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 530\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned shuffle 6\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 631\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 572\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 649\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 584\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 617\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 693\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 555\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 695\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on 10.0.243.53:37225 in memory (size: 19.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on algo-1:42111 in memory (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 559\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 672\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 495\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 720\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 501\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 598\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 639\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 653\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 660\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on 10.0.243.53:37225 in memory (size: 35.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on algo-1:42111 in memory (size: 35.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 715\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 595\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 521\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 589\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 609\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 508\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 709\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 580\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 627\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 502\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 511\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 616\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 751\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 705\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 531\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 596\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 680\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 554\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 632\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 733\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 615\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 547\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 746\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 742\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 542\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 506\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 610\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 646\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 569\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 707\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 636\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 597\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 747\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 682\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 677\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 599\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 668\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 601\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 737\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 519\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 663\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 700\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 496\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 655\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 717\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 493\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 500\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 757\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 678\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 624\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 517\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 532\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 722\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 759\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 518\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 688\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 492\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 503\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 683\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 729\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 594\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 684\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 587\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 494\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 652\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 696\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 706\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 711\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 551\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 528\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 752\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 731\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 561\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 504\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 499\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on 10.0.243.53:37225 in memory (size: 30.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on algo-1:42111 in memory (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 488\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 522\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 535\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 574\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 613\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 544\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on 10.0.243.53:37225 in memory (size: 35.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on algo-1:42111 in memory (size: 35.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 633\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 654\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 529\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 593\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 732\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 567\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 498\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 642\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 541\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 548\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 568\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 714\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 718\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 643\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 583\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 543\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 579\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 666\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 533\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 605\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 562\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  ContextCleaner:54 - Cleaned accumulator 591\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on 10.0.243.53:37225 in memory (size: 1925.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on algo-1:42111 in memory (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  CodeGenerator:54 - Code generated in 32.718884 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Registering RDD 138 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Got job 16 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Final stage: ResultStage 27 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 26)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 26)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 26 (MapPartitionsRDD[138] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 86.5 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on 10.0.243.53:37225 (size: 29.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  SparkContext:54 - Created broadcast 29 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[138] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Adding task set 26.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 26.0 (TID 43, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 1.0 in stage 26.0 (TID 44, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on algo-1:42111 (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Finished task 1.0 in stage 26.0 (TID 44) in 145 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 26.0 (TID 43) in 212 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - ShuffleMapStage 26 (collect at AnalysisRunner.scala:313) finished in 0.222 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - waiting: Set(ResultStage 27)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting ResultStage 27 (MapPartitionsRDD[141] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 53.8 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on 10.0.243.53:37225 (size: 16.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  SparkContext:54 - Created broadcast 30 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[141] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Adding task set 27.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 27.0 (TID 45, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on algo-1:42111 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 10 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 27.0 (TID 45) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - ResultStage 27 (collect at AnalysisRunner.scala:313) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Job 16 finished: collect at AnalysisRunner.scala:313, took 0.271850 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Registering RDD 148 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Got job 17 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Final stage: ResultStage 29 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 28)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 28)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 28 (MapPartitionsRDD[148] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 43.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  SparkContext:54 - Created broadcast 31 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[148] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Adding task set 28.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 28.0 (TID 46, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 1.0 in stage 28.0 (TID 47, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Finished task 1.0 in stage 28.0 (TID 47) in 40 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 28.0 (TID 46) in 73 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - ShuffleMapStage 28 (countByKey at ColumnProfiler.scala:566) finished in 0.082 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - waiting: Set(ResultStage 29)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting ResultStage 29 (ShuffledRDD[149] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 3.2 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 1925.0 B, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on 10.0.243.53:37225 (size: 1925.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  SparkContext:54 - Created broadcast 32 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[149] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  YarnScheduler:54 - Adding task set 29.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 29.0 (TID 48, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  TaskSetManager:54 - Starting task 1.0 in stage 29.0 (TID 49, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on algo-1:42111 (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:35 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 11 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Finished task 1.0 in stage 29.0 (TID 49) in 30 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 29.0 (TID 48) in 33 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  YarnScheduler:54 - Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - ResultStage 29 (countByKey at ColumnProfiler.scala:566) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Job 17 finished: countByKey at ColumnProfiler.scala:566, took 0.127527 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Registering RDD 154 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Got job 18 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Final stage: ResultStage 31 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 30 (MapPartitionsRDD[154] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 88.4 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on 10.0.243.53:37225 (size: 30.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  SparkContext:54 - Created broadcast 33 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[154] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  YarnScheduler:54 - Adding task set 30.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 30.0 (TID 50, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Starting task 1.0 in stage 30.0 (TID 51, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on algo-1:42111 (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Finished task 1.0 in stage 30.0 (TID 51) in 225 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 30.0 (TID 50) in 322 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  YarnScheduler:54 - Removed TaskSet 30.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - ShuffleMapStage 30 (collect at AnalysisRunner.scala:313) finished in 0.330 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - waiting: Set(ResultStage 31)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Submitting ResultStage 31 (MapPartitionsRDD[157] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 101.2 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 35.5 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on 10.0.243.53:37225 (size: 35.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  SparkContext:54 - Created broadcast 34 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[157] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  YarnScheduler:54 - Adding task set 31.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 31.0 (TID 52, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on algo-1:42111 (size: 35.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 12 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 31.0 (TID 52) in 102 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  YarnScheduler:54 - Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - ResultStage 31 (collect at AnalysisRunner.scala:313) finished in 0.111 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Job 18 finished: collect at AnalysisRunner.scala:313, took 0.446070 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  CodeGenerator:54 - Code generated in 7.902583 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Got job 19 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Submitting ResultStage 32 (MapPartitionsRDD[166] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 48.3 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 19.3 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on 10.0.243.53:37225 (size: 19.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  SparkContext:54 - Created broadcast 35 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[166] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  YarnScheduler:54 - Adding task set 32.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 32.0 (TID 53, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Starting task 1.0 in stage 32.0 (TID 54, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on algo-1:42111 (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:36 INFO  TaskSetManager:54 - Finished task 1.0 in stage 32.0 (TID 54) in 178 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 32.0 (TID 53) in 568 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.577 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Job 19 finished: treeReduce at KLLRunner.scala:107, took 0.609011 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  CodeGenerator:54 - Code generated in 31.971897 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Registering RDD 171 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Got job 20 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Final stage: ResultStage 34 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 33)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 33)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 33 (MapPartitionsRDD[171] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 86.5 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on 10.0.243.53:37225 (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Created broadcast 36 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[171] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Adding task set 33.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 33.0 (TID 55, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 33.0 (TID 56, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on algo-1:42111 (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 1.0 in stage 33.0 (TID 56) in 154 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 33.0 (TID 55) in 212 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - ShuffleMapStage 33 (collect at AnalysisRunner.scala:313) finished in 0.222 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 34)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting ResultStage 34 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 53.8 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on 10.0.243.53:37225 (size: 16.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Created broadcast 37 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Adding task set 34.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 34.0 (TID 57, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on algo-1:42111 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 13 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 34.0 (TID 57) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Removed TaskSet 34.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - ResultStage 34 (collect at AnalysisRunner.scala:313) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Job 20 finished: collect at AnalysisRunner.scala:313, took 0.253142 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Registering RDD 181 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Got job 21 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Final stage: ResultStage 36 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 35)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 35)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 35 (MapPartitionsRDD[181] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 43.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[181] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Adding task set 35.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 35.0 (TID 58, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 35.0 (TID 59, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 1.0 in stage 35.0 (TID 59) in 35 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 35.0 (TID 58) in 76 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - ShuffleMapStage 35 (countByKey at ColumnProfiler.scala:566) finished in 0.084 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 36)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting ResultStage 36 (ShuffledRDD[182] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 3.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 1926.0 B, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on 10.0.243.53:37225 (size: 1926.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 36 (ShuffledRDD[182] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Adding task set 36.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 36.0 (TID 60, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 36.0 (TID 61, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on algo-1:42111 (size: 1926.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 14 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 1.0 in stage 36.0 (TID 61) in 27 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 36.0 (TID 60) in 27 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - ResultStage 36 (countByKey at ColumnProfiler.scala:566) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Job 21 finished: countByKey at ColumnProfiler.scala:566, took 0.120796 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Registering RDD 187 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Got job 22 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Final stage: ResultStage 38 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 37)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 37)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 37 (MapPartitionsRDD[187] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_40 stored as values in memory (estimated size 88.4 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  MemoryStore:54 - Block broadcast_40_piece0 stored as bytes in memory (estimated size 30.5 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on 10.0.243.53:37225 (size: 30.5 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  SparkContext:54 - Created broadcast 40 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[187] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  YarnScheduler:54 - Adding task set 37.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 37.0 (TID 62, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:37 INFO  TaskSetManager:54 - Starting task 1.0 in stage 37.0 (TID 63, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on algo-1:42111 (size: 30.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Finished task 1.0 in stage 37.0 (TID 63) in 110 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 37.0 (TID 62) in 225 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  YarnScheduler:54 - Removed TaskSet 37.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - ShuffleMapStage 37 (collect at AnalysisRunner.scala:313) finished in 0.235 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - waiting: Set(ResultStage 38)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Submitting ResultStage 38 (MapPartitionsRDD[190] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  MemoryStore:54 - Block broadcast_41 stored as values in memory (estimated size 101.8 KB, free 1457.1 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  MemoryStore:54 - Block broadcast_41_piece0 stored as bytes in memory (estimated size 35.6 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on 10.0.243.53:37225 (size: 35.6 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  SparkContext:54 - Created broadcast 41 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[190] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  YarnScheduler:54 - Adding task set 38.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 38.0 (TID 64, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on algo-1:42111 (size: 35.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 15 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 38.0 (TID 64) in 81 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  YarnScheduler:54 - Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - ResultStage 38 (collect at AnalysisRunner.scala:313) finished in 0.091 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Job 22 finished: collect at AnalysisRunner.scala:313, took 0.328982 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  CodeGenerator:54 - Code generated in 9.537469 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Got job 23 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Final stage: ResultStage 39 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Submitting ResultStage 39 (MapPartitionsRDD[199] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  MemoryStore:54 - Block broadcast_42 stored as values in memory (estimated size 48.3 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  MemoryStore:54 - Block broadcast_42_piece0 stored as bytes in memory (estimated size 19.4 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on 10.0.243.53:37225 (size: 19.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  SparkContext:54 - Created broadcast 42 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[199] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  YarnScheduler:54 - Adding task set 39.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 39.0 (TID 65, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Starting task 1.0 in stage 39.0 (TID 66, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on algo-1:42111 (size: 19.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Finished task 1.0 in stage 39.0 (TID 66) in 117 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 39.0 (TID 65) in 428 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  YarnScheduler:54 - Removed TaskSet 39.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - ResultStage 39 (treeReduce at KLLRunner.scala:107) finished in 0.440 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1001\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1135\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned shuffle 13\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1033\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 778\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 884\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 897\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1011\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 991\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1096\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 968\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 888\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 826\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 931\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1076\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1100\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 840\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1090\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1092\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 960\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1052\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1034\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 781\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 999\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1009\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 893\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 776\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1043\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 760\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1072\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1113\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 944\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 923\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 868\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 993\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1018\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 858\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 867\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 976\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 875\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 981\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 874\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 768\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 797\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1141\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 770\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 801\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1132\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 780\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1028\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 851\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 895\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 771\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 795\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 856\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1174\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 900\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1083\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 783\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1102\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 799\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on 10.0.243.53:37225 in memory (size: 30.6 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on algo-1:42111 in memory (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 948\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 824\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 910\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 782\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 812\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 848\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 849\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1095\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 903\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1119\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 767\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1136\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 951\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 843\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 984\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1066\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1173\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 909\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 878\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on 10.0.243.53:37225 in memory (size: 1925.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on algo-1:42111 in memory (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 940\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1036\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 925\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 889\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1026\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 941\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1167\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 982\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1056\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1074\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 890\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 822\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 932\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1145\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 912\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 962\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 775\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 828\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 864\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 958\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on 10.0.243.53:37225 in memory (size: 19.3 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on algo-1:42111 in memory (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1120\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1131\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 979\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1005\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1030\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1061\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1067\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1176\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1093\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1041\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1158\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 809\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 899\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on 10.0.243.53:37225 in memory (size: 16.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on algo-1:42111 in memory (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 804\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 995\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned shuffle 15\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1169\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1094\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 883\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1015\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on 10.0.243.53:37225 in memory (size: 30.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on algo-1:42111 in memory (size: 30.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1147\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 926\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 943\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1055\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 977\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 927\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1105\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 820\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 859\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1103\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 793\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 906\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  DAGScheduler:54 - Job 23 finished: treeReduce at KLLRunner.scala:107, took 0.510692 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on 10.0.243.53:37225 in memory (size: 1926.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on algo-1:42111 in memory (size: 1926.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 839\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 972\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 946\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1125\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 763\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 954\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1129\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 911\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 803\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1023\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 790\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1079\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 833\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1088\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 870\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 825\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1110\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1127\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 916\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 947\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 914\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1014\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 817\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned shuffle 12\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1130\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 831\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 882\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1144\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 800\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 978\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1146\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1155\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 779\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 802\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1042\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1161\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 891\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 762\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 938\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 827\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1054\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1022\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 860\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 844\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 846\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 963\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 964\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 959\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1048\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1162\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1032\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1078\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 950\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1111\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 821\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1140\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned shuffle 14\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1137\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 992\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1159\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1117\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 813\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1077\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 787\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 834\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1085\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 785\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1049\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1128\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 863\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1149\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 818\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1087\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 998\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1059\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 805\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on 10.0.243.53:37225 in memory (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on algo-1:42111 in memory (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1099\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1050\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1007\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1044\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 877\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 929\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 880\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1086\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1153\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1003\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 854\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 808\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 769\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1124\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 866\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 996\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 798\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 980\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 969\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 907\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 983\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1073\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 942\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1142\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 871\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1060\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 862\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1065\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 928\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1012\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1160\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 830\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 885\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 918\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1031\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1108\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 784\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 971\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 956\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 879\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1139\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 915\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1075\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 842\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1175\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on 10.0.243.53:37225 in memory (size: 35.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on algo-1:42111 in memory (size: 35.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 857\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 791\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1156\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 850\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1143\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1114\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1104\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1138\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 967\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 764\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 806\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1062\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 772\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 908\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 957\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 838\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 761\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 997\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 986\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1118\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 811\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1020\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 765\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on 10.0.243.53:37225 in memory (size: 19.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on algo-1:42111 in memory (size: 19.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 829\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1177\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1051\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1123\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 777\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1168\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1046\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned shuffle 10\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 896\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 920\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1112\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1089\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 892\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 975\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1013\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1017\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 936\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1064\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 955\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1151\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1063\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 952\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 985\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 786\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 966\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 861\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1053\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 935\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 815\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 847\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1021\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 872\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1004\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1154\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 810\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1101\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 792\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 836\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 898\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 919\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1057\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 965\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 841\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 933\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 845\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1010\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1029\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on 10.0.243.53:37225 in memory (size: 35.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on algo-1:42111 in memory (size: 35.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1116\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1045\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1069\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1058\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1084\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 886\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1080\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 953\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1115\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 887\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 939\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 823\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 832\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1126\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1148\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 905\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1025\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 974\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1024\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1166\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned shuffle 11\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 855\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1016\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1163\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1019\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1071\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 913\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1037\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1000\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1171\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 807\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 973\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1027\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 794\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on 10.0.243.53:37225 in memory (size: 16.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on algo-1:42111 in memory (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 773\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1091\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1098\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 789\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 902\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1109\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1152\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 873\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on 10.0.243.53:37225 in memory (size: 29.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on algo-1:42111 in memory (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1122\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1070\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1002\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 945\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1133\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 924\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1068\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 904\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 881\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1121\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1170\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 917\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 937\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 852\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 970\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 901\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1134\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1097\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 796\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 837\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 816\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1081\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 869\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1082\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 988\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 766\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 987\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1008\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 788\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 835\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 994\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 814\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 934\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1035\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1172\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 922\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1164\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 894\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 921\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 961\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 930\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1157\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1038\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1165\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 865\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 990\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1150\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 949\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1006\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 989\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1106\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 853\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 876\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1040\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 1047\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:38 INFO  ContextCleaner:54 - Cleaned accumulator 819\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  CodeGenerator:54 - Code generated in 31.437716 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Registering RDD 204 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Got job 24 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Final stage: ResultStage 41 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 40)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 40)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 40 (MapPartitionsRDD[204] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_43 stored as values in memory (estimated size 86.5 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on 10.0.243.53:37225 (size: 29.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 43 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[204] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 40.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 40.0 (TID 67, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 40.0 (TID 68, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on algo-1:42111 (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 1.0 in stage 40.0 (TID 68) in 90 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 40.0 (TID 67) in 143 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - ShuffleMapStage 40 (collect at AnalysisRunner.scala:313) finished in 0.151 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 41)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ResultStage 41 (MapPartitionsRDD[207] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_44 stored as values in memory (estimated size 53.8 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on 10.0.243.53:37225 (size: 16.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 44 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[207] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 41.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 41.0 (TID 69, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on algo-1:42111 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 16 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 41.0 (TID 69) in 14 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - ResultStage 41 (collect at AnalysisRunner.scala:313) finished in 0.019 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Job 24 finished: collect at AnalysisRunner.scala:313, took 0.174191 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Registering RDD 214 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Got job 25 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Final stage: ResultStage 43 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 42)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 42)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 42 (MapPartitionsRDD[214] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_45 stored as values in memory (estimated size 43.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_45_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 45 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[214] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 42.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 42.0 (TID 70, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 42.0 (TID 71, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 1.0 in stage 42.0 (TID 71) in 31 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 42.0 (TID 70) in 66 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - ShuffleMapStage 42 (countByKey at ColumnProfiler.scala:566) finished in 0.075 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 43)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ResultStage 43 (ShuffledRDD[215] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_46 stored as values in memory (estimated size 3.2 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_46_piece0 stored as bytes in memory (estimated size 1925.0 B, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on 10.0.243.53:37225 (size: 1925.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 46 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 43 (ShuffledRDD[215] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 43.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 43.0 (TID 72, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 43.0 (TID 73, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on algo-1:42111 (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 17 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 43.0 (TID 72) in 19 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 1.0 in stage 43.0 (TID 73) in 19 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Removed TaskSet 43.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - ResultStage 43 (countByKey at ColumnProfiler.scala:566) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Job 25 finished: countByKey at ColumnProfiler.scala:566, took 0.102427 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Registering RDD 220 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Got job 26 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Final stage: ResultStage 45 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 44)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 44)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 44 (MapPartitionsRDD[220] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_47 stored as values in memory (estimated size 88.4 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_47_piece0 stored as bytes in memory (estimated size 30.6 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on 10.0.243.53:37225 (size: 30.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 47 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[220] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 44.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 44.0 (TID 74, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 44.0 (TID 75, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on algo-1:42111 (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 1.0 in stage 44.0 (TID 75) in 122 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 44.0 (TID 74) in 212 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - ShuffleMapStage 44 (collect at AnalysisRunner.scala:313) finished in 0.221 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 45)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ResultStage 45 (MapPartitionsRDD[223] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_48 stored as values in memory (estimated size 101.4 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_48_piece0 stored as bytes in memory (estimated size 35.5 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on 10.0.243.53:37225 (size: 35.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 48 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[223] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 45.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 45.0 (TID 76, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on algo-1:42111 (size: 35.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 18 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 45.0 (TID 76) in 66 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - ResultStage 45 (collect at AnalysisRunner.scala:313) finished in 0.074 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Job 26 finished: collect at AnalysisRunner.scala:313, took 0.298374 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  CodeGenerator:54 - Code generated in 7.167057 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Got job 27 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Final stage: ResultStage 46 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting ResultStage 46 (MapPartitionsRDD[232] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_49 stored as values in memory (estimated size 48.3 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  MemoryStore:54 - Block broadcast_49_piece0 stored as bytes in memory (estimated size 19.4 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on 10.0.243.53:37225 (size: 19.4 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  SparkContext:54 - Created broadcast 49 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[232] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  YarnScheduler:54 - Adding task set 46.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 46.0 (TID 77, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 46.0 (TID 78, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:39 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on algo-1:42111 (size: 19.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 1.0 in stage 46.0 (TID 78) in 145 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 46.0 (TID 77) in 471 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - ResultStage 46 (treeReduce at KLLRunner.scala:107) finished in 0.479 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Job 27 finished: treeReduce at KLLRunner.scala:107, took 0.507397 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  CodeGenerator:54 - Code generated in 28.346025 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Registering RDD 237 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Got job 28 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Final stage: ResultStage 48 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 47)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 47)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 47 (MapPartitionsRDD[237] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_50 stored as values in memory (estimated size 86.5 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_50_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on 10.0.243.53:37225 (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  SparkContext:54 - Created broadcast 50 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[237] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Adding task set 47.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 47.0 (TID 79, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 1.0 in stage 47.0 (TID 80, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on algo-1:42111 (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 1.0 in stage 47.0 (TID 80) in 155 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 47.0 (TID 79) in 198 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - ShuffleMapStage 47 (collect at AnalysisRunner.scala:313) finished in 0.204 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 48)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting ResultStage 48 (MapPartitionsRDD[240] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_51 stored as values in memory (estimated size 53.8 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_51_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on 10.0.243.53:37225 (size: 16.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  SparkContext:54 - Created broadcast 51 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[240] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Adding task set 48.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 48.0 (TID 81, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on algo-1:42111 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 19 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 48.0 (TID 81) in 12 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Removed TaskSet 48.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - ResultStage 48 (collect at AnalysisRunner.scala:313) finished in 0.017 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Job 28 finished: collect at AnalysisRunner.scala:313, took 0.224641 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Registering RDD 247 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Got job 29 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Final stage: ResultStage 50 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 49)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 49)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 49 (MapPartitionsRDD[247] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_52 stored as values in memory (estimated size 43.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_52_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on 10.0.243.53:37225 (size: 17.9 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  SparkContext:54 - Created broadcast 52 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[247] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Adding task set 49.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 49.0 (TID 82, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 1.0 in stage 49.0 (TID 83, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on algo-1:42111 (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 1.0 in stage 49.0 (TID 83) in 42 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 49.0 (TID 82) in 65 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - ShuffleMapStage 49 (countByKey at ColumnProfiler.scala:566) finished in 0.074 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 50)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting ResultStage 50 (ShuffledRDD[248] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_53 stored as values in memory (estimated size 3.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MemoryStore:54 - Block broadcast_53_piece0 stored as bytes in memory (estimated size 1925.0 B, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on 10.0.243.53:37225 (size: 1925.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  SparkContext:54 - Created broadcast 53 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 50 (ShuffledRDD[248] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Adding task set 50.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 50.0 (TID 84, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Starting task 1.0 in stage 50.0 (TID 85, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on algo-1:42111 (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 20 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 1.0 in stage 50.0 (TID 85) in 14 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 50.0 (TID 84) in 18 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  YarnScheduler:54 - Removed TaskSet 50.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - ResultStage 50 (countByKey at ColumnProfiler.scala:566) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  DAGScheduler:54 - Job 29 finished: countByKey at ColumnProfiler.scala:566, took 0.100617 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:40 INFO  CodeGenerator:54 - Code generated in 7.054503 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1233\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1227\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1407\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1287\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1179\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1366\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1522\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1315\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1320\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1248\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1255\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1230\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1211\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1253\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1499\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1201\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1473\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1338\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1326\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1445\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1505\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1435\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned shuffle 16\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1463\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1504\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1234\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1209\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1478\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1187\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1392\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1489\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1519\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1483\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1448\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1221\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1182\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1342\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1422\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1404\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1257\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1349\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1464\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1468\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1419\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1467\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1232\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1297\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1432\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1428\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1513\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1382\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1449\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1460\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1220\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1314\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1515\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1480\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1309\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1441\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1322\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1477\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1521\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1469\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1484\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1375\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1465\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1487\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1520\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1532\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1373\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1413\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1351\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1185\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1367\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1237\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1318\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1263\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1321\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1330\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1447\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1219\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1190\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1362\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1344\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1361\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1387\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1181\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1518\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1256\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1395\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1414\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1416\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1339\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1204\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1377\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1202\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1396\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1360\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1260\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1438\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1222\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on 10.0.243.53:37225 in memory (size: 16.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on algo-1:42111 in memory (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1476\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1336\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned shuffle 20\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1371\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1517\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on 10.0.243.53:37225 in memory (size: 30.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on algo-1:42111 in memory (size: 30.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1474\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1488\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1459\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1288\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1500\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1310\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1281\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1207\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1210\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1394\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1180\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1261\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1228\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1426\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1374\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1225\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1417\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1485\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1507\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1229\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1332\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1378\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1498\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1335\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1345\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1296\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1302\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1304\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1510\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1245\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned shuffle 17\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1205\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1389\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1450\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1337\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1410\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1198\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1393\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1424\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1481\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1420\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1259\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1264\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1434\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1252\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1439\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1331\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1323\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1319\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1430\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1244\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1405\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1213\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1224\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1358\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1466\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1241\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1454\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1491\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1258\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1273\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1279\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1452\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1530\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1370\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1497\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1400\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1495\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1402\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1231\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1274\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1427\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1192\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1372\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1195\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on 10.0.243.53:37225 in memory (size: 29.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on algo-1:42111 in memory (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1240\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1290\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1238\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1189\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1397\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1293\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1376\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1385\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1482\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1249\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1308\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1269\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1347\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1324\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1425\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1462\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1197\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1472\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1399\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1456\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1493\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1188\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1350\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1486\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1251\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1199\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1295\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned shuffle 18\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1235\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1415\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1409\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1254\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1471\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1214\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1278\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1353\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1312\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1311\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1292\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1508\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1475\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1363\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1408\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1262\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1276\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1386\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Registering RDD 253 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Got job 30 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Final stage: ResultStage 52 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 51)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 51)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 51 (MapPartitionsRDD[253] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1247\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1217\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1316\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1343\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1203\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1265\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on 10.0.243.53:37225 in memory (size: 19.4 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_54 stored as values in memory (estimated size 63.2 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on algo-1:42111 in memory (size: 19.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1470\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1531\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1196\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1446\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1379\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1526\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1384\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1433\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1429\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1443\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned shuffle 19\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1272\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1283\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1328\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on 10.0.243.53:37225 in memory (size: 16.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on algo-1:42111 in memory (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_54_piece0 stored as bytes in memory (estimated size 23.8 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on 10.0.243.53:37225 (size: 23.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1270\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1284\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1294\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1282\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 54 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1451\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1239\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1299\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1380\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1340\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1216\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1301\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1355\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[253] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 51.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1406\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1509\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1455\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1411\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1479\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1305\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1186\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1333\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1412\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1303\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1368\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1529\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1512\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1440\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1329\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 51.0 (TID 86, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1461\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1194\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1266\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1271\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1280\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on 10.0.243.53:37225 in memory (size: 17.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 1.0 in stage 51.0 (TID 87, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on algo-1:42111 in memory (size: 17.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1306\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1490\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1208\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1325\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1212\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1267\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1423\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1184\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1236\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1277\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1356\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1528\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1444\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1206\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1403\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1442\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1223\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1357\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1381\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1364\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1285\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1388\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1178\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1390\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1291\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1457\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1527\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1421\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1307\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1458\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1524\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1437\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1525\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1346\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1496\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1243\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1327\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1352\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1275\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1268\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1193\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1503\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1354\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1514\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1494\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1383\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1341\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1502\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1317\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1436\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1218\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on 10.0.243.53:37225 in memory (size: 19.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on algo-1:42111 in memory (size: 19.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on algo-1:42111 (size: 23.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1501\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1398\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1369\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1453\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on 10.0.243.53:37225 in memory (size: 29.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on algo-1:42111 in memory (size: 29.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1391\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1250\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1348\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1183\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1300\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1516\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1298\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1334\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1523\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1200\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1365\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1418\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1215\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1289\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1492\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1191\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1506\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1359\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1246\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on 10.0.243.53:37225 in memory (size: 35.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on algo-1:42111 in memory (size: 35.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1401\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1431\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on 10.0.243.53:37225 in memory (size: 1925.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on algo-1:42111 in memory (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1242\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on 10.0.243.53:37225 in memory (size: 1925.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on algo-1:42111 in memory (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1511\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1226\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ContextCleaner:54 - Cleaned accumulator 1286\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 51.0 (TID 87) in 171 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 51.0 (TID 86) in 200 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 51.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ShuffleMapStage 51 (collect at AnalysisRunner.scala:313) finished in 0.211 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - waiting: Set(ResultStage 52)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ResultStage 52 (MapPartitionsRDD[256] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_55 stored as values in memory (estimated size 69.9 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_55_piece0 stored as bytes in memory (estimated size 25.7 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on 10.0.243.53:37225 (size: 25.7 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 55 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[256] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 52.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 52.0 (TID 88, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on algo-1:42111 (size: 25.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 21 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 52.0 (TID 88) in 81 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 52.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ResultStage 52 (collect at AnalysisRunner.scala:313) finished in 0.087 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Job 30 finished: collect at AnalysisRunner.scala:313, took 0.303708 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  CodeGenerator:54 - Code generated in 6.222967 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Got job 31 (treeReduce at KLLRunner.scala:107) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Final stage: ResultStage 53 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ResultStage 53 (MapPartitionsRDD[265] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_56 stored as values in memory (estimated size 46.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_56_piece0 stored as bytes in memory (estimated size 18.9 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on 10.0.243.53:37225 (size: 18.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 56 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[265] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 53.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 53.0 (TID 89, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 1.0 in stage 53.0 (TID 90, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8363 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on algo-1:42111 (size: 18.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 53.0 (TID 90) in 69 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 53.0 (TID 89) in 189 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 53.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ResultStage 53 (treeReduce at KLLRunner.scala:107) finished in 0.195 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Job 31 finished: treeReduce at KLLRunner.scala:107, took 0.207580 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  CodeGenerator:54 - Code generated in 11.476744 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  CodeGenerator:54 - Code generated in 18.930376 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  CodeGenerator:54 - Code generated in 16.50328 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Registering RDD 270 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Got job 32 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Final stage: ResultStage 55 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 54 (MapPartitionsRDD[270] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_57 stored as values in memory (estimated size 60.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_57_piece0 stored as bytes in memory (estimated size 22.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on 10.0.243.53:37225 (size: 22.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 57 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[270] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 54.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 54.0 (TID 91, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 1.0 in stage 54.0 (TID 92, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on algo-1:42111 (size: 22.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 54.0 (TID 92) in 45 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 54.0 (TID 91) in 61 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 54.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ShuffleMapStage 54 (collect at AnalysisRunner.scala:313) finished in 0.067 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - waiting: Set(ResultStage 55)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ResultStage 55 (MapPartitionsRDD[273] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_58 stored as values in memory (estimated size 25.4 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_58_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on 10.0.243.53:37225 (size: 8.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 58 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[273] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 55.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 55.0 (TID 93, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on algo-1:42111 (size: 8.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 22 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 55.0 (TID 93) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 55.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ResultStage 55 (collect at AnalysisRunner.scala:313) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Job 32 finished: collect at AnalysisRunner.scala:313, took 0.108397 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Registering RDD 280 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Got job 33 (countByKey at ColumnProfiler.scala:566) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Final stage: ResultStage 57 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 56)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 56)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 56 (MapPartitionsRDD[280] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_59 stored as values in memory (estimated size 42.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_59_piece0 stored as bytes in memory (estimated size 17.8 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on 10.0.243.53:37225 (size: 17.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 59 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[280] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 56.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 56.0 (TID 94, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 1.0 in stage 56.0 (TID 95, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on algo-1:42111 (size: 17.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 56.0 (TID 95) in 55 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 56.0 (TID 94) in 92 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 56.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ShuffleMapStage 56 (countByKey at ColumnProfiler.scala:566) finished in 0.099 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - waiting: Set(ResultStage 57)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting ResultStage 57 (ShuffledRDD[281] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_60 stored as values in memory (estimated size 3.2 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MemoryStore:54 - Block broadcast_60_piece0 stored as bytes in memory (estimated size 1925.0 B, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on 10.0.243.53:37225 (size: 1925.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  SparkContext:54 - Created broadcast 60 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 57 (ShuffledRDD[281] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Adding task set 57.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 57.0 (TID 96, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Starting task 1.0 in stage 57.0 (TID 97, algo-1, executor 1, partition 1, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on algo-1:42111 (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 23 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 1.0 in stage 57.0 (TID 97) in 16 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 57.0 (TID 96) in 16 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  YarnScheduler:54 - Removed TaskSet 57.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - ResultStage 57 (countByKey at ColumnProfiler.scala:566) finished in 0.022 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  DAGScheduler:54 - Job 33 finished: countByKey at ColumnProfiler.scala:566, took 0.125365 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:41 INFO  ConstraintGenerator:45 - Generating Constraints:\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  ConstraintGenerator:50 - Constraints: {\n",
      "  \"version\" : 0.0,\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"_c0\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_years\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"insurance_grp\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"no_fam_member\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"total_visit_count\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"diagnosis_code_1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"diagnosis_code_2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : false\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"diagnosis_code_3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : false\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"alcohol\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"drug\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"fire\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sex_M\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sex_F\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_V\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_C\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_L\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_S\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_M\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_death_2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_death_0\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_death_1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Home\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Not recorded\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_School/ Sports Complex\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Public property\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Street\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Unknown\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Industrial area\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_less than 20\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_60 above\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_20 to 40\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_41 to 60\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"insurance_grp_bin_less than 50\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"insurance_grp_bin_greater than 50\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  } ],\n",
      "  \"monitoring_config\" : {\n",
      "    \"evaluate_constraints\" : \"Enabled\",\n",
      "    \"emit_metrics\" : \"Enabled\",\n",
      "    \"datatype_check_threshold\" : 1.0,\n",
      "    \"domain_content_threshold\" : 1.0,\n",
      "    \"distribution_constraints\" : {\n",
      "      \"perform_comparison\" : \"Enabled\",\n",
      "      \"comparison_threshold\" : 0.1,\n",
      "      \"comparison_method\" : \"Robust\"\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  FileUtil:29 - Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  StatsGenerator:65 - Generating Stats:\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  CodeGenerator:54 - Code generated in 4.988046 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  CodeGenerator:54 - Code generated in 4.045607 ms\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  SparkContext:54 - Starting job: count at StatsGenerator.scala:67\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Registering RDD 286 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Got job 34 (count at StatsGenerator.scala:67) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Final stage: ResultStage 59 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 58)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 58)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 58 (MapPartitionsRDD[286] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MemoryStore:54 - Block broadcast_61 stored as values in memory (estimated size 43.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MemoryStore:54 - Block broadcast_61_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on 10.0.243.53:37225 (size: 18.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  SparkContext:54 - Created broadcast 61 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[286] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnScheduler:54 - Adding task set 58.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 58.0 (TID 98, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  TaskSetManager:54 - Starting task 1.0 in stage 58.0 (TID 99, algo-1, executor 1, partition 1, PROCESS_LOCAL, 8352 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on algo-1:42111 (size: 18.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 58.0 (TID 98) in 45 ms on algo-1 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  TaskSetManager:54 - Finished task 1.0 in stage 58.0 (TID 99) in 47 ms on algo-1 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnScheduler:54 - Removed TaskSet 58.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - ShuffleMapStage 58 (count at StatsGenerator.scala:67) finished in 0.053 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - waiting: Set(ResultStage 59)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Submitting ResultStage 59 (MapPartitionsRDD[289] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MemoryStore:54 - Block broadcast_62 stored as values in memory (estimated size 7.4 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MemoryStore:54 - Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on 10.0.243.53:37225 (size: 3.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  SparkContext:54 - Created broadcast 62 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[289] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnScheduler:54 - Adding task set 59.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 59.0 (TID 100, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on algo-1:42111 (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 24 to 10.0.243.53:33774\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 59.0 (TID 100) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnScheduler:54 - Removed TaskSet 59.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - ResultStage 59 (count at StatsGenerator.scala:67) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  DAGScheduler:54 - Job 34 finished: count at StatsGenerator.scala:67, took 0.083274 s\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  StatsGenerator:70 - Stats: {\n",
      "  \"version\" : 0.0,\n",
      "  \"dataset\" : {\n",
      "    \"item_count\" : 33184\n",
      "  },\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"_c0\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 23791.9856256027,\n",
      "      \"sum\" : 7.89513251E8,\n",
      "      \"std_dev\" : 13681.213108347696,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 47405.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 4741.4,\n",
      "            \"count\" : 3280.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4741.4,\n",
      "            \"upper_bound\" : 9481.8,\n",
      "            \"count\" : 3312.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 9481.8,\n",
      "            \"upper_bound\" : 14222.2,\n",
      "            \"count\" : 3288.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 14222.2,\n",
      "            \"upper_bound\" : 18962.6,\n",
      "            \"count\" : 3280.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 18962.6,\n",
      "            \"upper_bound\" : 23703.0,\n",
      "            \"count\" : 3328.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 23703.0,\n",
      "            \"upper_bound\" : 28443.4,\n",
      "            \"count\" : 3344.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 28443.4,\n",
      "            \"upper_bound\" : 33183.8,\n",
      "            \"count\" : 3332.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 33183.8,\n",
      "            \"upper_bound\" : 37924.2,\n",
      "            \"count\" : 3324.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 37924.2,\n",
      "            \"upper_bound\" : 42664.6,\n",
      "            \"count\" : 3384.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 42664.6,\n",
      "            \"upper_bound\" : 47405.0,\n",
      "            \"count\" : 3312.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 14.0, 34.0, 86.0, 159.0, 216.0, 236.0, 254.0, 317.0, 392.0, 412.0, 448.0, 481.0, 501.0, 550.0, 591.0, 623.0, 664.0, 720.0, 759.0, 789.0, 869.0, 913.0, 960.0, 1012.0, 1062.0, 1080.0, 1097.0, 1154.0, 1197.0, 1248.0, 1261.0, 1321.0, 1366.0, 1415.0, 1483.0, 1518.0, 1525.0, 1578.0, 1593.0, 1640.0, 1664.0, 1736.0, 1791.0, 1843.0, 1880.0, 1956.0, 2026.0, 2088.0, 2106.0, 2130.0, 2147.0, 2198.0, 2245.0, 2314.0, 2357.0, 2382.0, 2426.0, 2449.0, 2500.0, 2507.0, 2532.0, 2551.0, 2594.0, 2662.0, 2695.0, 2720.0, 2782.0, 2816.0, 2853.0, 2900.0, 2930.0, 2950.0, 2976.0, 3013.0, 3051.0, 3101.0, 3141.0, 3210.0, 3244.0, 3282.0, 3343.0, 3367.0, 3418.0, 3442.0, 3484.0, 3541.0, 3566.0, 3601.0, 3635.0, 3649.0, 3692.0, 3747.0, 3786.0, 3806.0, 3867.0, 3891.0, 3927.0, 3963.0, 4003.0, 4019.0, 4040.0, 4058.0, 4104.0, 4139.0, 4163.0, 4227.0, 4252.0, 4309.0, 4326.0, 4364.0, 4431.0, 4489.0, 4549.0, 4593.0, 4613.0, 4666.0, 4722.0, 4755.0, 4810.0, 4826.0, 4857.0, 4866.0, 4980.0, 5020.0, 5035.0, 5070.0, 5153.0, 5195.0, 5263.0, 5436.0, 5457.0, 5560.0, 5603.0, 5656.0, 5674.0, 5757.0, 5775.0, 5846.0, 5895.0, 5933.0, 5976.0, 6024.0, 6069.0, 6102.0, 6131.0, 6171.0, 6226.0, 6276.0, 6385.0, 6424.0, 6491.0, 6521.0, 6580.0, 6613.0, 6646.0, 6700.0, 6744.0, 6773.0, 6791.0, 6839.0, 6907.0, 6942.0, 6965.0, 7041.0, 7129.0, 7182.0, 7217.0, 7222.0, 7272.0, 7293.0, 7343.0, 7398.0, 7439.0, 7484.0, 7521.0, 7571.0, 7609.0, 7640.0, 7654.0, 7717.0, 7742.0, 7782.0, 7831.0, 7872.0, 7905.0, 7955.0, 7974.0, 8035.0, 8101.0, 8135.0, 8147.0, 8203.0, 8266.0, 8272.0, 8304.0, 8351.0, 8403.0, 8443.0, 8513.0, 8538.0, 8558.0, 8598.0, 8642.0, 8772.0, 8796.0, 8833.0, 8905.0, 8966.0, 8983.0, 9046.0, 9087.0, 9099.0, 9113.0, 9169.0, 9224.0, 9240.0, 9285.0, 9337.0, 9362.0, 9440.0, 9505.0, 9558.0, 9599.0, 9652.0, 9661.0, 9679.0, 9730.0, 9763.0, 9825.0, 9847.0, 9874.0, 9933.0, 10030.0, 10044.0, 10108.0, 10138.0, 10243.0, 10271.0, 10314.0, 10374.0, 10388.0, 10437.0, 10498.0, 10519.0, 10592.0, 10628.0, 10666.0, 10677.0, 10701.0, 10736.0, 10774.0, 10797.0, 10828.0, 10850.0, 10872.0, 10905.0, 10928.0, 10978.0, 11014.0, 11067.0, 11105.0, 11144.0, 11185.0, 11195.0, 11294.0, 11332.0, 11383.0, 11419.0, 11432.0, 11477.0, 11514.0, 11545.0, 11554.0, 11611.0, 11630.0, 11667.0, 11712.0, 11767.0, 11851.0, 11884.0, 11922.0, 11943.0, 11956.0, 12000.0, 12057.0, 12101.0, 12117.0, 12163.0, 12178.0, 12210.0, 12252.0, 12263.0, 12289.0, 12333.0, 12348.0, 12387.0, 12425.0, 12497.0, 12532.0, 12546.0, 12580.0, 12595.0, 12652.0, 12673.0, 12704.0, 12722.0, 12776.0, 12818.0, 12831.0, 12869.0, 12941.0, 12970.0, 13055.0, 13105.0, 13169.0, 13194.0, 13200.0, 13235.0, 13252.0, 13340.0, 13451.0, 13466.0, 13555.0, 13606.0, 13636.0, 13663.0, 13699.0, 13736.0, 13751.0, 13779.0, 13840.0, 13857.0, 13880.0, 13953.0, 13990.0, 14021.0, 14042.0, 14131.0, 14177.0, 14230.0, 14290.0, 14323.0, 14371.0, 14439.0, 14493.0, 14530.0, 14561.0, 14622.0, 14661.0, 14724.0, 14757.0, 14817.0, 14886.0, 14901.0, 14992.0, 15023.0, 15051.0, 15112.0, 15138.0, 15200.0, 15231.0, 15298.0, 15425.0, 15453.0, 15499.0, 15533.0, 15547.0, 15602.0, 15651.0, 15713.0, 15733.0, 15768.0, 15823.0, 15874.0, 15901.0, 15924.0, 15972.0, 16048.0, 16064.0, 16094.0, 16174.0, 16201.0, 16224.0, 16283.0, 16317.0, 16349.0, 16354.0, 16485.0, 16627.0, 16652.0, 16715.0, 16764.0, 16834.0, 16907.0, 16948.0, 16966.0, 16993.0, 17092.0, 17127.0, 17145.0, 17188.0, 17198.0, 17232.0, 17324.0, 17357.0, 17395.0, 17415.0, 17471.0, 17558.0, 17592.0, 17635.0, 17704.0, 17743.0, 17783.0, 17822.0, 17870.0, 17908.0, 17966.0, 17979.0, 18012.0, 18054.0, 18138.0, 18168.0, 18205.0, 18228.0, 18272.0, 18303.0, 18340.0, 18354.0, 18409.0, 18437.0, 18490.0, 18508.0, 18522.0, 18556.0, 18582.0, 18654.0, 18698.0, 18732.0, 18766.0, 18782.0, 18810.0, 18819.0, 18952.0, 18974.0, 18994.0, 19031.0, 19044.0, 19077.0, 19127.0, 19173.0, 19241.0, 19265.0, 19294.0, 19357.0, 19433.0, 19503.0, 19544.0, 19569.0, 19619.0, 19660.0, 19684.0, 19703.0, 19737.0, 19770.0, 19785.0, 19828.0, 19845.0, 20007.0, 20052.0, 20114.0, 20147.0, 20221.0, 20245.0, 20342.0, 20359.0, 20393.0, 20416.0, 20446.0, 20503.0, 20532.0, 20548.0, 20583.0, 20623.0, 20681.0, 20704.0, 20728.0, 20753.0, 20784.0, 20892.0, 20908.0, 20937.0, 20971.0, 21026.0, 21083.0, 21186.0, 21240.0, 21248.0, 21294.0, 21336.0, 21400.0, 21434.0, 21461.0, 21555.0, 21569.0, 21605.0, 21659.0, 21675.0, 21708.0, 21778.0, 21828.0, 21836.0, 21871.0, 21894.0, 21976.0, 22007.0, 22045.0, 22061.0, 22095.0, 22171.0, 22194.0, 22231.0, 22261.0, 22305.0, 22347.0, 22447.0, 22519.0, 22542.0, 22628.0, 22683.0, 22711.0, 22795.0, 22869.0, 22924.0, 22936.0, 22982.0, 23010.0, 23044.0, 23073.0, 23109.0, 23160.0, 23215.0, 23264.0, 23285.0, 23313.0, 23354.0, 23397.0, 23507.0, 23530.0, 23562.0, 23618.0, 23659.0, 23694.0, 23722.0, 23762.0, 23795.0, 23835.0, 23906.0, 23915.0, 23976.0, 24018.0, 24083.0, 24101.0, 24154.0, 24206.0, 24237.0, 24255.0, 24299.0, 24318.0, 24346.0, 24399.0, 24438.0, 24457.0, 24486.0, 24552.0, 24616.0, 24653.0, 24688.0, 24743.0, 24792.0, 24828.0, 24904.0, 24929.0, 24987.0, 25074.0, 25148.0, 25172.0, 25244.0, 25301.0, 25332.0, 25378.0, 25480.0, 25534.0, 25595.0, 25620.0, 25639.0, 25693.0, 25728.0, 25769.0, 25811.0, 25837.0, 25873.0, 25892.0, 25921.0, 25967.0, 25985.0, 26056.0, 26075.0, 26143.0, 26157.0, 26215.0, 26268.0, 26299.0, 26339.0, 26382.0, 26412.0, 26442.0, 26471.0, 26510.0, 26586.0, 26614.0, 26628.0, 26672.0, 26706.0, 26734.0, 26777.0, 26830.0, 26874.0, 26907.0, 26977.0, 27005.0, 27032.0, 27076.0, 27093.0, 27132.0, 27191.0, 27243.0, 27300.0, 27356.0, 27449.0, 27474.0, 27511.0, 27555.0, 27581.0, 27648.0, 27661.0, 27678.0, 27745.0, 27766.0, 27829.0, 27839.0, 27884.0, 27908.0, 27928.0, 28013.0, 28077.0, 28122.0, 28159.0, 28198.0, 28235.0, 28304.0, 28337.0, 28354.0, 28373.0, 28407.0, 28452.0, 28493.0, 28559.0, 28594.0, 28650.0, 28693.0, 28775.0, 28815.0, 28850.0, 28902.0, 28924.0, 28975.0, 29000.0, 29067.0, 29111.0, 29179.0, 29212.0, 29240.0, 29268.0, 29326.0, 29377.0, 29439.0, 29489.0, 29539.0, 29562.0, 29614.0, 29649.0, 29697.0, 29730.0, 29760.0, 29777.0, 29800.0, 29828.0, 29857.0, 29884.0, 29920.0, 29967.0, 29992.0, 30031.0, 30070.0, 30115.0, 30151.0, 30172.0, 30260.0, 30336.0, 30387.0, 30475.0, 30509.0, 30541.0, 30598.0, 30621.0, 30659.0, 30721.0, 30773.0, 30875.0, 30912.0, 30957.0, 30971.0, 30991.0, 31018.0, 31071.0, 31101.0, 31151.0, 31218.0, 31265.0, 31347.0, 31374.0, 31415.0, 31475.0, 31537.0, 31595.0, 31694.0, 31720.0, 31796.0, 31817.0, 31853.0, 31887.0, 31937.0, 31963.0, 31968.0, 32051.0, 32088.0, 32128.0, 32155.0, 32198.0, 32246.0, 32286.0, 32330.0, 32365.0, 32371.0, 32403.0, 32441.0, 32451.0, 32504.0, 32536.0, 32595.0, 32671.0, 32733.0, 32766.0, 32792.0, 32850.0, 32895.0, 32925.0, 32941.0, 32971.0, 33001.0, 33039.0, 33130.0, 33175.0, 33247.0, 33303.0, 33356.0, 33391.0, 33470.0, 33500.0, 33550.0, 33586.0, 33609.0, 33627.0, 33685.0, 33725.0, 33817.0, 33860.0, 33879.0, 33920.0, 33982.0, 33988.0, 34027.0, 34048.0, 34198.0, 34253.0, 34324.0, 34356.0, 34454.0, 34487.0, 34519.0, 34563.0, 34608.0, 34714.0, 34731.0, 34770.0, 34796.0, 34830.0, 34876.0, 34909.0, 34965.0, 35009.0, 35040.0, 35085.0, 35114.0, 35150.0, 35187.0, 35206.0, 35248.0, 35272.0, 35317.0, 35376.0, 35462.0, 35510.0, 35564.0, 35605.0, 35641.0, 35678.0, 35752.0, 35758.0, 35775.0, 35805.0, 35915.0, 35960.0, 35981.0, 35999.0, 36048.0, 36097.0, 36150.0, 36220.0, 36250.0, 36277.0, 36357.0, 36369.0, 36400.0, 36429.0, 36442.0, 36474.0, 36503.0, 36539.0, 36611.0, 36632.0, 36680.0, 36788.0, 36859.0, 36893.0, 36948.0, 36996.0, 37025.0, 37067.0, 37115.0, 37158.0, 37192.0, 37273.0, 37356.0, 37376.0, 37440.0, 37457.0, 37481.0, 37518.0, 37543.0, 37579.0, 37608.0, 37693.0, 37802.0, 37811.0, 37888.0, 37938.0, 38010.0, 38049.0, 38067.0, 38091.0, 38108.0, 38130.0, 38190.0, 38210.0, 38291.0, 38331.0, 38367.0, 38397.0, 38449.0, 38503.0, 38532.0, 38561.0, 38600.0, 38613.0, 38627.0, 38649.0, 38688.0, 38699.0, 38748.0, 38809.0, 38821.0, 38835.0, 38856.0, 38949.0, 38996.0, 39016.0, 39055.0, 39111.0, 39213.0, 39241.0, 39274.0, 39302.0, 39347.0, 39372.0, 39419.0, 39447.0, 39485.0, 39529.0, 39569.0, 39622.0, 39675.0, 39791.0, 39828.0, 39840.0, 39876.0, 39914.0, 39926.0, 39951.0, 40014.0, 40036.0, 40064.0, 40105.0, 40122.0, 40209.0, 40234.0, 40335.0, 40382.0, 40431.0, 40501.0, 40550.0, 40573.0, 40624.0, 40659.0, 40697.0, 40729.0, 40782.0, 40819.0, 40869.0, 40924.0, 40931.0, 40956.0, 41015.0, 41065.0, 41126.0, 41166.0, 41251.0, 41292.0, 41330.0, 41345.0, 41416.0, 41453.0, 41489.0, 41563.0, 41610.0, 41648.0, 41695.0, 41721.0, 41743.0, 41786.0, 41837.0, 41865.0, 41907.0, 41946.0, 42046.0, 42070.0, 42082.0, 42136.0, 42166.0, 42234.0, 42303.0, 42368.0, 42399.0, 42434.0, 42459.0, 42495.0, 42509.0, 42543.0, 42555.0, 42575.0, 42614.0, 42649.0, 42730.0, 42744.0, 42808.0, 42834.0, 42892.0, 42978.0, 43003.0, 43040.0, 43066.0, 43135.0, 43145.0, 43210.0, 43240.0, 43273.0, 43303.0, 43344.0, 43369.0, 43395.0, 43465.0, 43512.0, 43548.0, 43592.0, 43630.0, 43646.0, 43658.0, 43675.0, 43709.0, 43736.0, 43753.0, 43791.0, 43883.0, 43989.0, 44033.0, 44091.0, 44131.0, 44191.0, 44303.0, 44344.0, 44405.0, 44446.0, 44513.0, 44551.0, 44676.0, 44723.0, 44781.0, 44838.0, 44868.0, 44928.0, 45000.0, 45038.0, 45089.0, 45152.0, 45209.0, 45288.0, 45304.0, 45352.0, 45383.0, 45410.0, 45472.0, 45565.0, 45590.0, 45617.0, 45641.0, 45686.0, 45706.0, 45776.0, 45802.0, 45842.0, 45855.0, 45949.0, 45973.0, 46013.0, 46051.0, 46082.0, 46098.0, 46137.0, 46231.0, 46263.0, 46286.0, 46304.0, 46342.0, 46416.0, 46450.0, 46496.0, 46525.0, 46560.0, 46592.0, 46620.0, 46651.0, 46688.0, 46738.0, 46790.0, 46850.0, 46891.0, 46955.0, 47012.0, 47038.0, 47055.0, 47113.0, 47162.0, 47192.0, 47274.0, 47334.0, 47383.0, 47220.0, 66.0, 101.0, 114.0, 178.0, 200.0, 244.0, 285.0, 316.0, 369.0, 395.0, 414.0, 455.0, 476.0, 553.0, 594.0, 602.0, 638.0, 674.0, 711.0, 758.0, 798.0, 839.0, 866.0, 911.0, 944.0, 966.0, 984.0, 1044.0, 1075.0, 1192.0, 1199.0, 1245.0, 1290.0, 1327.0, 1372.0, 1434.0, 1509.0, 1569.0, 1586.0, 1651.0, 1671.0, 1719.0, 1785.0, 1849.0, 1905.0, 1925.0, 1972.0, 1997.0, 2042.0, 2124.0, 2177.0, 2203.0, 2280.0, 2340.0, 2368.0, 2411.0, 2452.0, 2541.0, 2571.0, 2637.0, 2671.0, 2719.0, 2766.0, 2831.0, 2842.0, 2874.0, 2969.0, 3004.0, 3047.0, 3120.0, 3137.0, 3159.0, 3227.0, 3262.0, 3339.0, 3426.0, 3441.0, 3463.0, 3510.0, 3552.0, 3585.0, 3690.0, 3745.0, 3793.0, 3835.0, 3873.0, 3954.0, 3992.0, 4027.0, 4046.0, 4099.0, 4124.0, 4145.0, 4169.0, 4193.0, 4254.0, 4293.0, 4392.0, 4433.0, 4480.0, 4509.0, 4528.0, 4570.0, 4584.0, 4675.0, 4692.0, 4745.0, 4781.0, 4831.0, 4890.0, 4945.0, 4997.0, 5077.0, 5131.0, 5175.0, 5216.0, 5266.0, 5297.0, 5326.0, 5397.0, 5420.0, 5460.0, 5483.0, 5511.0, 5559.0, 5594.0, 5631.0, 5680.0, 5710.0, 5738.0, 5791.0, 5812.0, 5864.0, 5886.0, 5920.0, 5938.0, 5956.0, 5998.0, 6034.0, 6061.0, 6082.0, 6133.0, 6154.0, 6195.0, 6232.0, 6257.0, 6282.0, 6307.0, 6351.0, 6397.0, 6413.0, 6464.0, 6478.0, 6520.0, 6572.0, 6609.0, 6679.0, 6785.0, 6810.0, 6896.0, 6903.0, 6943.0, 6958.0, 6983.0, 7018.0, 7048.0, 7085.0, 7136.0, 7196.0, 7247.0, 7296.0, 7346.0, 7391.0, 7408.0, 7423.0, 7497.0, 7542.0, 7578.0, 7607.0, 7648.0, 7682.0, 7718.0, 7777.0, 7805.0, 7862.0, 7927.0, 7966.0, 8029.0, 8067.0, 8099.0, 8136.0, 8205.0, 8217.0, 8245.0, 8285.0, 8333.0, 8396.0, 8440.0, 8477.0, 8518.0, 8541.0, 8619.0, 8629.0, 8682.0, 8704.0, 8751.0, 8805.0, 8823.0, 8882.0, 8924.0, 8951.0, 8958.0, 8995.0, 9076.0, 9118.0, 9166.0, 9204.0, 9231.0, 9241.0, 9284.0, 9312.0, 9359.0, 9392.0, 9420.0, 9615.0, 9635.0, 9653.0, 9691.0, 9735.0, 9765.0, 9783.0, 9865.0, 9915.0, 10000.0, 10019.0, 10040.0, 10111.0, 10142.0, 10193.0, 10235.0, 10264.0, 10346.0, 10376.0, 10406.0, 10419.0, 10468.0, 10497.0, 10557.0, 10602.0, 10632.0, 10679.0, 10728.0, 10740.0, 10854.0, 10894.0, 10933.0, 10999.0, 11034.0, 11068.0, 11115.0, 11155.0, 11243.0, 11276.0, 11309.0, 11338.0, 11393.0, 11523.0, 11553.0, 11579.0, 11643.0, 11693.0, 11747.0, 11801.0, 11865.0, 11896.0, 11935.0, 11965.0, 11991.0, 12004.0, 12060.0, 12120.0, 12156.0, 12227.0, 12315.0, 12370.0, 12402.0, 12449.0, 12480.0, 12560.0, 12582.0, 12604.0, 12643.0, 12732.0, 12754.0, 12838.0, 12878.0, 12892.0, 12914.0, 12961.0, 12987.0, 13036.0, 13094.0, 13131.0, 13137.0, 13168.0, 13224.0, 13300.0, 13350.0, 13387.0, 13444.0, 13486.0, 13524.0, 13585.0, 13613.0, 13638.0, 13672.0, 13756.0, 13797.0, 13832.0, 13916.0, 13952.0, 13981.0, 14004.0, 14059.0, 14100.0, 14142.0, 14194.0, 14237.0, 14347.0, 14362.0, 14403.0, 14437.0, 14478.0, 14492.0, 14697.0, 14753.0, 14778.0, 14797.0, 14829.0, 14899.0, 14947.0, 15022.0, 15045.0, 15079.0, 15133.0, 15174.0, 15189.0, 15271.0, 15295.0, 15339.0, 15404.0, 15427.0, 15466.0, 15509.0, 15559.0, 15570.0, 15612.0, 15633.0, 15662.0, 15746.0, 15824.0, 15860.0, 15910.0, 15946.0, 15973.0, 16001.0, 16038.0, 16098.0, 16157.0, 16190.0, 16225.0, 16279.0, 16315.0, 16386.0, 16443.0, 16472.0, 16517.0, 16577.0, 16615.0, 16681.0, 16710.0, 16738.0, 16843.0, 16874.0, 16897.0, 16922.0, 16949.0, 16995.0, 17043.0, 17071.0, 17090.0, 17116.0, 17199.0, 17231.0, 17305.0, 17322.0, 17381.0, 17418.0, 17446.0, 17497.0, 17519.0, 17564.0, 17615.0, 17636.0, 17668.0, 17712.0, 17790.0, 17830.0, 17885.0, 17930.0, 17960.0, 17985.0, 18037.0, 18061.0, 18079.0, 18152.0, 18199.0, 18266.0, 18282.0, 18292.0, 18336.0, 18384.0, 18503.0, 18541.0, 18558.0, 18586.0, 18633.0, 18644.0, 18664.0, 18750.0, 18863.0, 18879.0, 18899.0, 18926.0, 19008.0, 19026.0, 19098.0, 19111.0, 19126.0, 19171.0, 19216.0, 19274.0, 19280.0, 19321.0, 19352.0, 19445.0, 19496.0, 19526.0, 19600.0, 19675.0, 19679.0, 19715.0, 19796.0, 19818.0, 19835.0, 19882.0, 19904.0, 19915.0, 19992.0, 20023.0, 20079.0, 20108.0, 20122.0, 20160.0, 20174.0, 20214.0, 20301.0, 20322.0, 20362.0, 20395.0, 20435.0, 20463.0, 20527.0, 20602.0, 20628.0, 20659.0, 20745.0, 20757.0, 20799.0, 20836.0, 20861.0, 20917.0, 20977.0, 20996.0, 21028.0, 21110.0, 21126.0, 21188.0, 21209.0, 21279.0, 21327.0, 21363.0, 21426.0, 21493.0, 21559.0, 21615.0, 21642.0, 21669.0, 21714.0, 21768.0, 21797.0, 21818.0, 21840.0, 21867.0, 21938.0, 21962.0, 22022.0, 22064.0, 22082.0, 22117.0, 22125.0, 22179.0, 22240.0, 22278.0, 22334.0, 22378.0, 22475.0, 22494.0, 22546.0, 22647.0, 22688.0, 22732.0, 22831.0, 22866.0, 22887.0, 22940.0, 22962.0, 22988.0, 23002.0, 23065.0, 23105.0, 23135.0, 23198.0, 23248.0, 23303.0, 23352.0, 23392.0, 23422.0, 23463.0, 23484.0, 23515.0, 23576.0, 23681.0, 23693.0, 23725.0, 23754.0, 23776.0, 23830.0, 23864.0, 23918.0, 23934.0, 23989.0, 24032.0, 24047.0, 24069.0, 24108.0, 24152.0, 24204.0, 24309.0, 24327.0, 24385.0, 24454.0, 24488.0, 24542.0, 24589.0, 24631.0, 24659.0, 24733.0, 24755.0, 24821.0, 24865.0, 24901.0, 24962.0, 24982.0, 25013.0, 25032.0, 25099.0, 25174.0, 25217.0, 25257.0, 25279.0, 25347.0, 25379.0, 25403.0, 25430.0, 25481.0, 25513.0, 25554.0, 25617.0, 25667.0, 25699.0, 25754.0, 25803.0, 25847.0, 25879.0, 25930.0, 25976.0, 25997.0, 26025.0, 26062.0, 26085.0, 26128.0, 26179.0, 26220.0, 26275.0, 26311.0, 26328.0, 26349.0, 26424.0, 26455.0, 26476.0, 26537.0, 26550.0, 26591.0, 26630.0, 26673.0, 26755.0, 26793.0, 26817.0, 26839.0, 26920.0, 27035.0, 27052.0, 27097.0, 27171.0, 27210.0, 27270.0, 27304.0, 27348.0, 27369.0, 27384.0, 27421.0, 27518.0, 27603.0, 27646.0, 27690.0, 27752.0, 27801.0, 27847.0, 27905.0, 27948.0, 27967.0, 28012.0, 28044.0, 28105.0, 28156.0, 28184.0, 28216.0, 28246.0, 28274.0, 28339.0, 28396.0, 28434.0, 28468.0, 28496.0, 28514.0, 28629.0, 28664.0, 28696.0, 28791.0, 28851.0, 28892.0, 28950.0, 28964.0, 28993.0, 29030.0, 29062.0, 29101.0, 29143.0, 29176.0, 29194.0, 29316.0, 29343.0, 29386.0, 29424.0, 29455.0, 29514.0, 29540.0, 29575.0, 29642.0, 29664.0, 29699.0, 29736.0, 29781.0, 29847.0, 29876.0, 29917.0, 29936.0, 30015.0, 30027.0, 30041.0, 30067.0, 30083.0, 30120.0, 30160.0, 30194.0, 30235.0, 30251.0, 30274.0, 30324.0, 30377.0, 30424.0, 30451.0, 30515.0, 30564.0, 30605.0, 30638.0, 30706.0, 30779.0, 30800.0, 30874.0, 30901.0, 30942.0, 30975.0, 30989.0, 31034.0, 31063.0, 31106.0, 31177.0, 31205.0, 31289.0, 31354.0, 31377.0, 31387.0, 31451.0, 31504.0, 31549.0, 31599.0, 31640.0, 31655.0, 31707.0, 31750.0, 31794.0, 31821.0, 31870.0, 31935.0, 31950.0, 31978.0, 32005.0, 32035.0, 32068.0, 32158.0, 32201.0, 32289.0, 32354.0, 32412.0, 32443.0, 32481.0, 32525.0, 32562.0, 32569.0, 32601.0, 32673.0, 32702.0, 32752.0, 32835.0, 32897.0, 32934.0, 32960.0, 32994.0, 33070.0, 33093.0, 33177.0, 33217.0, 33261.0, 33313.0, 33326.0, 33359.0, 33375.0, 33433.0, 33440.0, 33542.0, 33556.0, 33623.0, 33699.0, 33732.0, 33\u001b[0m\n",
      "\u001b[34m801.0, 33829.0, 33878.0, 33895.0, 33927.0, 33993.0, 34010.0, 34038.0, 34109.0, 34147.0, 34171.0, 34217.0, 34279.0, 34319.0, 34371.0, 34416.0, 34506.0, 34532.0, 34561.0, 34600.0, 34662.0, 34703.0, 34791.0, 34813.0, 34856.0, 34935.0, 34957.0, 34991.0, 35070.0, 35153.0, 35162.0, 35256.0, 35327.0, 35360.0, 35391.0, 35415.0, 35444.0, 35496.0, 35550.0, 35602.0, 35674.0, 35743.0, 35795.0, 35844.0, 35894.0, 35942.0, 35995.0, 36077.0, 36128.0, 36172.0, 36200.0, 36238.0, 36278.0, 36319.0, 36349.0, 36486.0, 36513.0, 36585.0, 36610.0, 36647.0, 36673.0, 36722.0, 36737.0, 36756.0, 36794.0, 36805.0, 36883.0, 36949.0, 36974.0, 37008.0, 37080.0, 37113.0, 37154.0, 37274.0, 37304.0, 37339.0, 37401.0, 37416.0, 37474.0, 37492.0, 37528.0, 37582.0, 37634.0, 37649.0, 37666.0, 37725.0, 37766.0, 37809.0, 37849.0, 37902.0, 37922.0, 37981.0, 37993.0, 38072.0, 38157.0, 38243.0, 38278.0, 38342.0, 38361.0, 38485.0, 38529.0, 38598.0, 38686.0, 38718.0, 38798.0, 38881.0, 38934.0, 38969.0, 39026.0, 39038.0, 39127.0, 39172.0, 39197.0, 39239.0, 39258.0, 39279.0, 39325.0, 39388.0, 39400.0, 39459.0, 39477.0, 39511.0, 39541.0, 39559.0, 39580.0, 39596.0, 39631.0, 39690.0, 39748.0, 39769.0, 39790.0, 39822.0, 39889.0, 39897.0, 39918.0, 39963.0, 39996.0, 40050.0, 40073.0, 40113.0, 40140.0, 40184.0, 40228.0, 40272.0, 40345.0, 40401.0, 40422.0, 40469.0, 40536.0, 40567.0, 40611.0, 40637.0, 40678.0, 40755.0, 40789.0, 40821.0, 40835.0, 40875.0, 40913.0, 40953.0, 40980.0, 41049.0, 41076.0, 41144.0, 41195.0, 41248.0, 41284.0, 41328.0, 41357.0, 41393.0, 41414.0, 41427.0, 41451.0, 41505.0, 41539.0, 41552.0, 41579.0, 41589.0, 41632.0, 41661.0, 41701.0, 41790.0, 41827.0, 41867.0, 41904.0, 41941.0, 41971.0, 42007.0, 42088.0, 42108.0, 42140.0, 42220.0, 42266.0, 42281.0, 42297.0, 42391.0, 42419.0, 42467.0, 42513.0, 42617.0, 42633.0, 42677.0, 42690.0, 42752.0, 42794.0, 42812.0, 42928.0, 42947.0, 42992.0, 43045.0, 43101.0, 43137.0, 43158.0, 43192.0, 43218.0, 43258.0, 43314.0, 43368.0, 43410.0, 43478.0, 43521.0, 43545.0, 43559.0, 43631.0, 43679.0, 43727.0, 43758.0, 43798.0, 43914.0, 43943.0, 43972.0, 44018.0, 44035.0, 44064.0, 44102.0, 44123.0, 44162.0, 44194.0, 44215.0, 44242.0, 44273.0, 44327.0, 44382.0, 44406.0, 44481.0, 44572.0, 44628.0, 44696.0, 44741.0, 44801.0, 44833.0, 44894.0, 44940.0, 44985.0, 45037.0, 45074.0, 45116.0, 45206.0, 45230.0, 45253.0, 45286.0, 45337.0, 45358.0, 45385.0, 45413.0, 45435.0, 45500.0, 45578.0, 45603.0, 45628.0, 45663.0, 45744.0, 45771.0, 45828.0, 45878.0, 45938.0, 45968.0, 45984.0, 46036.0, 46101.0, 46135.0, 46195.0, 46267.0, 46302.0, 46334.0, 46393.0, 46445.0, 46499.0, 46524.0, 46570.0, 46612.0, 46673.0, 46712.0, 46803.0, 46852.0, 46948.0, 46963.0, 47052.0, 47086.0, 47122.0, 47135.0, 47155.0, 47188.0, 47222.0, 47263.0, 47298.0, 47319.0, 47343.0, 47362.0, 50.0, 97.0, 136.0, 180.0, 267.0, 312.0, 338.0, 409.0, 504.0, 520.0, 576.0, 640.0, 738.0, 776.0, 828.0, 862.0, 893.0, 910.0, 973.0, 1003.0, 1040.0, 1089.0, 1110.0, 1134.0, 1177.0, 1240.0, 1289.0, 1318.0, 1385.0, 1486.0, 1607.0, 1654.0, 1690.0, 1743.0, 1808.0, 1877.0, 1898.0, 1940.0, 1980.0, 2062.0, 2131.0, 2192.0, 2236.0, 2279.0, 2305.0, 2387.0, 2480.0, 2554.0, 2590.0, 2655.0, 2743.0, 2828.0, 2946.0, 3003.0, 3041.0, 3103.0, 3139.0, 3209.0, 3260.0, 3283.0, 3312.0, 3354.0, 3421.0, 3494.0, 3513.0, 3529.0, 3550.0, 3624.0, 3657.0, 3701.0, 3748.0, 3816.0, 3878.0, 3914.0, 4012.0, 4079.0, 4127.0, 4181.0, 4241.0, 4288.0, 4345.0, 4375.0, 4418.0, 4486.0, 4537.0, 4595.0, 4627.0, 4677.0, 4720.0, 4765.0, 4806.0, 4844.0, 4893.0, 4935.0, 4967.0, 5009.0, 5036.0, 5104.0, 5158.0, 5201.0, 5228.0, 5329.0, 5382.0, 5451.0, 5527.0, 5598.0, 5649.0, 5808.0, 5837.0, 5859.0, 5887.0, 5925.0, 6048.0, 6081.0, 6125.0, 6196.0, 6218.0, 6280.0, 6345.0, 6388.0, 6454.0, 6524.0, 6557.0, 6645.0, 6667.0, 6689.0, 6710.0, 6730.0, 6768.0, 6780.0, 6819.0, 6872.0, 6918.0, 6977.0, 7073.0, 7083.0, 7143.0, 7208.0, 7294.0, 7366.0, 7464.0, 7508.0, 7564.0, 7593.0, 7644.0, 7680.0, 7713.0, 7750.0, 7789.0, 7858.0, 7910.0, 7934.0, 7977.0, 8019.0, 8087.0, 8129.0, 8210.0, 8234.0, 8276.0, 8301.0, 8386.0, 8401.0, 8438.0, 8510.0, 8581.0, 8645.0, 8693.0, 8734.0, 8770.0, 8801.0, 8841.0, 8885.0, 8910.0, 8979.0, 9065.0, 9110.0, 9216.0, 9269.0, 9345.0, 9406.0, 9426.0, 9480.0, 9527.0, 9588.0, 9645.0, 9710.0, 9767.0, 9830.0, 9869.0, 9909.0, 10003.0, 10072.0, 10096.0, 10136.0, 10161.0, 10181.0, 10234.0, 10256.0, 10325.0, 10394.0, 10424.0, 10459.0, 10505.0, 10521.0, 10585.0, 10613.0, 10696.0, 10754.0, 10769.0, 10820.0, 10861.0, 10904.0, 10950.0, 11000.0, 11038.0, 11080.0, 11116.0, 11182.0, 11354.0, 11425.0, 11471.0, 11488.0, 11567.0, 11592.0, 11606.0, 11677.0, 11710.0, 11779.0, 11809.0, 11855.0, 11887.0, 11944.0, 11998.0, 12036.0, 12082.0, 12159.0, 12230.0, 12278.0, 12343.0, 12434.0, 12526.0, 12575.0, 12591.0, 12628.0, 12683.0, 12721.0, 12750.0, 12836.0, 12885.0, 12915.0, 12989.0, 13046.0, 13088.0, 13174.0, 13198.0, 13229.0, 13285.0, 13315.0, 13335.0, 13390.0, 13511.0, 13576.0, 13598.0, 13647.0, 13700.0, 13782.0, 13814.0, 13888.0, 13924.0, 13988.0, 14034.0, 14069.0, 14169.0, 14201.0, 14234.0, 14310.0, 14373.0, 14420.0, 14481.0, 14512.0, 14526.0, 14596.0, 14631.0, 14684.0, 14750.0, 14824.0, 14855.0, 14941.0, 14975.0, 15012.0, 15076.0, 15135.0, 15198.0, 15261.0, 15316.0, 15400.0, 15448.0, 15577.0, 15639.0, 15706.0, 15827.0, 15869.0, 15903.0, 15990.0, 16024.0, 16045.0, 16123.0, 16182.0, 16240.0, 16258.0, 16299.0, 16342.0, 16396.0, 16447.0, 16483.0, 16561.0, 16606.0, 16629.0, 16695.0, 16747.0, 16806.0, 16875.0, 16939.0, 17028.0, 17065.0, 17136.0, 17171.0, 17256.0, 17293.0, 17320.0, 17410.0, 17430.0, 17525.0, 17595.0, 17692.0, 17709.0, 17754.0, 17800.0, 17854.0, 17955.0, 18122.0, 18218.0, 18295.0, 18321.0, 18372.0, 18426.0, 18441.0, 18496.0, 18551.0, 18565.0, 18680.0, 18695.0, 18772.0, 18813.0, 18847.0, 18907.0, 19004.0, 19063.0, 19123.0, 19189.0, 19205.0, 19287.0, 19349.0, 19417.0, 19494.0, 19560.0, 19659.0, 19706.0, 19748.0, 19863.0, 19924.0, 19955.0, 19974.0, 20076.0, 20157.0, 20206.0, 20260.0, 20296.0, 20320.0, 20387.0, 20413.0, 20534.0, 20575.0, 20622.0, 20676.0, 20700.0, 20765.0, 20868.0, 20905.0, 20927.0, 20967.0, 21033.0, 21125.0, 21207.0, 21243.0, 21353.0, 21391.0, 21494.0, 21549.0, 21587.0, 21631.0, 21767.0, 21817.0, 21877.0, 21919.0, 21949.0, 22006.0, 22033.0, 22116.0, 22169.0, 22228.0, 22318.0, 22395.0, 22438.0, 22450.0, 22518.0, 22551.0, 22598.0, 22634.0, 22663.0, 22725.0, 22773.0, 22813.0, 22848.0, 22906.0, 22960.0, 22991.0, 23018.0, 23069.0, 23101.0, 23154.0, 23220.0, 23266.0, 23314.0, 23430.0, 23465.0, 23500.0, 23591.0, 23655.0, 23707.0, 23760.0, 23848.0, 23903.0, 23970.0, 23996.0, 24049.0, 24093.0, 24177.0, 24224.0, 24291.0, 24315.0, 24394.0, 24432.0, 24507.0, 24554.0, 24609.0, 24672.0, 24730.0, 24808.0, 24948.0, 24997.0, 25046.0, 25123.0, 25189.0, 25225.0, 25284.0, 25316.0, 25448.0, 25511.0, 25546.0, 25609.0, 25736.0, 25766.0, 25876.0, 25913.0, 25927.0, 26034.0, 26064.0, 26093.0, 26140.0, 26176.0, 26272.0, 26362.0, 26399.0, 26453.0, 26499.0, 26577.0, 26602.0, 26646.0, 26689.0, 26714.0, 26802.0, 26893.0, 27001.0, 27044.0, 27119.0, 27153.0, 27218.0, 27241.0, 27318.0, 27357.0, 27389.0, 27415.0, 27441.0, 27458.0, 27566.0, 27607.0, 27662.0, 27698.0, 27783.0, 27837.0, 27865.0, 27885.0, 27953.0, 28048.0, 28082.0, 28112.0, 28158.0, 28228.0, 28289.0, 28334.0, 28408.0, 28461.0, 28489.0, 28548.0, 28648.0, 28692.0, 28725.0, 28773.0, 28863.0, 28879.0, 28895.0, 28922.0, 29025.0, 29076.0, 29114.0, 29184.0, 29206.0, 29290.0, 29318.0, 29387.0, 29452.0, 29560.0, 29656.0, 29813.0, 29866.0, 29918.0, 30007.0, 30062.0, 30141.0, 30180.0, 30239.0, 30309.0, 30450.0, 30508.0, 30554.0, 30686.0, 30787.0, 30834.0, 30909.0, 30995.0, 31050.0, 31084.0, 31118.0, 31164.0, 31236.0, 31263.0, 31291.0, 31325.0, 31357.0, 31383.0, 31393.0, 31434.0, 31462.0, 31500.0, 31540.0, 31611.0, 31687.0, 31758.0, 31856.0, 31904.0, 31999.0, 32044.0, 32089.0, 32183.0, 32264.0, 32300.0, 32380.0, 32482.0, 32546.0, 32580.0, 32600.0, 32665.0, 32713.0, 32748.0, 32847.0, 32906.0, 32922.0, 33044.0, 33094.0, 33112.0, 33172.0, 33190.0, 33276.0, 33424.0, 33456.0, 33514.0, 33546.0, 33579.0, 33639.0, 33676.0, 33748.0, 33769.0, 33779.0, 33794.0, 33852.0, 33904.0, 33945.0, 33989.0, 34070.0, 34118.0, 34148.0, 34176.0, 34254.0, 34307.0, 34375.0, 34434.0, 34481.0, 34554.0, 34611.0, 34654.0, 34715.0, 34767.0, 34925.0, 34974.0, 35008.0, 35086.0, 35137.0, 35151.0, 35245.0, 35289.0, 35367.0, 35447.0, 35460.0, 35506.0, 35536.0, 35654.0, 35672.0, 35698.0, 35748.0, 35804.0, 35820.0, 35896.0, 35997.0, 36040.0, 36089.0, 36119.0, 36196.0, 36284.0, 36294.0, 36379.0, 36428.0, 36455.0, 36528.0, 36561.0, 36578.0, 36666.0, 36691.0, 36752.0, 36810.0, 36879.0, 36911.0, 36934.0, 37036.0, 37079.0, 37129.0, 37196.0, 37220.0, 37292.0, 37305.0, 37329.0, 37372.0, 37429.0, 37473.0, 37559.0, 37593.0, 37723.0, 37773.0, 37844.0, 37904.0, 37929.0, 37975.0, 38026.0, 38054.0, 38087.0, 38162.0, 38238.0, 38284.0, 38322.0, 38394.0, 38426.0, 38456.0, 38504.0, 38526.0, 38588.0, 38693.0, 38722.0, 38762.0, 38923.0, 38962.0, 39035.0, 39065.0, 39101.0, 39166.0, 39255.0, 39316.0, 39387.0, 39436.0, 39470.0, 39518.0, 39561.0, 39604.0, 39642.0, 39729.0, 39772.0, 39823.0, 39886.0, 39959.0, 39999.0, 40054.0, 40102.0, 40212.0, 40266.0, 40313.0, 40355.0, 40438.0, 40507.0, 40535.0, 40576.0, 40612.0, 40645.0, 40666.0, 40739.0, 40777.0, 40795.0, 40830.0, 40880.0, 40945.0, 40985.0, 41026.0, 41095.0, 41130.0, 41175.0, 41219.0, 41362.0, 41452.0, 41503.0, 41527.0, 41603.0, 41628.0, 41675.0, 41724.0, 41746.0, 41794.0, 41836.0, 41861.0, 41879.0, 41896.0, 41962.0, 42025.0, 42086.0, 42135.0, 42185.0, 42230.0, 42259.0, 42319.0, 42384.0, 42580.0, 42719.0, 42796.0, 42874.0, 42900.0, 42952.0, 43023.0, 43074.0, 43125.0, 43144.0, 43225.0, 43298.0, 43322.0, 43382.0, 43407.0, 43452.0, 43516.0, 43565.0, 43599.0, 43656.0, 43730.0, 43816.0, 43862.0, 43891.0, 43940.0, 43962.0, 43988.0, 44065.0, 44106.0, 44181.0, 44224.0, 44302.0, 44398.0, 44436.0, 44478.0, 44552.0, 44596.0, 44649.0, 44674.0, 44752.0, 44775.0, 44811.0, 44842.0, 44873.0, 44932.0, 44960.0, 44980.0, 45046.0, 45073.0, 45092.0, 45153.0, 45175.0, 45268.0, 45281.0, 45367.0, 45434.0, 45478.0, 45528.0, 45652.0, 45733.0, 45761.0, 45846.0, 45908.0, 45976.0, 45996.0, 46057.0, 46139.0, 46169.0, 46187.0, 46241.0, 46303.0, 46362.0, 46409.0, 46457.0, 46498.0, 46628.0, 46659.0, 46681.0, 46749.0, 46768.0, 46921.0, 46990.0, 47056.0, 47069.0, 47110.0, 47186.0, 47233.0, 47267.0, 47301.0, 47359.0, 47381.0, 47399.0 ], [ 47394.0, 74.0, 130.0, 202.0, 243.0, 295.0, 329.0, 381.0, 449.0, 494.0, 516.0, 552.0, 587.0, 614.0, 662.0, 703.0, 724.0, 750.0, 793.0, 834.0, 871.0, 915.0, 999.0, 1048.0, 1084.0, 1114.0, 1158.0, 1185.0, 1236.0, 1255.0, 1317.0, 1354.0, 1390.0, 1421.0, 1484.0, 1511.0, 1570.0, 1596.0, 1621.0, 1679.0, 1718.0, 1799.0, 1860.0, 1888.0, 1921.0, 1993.0, 2030.0, 2083.0, 2108.0, 2143.0, 2185.0, 2271.0, 2320.0, 2349.0, 2390.0, 2421.0, 2467.0, 2527.0, 2545.0, 2581.0, 2606.0, 2684.0, 2725.0, 2756.0, 2785.0, 2823.0, 2843.0, 2923.0, 2965.0, 2990.0, 3038.0, 3081.0, 3135.0, 3194.0, 3212.0, 3296.0, 3314.0, 3381.0, 3396.0, 3481.0, 3572.0, 3620.0, 3663.0, 3706.0, 3731.0, 3832.0, 3883.0, 3939.0, 4009.0, 4091.0, 4125.0, 4167.0, 4197.0, 4242.0, 4284.0, 4312.0, 4350.0, 4373.0, 4404.0, 4452.0, 4498.0, 4574.0, 4621.0, 4684.0, 4735.0, 4809.0, 4833.0, 4873.0, 4918.0, 4938.0, 5010.0, 5059.0, 5123.0, 5149.0, 5207.0, 5246.0, 5285.0, 5322.0, 5372.0, 5427.0, 5454.0, 5507.0, 5557.0, 5593.0, 5614.0, 5668.0, 5687.0, 5759.0, 5789.0, 5834.0, 5883.0, 5934.0, 5983.0, 5994.0, 6064.0, 6099.0, 6149.0, 6162.0, 6216.0, 6263.0, 6306.0, 6323.0, 6374.0, 6445.0, 6461.0, 6531.0, 6585.0, 6634.0, 6657.0, 6720.0, 6758.0, 6827.0, 6892.0, 6941.0, 6991.0, 7026.0, 7098.0, 7135.0, 7200.0, 7244.0, 7271.0, 7323.0, 7355.0, 7400.0, 7436.0, 7468.0, 7527.0, 7573.0, 7627.0, 7674.0, 7725.0, 7758.0, 7827.0, 7859.0, 7887.0, 7961.0, 7998.0, 8037.0, 8093.0, 8151.0, 8183.0, 8256.0, 8275.0, 8371.0, 8455.0, 8490.0, 8557.0, 8595.0, 8659.0, 8684.0, 8760.0, 8800.0, 8851.0, 8874.0, 8936.0, 8970.0, 9037.0, 9066.0, 9090.0, 9146.0, 9183.0, 9213.0, 9239.0, 9320.0, 9372.0, 9422.0, 9452.0, 9467.0, 9537.0, 9564.0, 9596.0, 9633.0, 9718.0, 9778.0, 9822.0, 9867.0, 9919.0, 9950.0, 9990.0, 10038.0, 10085.0, 10155.0, 10192.0, 10213.0, 10233.0, 10292.0, 10328.0, 10379.0, 10428.0, 10453.0, 10501.0, 10546.0, 10609.0, 10626.0, 10682.0, 10719.0, 10755.0, 10834.0, 10874.0, 10910.0, 10986.0, 11043.0, 11087.0, 11117.0, 11141.0, 11153.0, 11223.0, 11277.0, 11318.0, 11349.0, 11379.0, 11413.0, 11525.0, 11566.0, 11620.0, 11659.0, 11720.0, 11763.0, 11846.0, 11875.0, 11932.0, 11969.0, 12048.0, 12098.0, 12169.0, 12220.0, 12268.0, 12311.0, 12367.0, 12412.0, 12441.0, 12487.0, 12515.0, 12536.0, 12615.0, 12670.0, 12718.0, 12746.0, 12789.0, 12812.0, 12858.0, 12919.0, 12963.0, 13011.0, 13057.0, 13106.0, 13126.0, 13162.0, 13217.0, 13279.0, 13308.0, 13336.0, 13388.0, 13455.0, 13474.0, 13527.0, 13574.0, 13611.0, 13653.0, 13686.0, 13716.0, 13749.0, 13812.0, 13862.0, 13929.0, 13961.0, 14001.0, 14036.0, 14074.0, 14093.0, 14134.0, 14164.0, 14236.0, 14261.0, 14316.0, 14365.0, 14423.0, 14458.0, 14494.0, 14549.0, 14576.0, 14618.0, 14640.0, 14725.0, 14801.0, 14822.0, 14887.0, 14915.0, 14937.0, 14978.0, 15018.0, 15092.0, 15128.0, 15177.0, 15205.0, 15246.0, 15315.0, 15344.0, 15364.0, 15411.0, 15460.0, 15486.0, 15546.0, 15567.0, 15640.0, 15669.0, 15718.0, 15761.0, 15805.0, 15854.0, 15896.0, 15940.0, 16012.0, 16029.0, 16083.0, 16102.0, 16149.0, 16169.0, 16229.0, 16261.0, 16286.0, 16319.0, 16389.0, 16409.0, 16426.0, 16480.0, 16510.0, 16558.0, 16579.0, 16635.0, 16686.0, 16707.0, 16788.0, 16819.0, 16862.0, 16890.0, 16967.0, 17003.0, 17039.0, 17117.0, 17142.0, 17175.0, 17226.0, 17263.0, 17294.0, 17351.0, 17385.0, 17408.0, 17464.0, 17520.0, 17545.0, 17621.0, 17671.0, 17688.0, 17745.0, 17761.0, 17788.0, 17848.0, 17897.0, 17935.0, 17949.0, 18001.0, 18023.0, 18099.0, 18161.0, 18227.0, 18289.0, 18351.0, 18376.0, 18416.0, 18448.0, 18525.0, 18587.0, 18649.0, 18687.0, 18735.0, 18775.0, 18821.0, 18867.0, 18900.0, 18962.0, 19038.0, 19061.0, 19119.0, 19152.0, 19188.0, 19238.0, 19282.0, 19312.0, 19393.0, 19405.0, 19468.0, 19498.0, 19541.0, 19583.0, 19607.0, 19641.0, 19686.0, 19747.0, 19792.0, 19895.0, 19978.0, 20002.0, 20048.0, 20091.0, 20130.0, 20165.0, 20213.0, 20287.0, 20374.0, 20426.0, 20482.0, 20535.0, 20588.0, 20664.0, 20710.0, 20738.0, 20792.0, 20831.0, 20913.0, 20951.0, 20986.0, 21035.0, 21074.0, 21099.0, 21136.0, 21152.0, 21191.0, 21270.0, 21305.0, 21377.0, 21422.0, 21471.0, 21540.0, 21583.0, 21613.0, 21665.0, 21722.0, 21761.0, 21796.0, 21889.0, 21925.0, 21965.0, 22023.0, 22101.0, 22158.0, 22200.0, 22259.0, 22283.0, 22331.0, 22354.0, 22400.0, 22457.0, 22487.0, 22537.0, 22576.0, 22622.0, 22702.0, 22753.0, 22794.0, 22824.0, 22859.0, 22886.0, 22925.0, 22967.0, 23001.0, 23039.0, 23103.0, 23144.0, 23171.0, 23228.0, 23253.0, 23280.0, 23310.0, 23335.0, 23368.0, 23401.0, 23442.0, 23539.0, 23554.0, 23614.0, 23656.0, 23731.0, 23801.0, 23850.0, 23890.0, 23935.0, 23962.0, 24020.0, 24078.0, 24114.0, 24142.0, 24175.0, 24197.0, 24251.0, 24274.0, 24313.0, 24347.0, 24392.0, 24428.0, 24471.0, 24531.0, 24560.0, 24575.0, 24606.0, 24624.0, 24682.0, 24764.0, 24789.0, 24824.0, 24883.0, 24897.0, 24953.0, 24996.0, 25054.0, 25106.0, 25155.0, 25184.0, 25235.0, 25289.0, 25317.0, 25369.0, 25415.0, 25442.0, 25493.0, 25524.0, 25559.0, 25585.0, 25612.0, 25676.0, 25705.0, 25750.0, 25807.0, 25853.0, 25905.0, 25932.0, 26024.0, 26077.0, 26108.0, 26180.0, 26214.0, 26223.0, 26287.0, 26333.0, 26391.0, 26430.0, 26468.0, 26493.0, 26527.0, 26617.0, 26665.0, 26692.0, 26754.0, 26799.0, 26845.0, 26873.0, 26892.0, 26935.0, 26972.0, 27040.0, 27088.0, 27106.0, 27161.0, 27192.0, 27227.0, 27273.0, 27297.0, 27341.0, 27363.0, 27425.0, 27472.0, 27497.0, 27570.0, 27626.0, 27685.0, 27747.0, 27798.0, 27831.0, 27869.0, 27937.0, 27954.0, 27997.0, 28022.0, 28058.0, 28108.0, 28177.0, 28248.0, 28265.0, 28310.0, 28341.0, 28384.0, 28414.0, 28446.0, 28500.0, 28542.0, 28579.0, 28633.0, 28686.0, 28728.0, 28755.0, 28798.0, 28820.0, 28890.0, 28926.0, 28985.0, 29023.0, 29061.0, 29133.0, 29171.0, 29183.0, 29213.0, 29238.0, 29311.0, 29345.0, 29380.0, 29415.0, 29483.0, 29538.0, 29574.0, 29599.0, 29643.0, 29695.0, 29705.0, 29751.0, 29792.0, 29827.0, 29877.0, 29904.0, 29985.0, 30016.0, 30066.0, 30118.0, 30137.0, 30215.0, 30246.0, 30315.0, 30363.0, 30397.0, 30411.0, 30434.0, 30477.0, 30545.0, 30599.0, 30619.0, 30648.0, 30680.0, 30741.0, 30775.0, 30806.0, 30860.0, 30915.0, 30978.0, 3101\u001b[0m\n",
      "\u001b[34m9.0, 31049.0, 31061.0, 31139.0, 31188.0, 31222.0, 31262.0, 31281.0, 31335.0, 31364.0, 31420.0, 31443.0, 31485.0, 31526.0, 31572.0, 31590.0, 31661.0, 31693.0, 31730.0, 31778.0, 31828.0, 31894.0, 31919.0, 32001.0, 32039.0, 32080.0, 32115.0, 32162.0, 32188.0, 32222.0, 32271.0, 32329.0, 32360.0, 32460.0, 32492.0, 32524.0, 32560.0, 32593.0, 32642.0, 32682.0, 32768.0, 32816.0, 32848.0, 32917.0, 32952.0, 33012.0, 33047.0, 33096.0, 33159.0, 33185.0, 33232.0, 33254.0, 33293.0, 33339.0, 33410.0, 33454.0, 33498.0, 33522.0, 33588.0, 33665.0, 33680.0, 33724.0, 33802.0, 33840.0, 33901.0, 33936.0, 33979.0, 34028.0, 34073.0, 34138.0, 34182.0, 34210.0, 34260.0, 34289.0, 34336.0, 34366.0, 34415.0, 34423.0, 34461.0, 34493.0, 34516.0, 34587.0, 34628.0, 34658.0, 34689.0, 34773.0, 34797.0, 34839.0, 34890.0, 34946.0, 34993.0, 35032.0, 35064.0, 35102.0, 35138.0, 35179.0, 35221.0, 35269.0, 35296.0, 35364.0, 35398.0, 35455.0, 35495.0, 35516.0, 35547.0, 35611.0, 35644.0, 35723.0, 35807.0, 35845.0, 35873.0, 35895.0, 35935.0, 35959.0, 36045.0, 36085.0, 36103.0, 36157.0, 36185.0, 36246.0, 36266.0, 36308.0, 36330.0, 36384.0, 36408.0, 36482.0, 36524.0, 36593.0, 36655.0, 36685.0, 36733.0, 36781.0, 36856.0, 36870.0, 36919.0, 36977.0, 37010.0, 37039.0, 37114.0, 37144.0, 37235.0, 37257.0, 37298.0, 37341.0, 37389.0, 37427.0, 37486.0, 37552.0, 37605.0, 37656.0, 37699.0, 37730.0, 37774.0, 37830.0, 37850.0, 37880.0, 37913.0, 37946.0, 37977.0, 38016.0, 38081.0, 38135.0, 38160.0, 38236.0, 38293.0, 38336.0, 38393.0, 38425.0, 38483.0, 38498.0, 38552.0, 38610.0, 38661.0, 38685.0, 38754.0, 38792.0, 38834.0, 38847.0, 38887.0, 38978.0, 39015.0, 39068.0, 39109.0, 39151.0, 39165.0, 39198.0, 39235.0, 39332.0, 39362.0, 39432.0, 39466.0, 39574.0, 39599.0, 39652.0, 39715.0, 39753.0, 39830.0, 39888.0, 39960.0, 39976.0, 40018.0, 40049.0, 40108.0, 40156.0, 40194.0, 40252.0, 40294.0, 40320.0, 40350.0, 40423.0, 40476.0, 40516.0, 40568.0, 40607.0, 40660.0, 40690.0, 40706.0, 40757.0, 40786.0, 40836.0, 40896.0, 40958.0, 41011.0, 41028.0, 41084.0, 41119.0, 41141.0, 41198.0, 41232.0, 41282.0, 41320.0, 41356.0, 41430.0, 41476.0, 41530.0, 41556.0, 41598.0, 41637.0, 41678.0, 41718.0, 41775.0, 41824.0, 41891.0, 41916.0, 41948.0, 41994.0, 42036.0, 42060.0, 42159.0, 42188.0, 42242.0, 42269.0, 42329.0, 42362.0, 42421.0, 42437.0, 42460.0, 42540.0, 42577.0, 42601.0, 42619.0, 42691.0, 42769.0, 42784.0, 42813.0, 42837.0, 42903.0, 42968.0, 42989.0, 43022.0, 43060.0, 43096.0, 43183.0, 43229.0, 43248.0, 43297.0, 43341.0, 43392.0, 43427.0, 43460.0, 43497.0, 43549.0, 43577.0, 43666.0, 43704.0, 43724.0, 43787.0, 43819.0, 43842.0, 43867.0, 43907.0, 43939.0, 43997.0, 44070.0, 44081.0, 44124.0, 44164.0, 44184.0, 44225.0, 44264.0, 44307.0, 44326.0, 44370.0, 44411.0, 44453.0, 44492.0, 44538.0, 44575.0, 44610.0, 44663.0, 44717.0, 44751.0, 44818.0, 44835.0, 44899.0, 44974.0, 45002.0, 45060.0, 45097.0, 45147.0, 45183.0, 45198.0, 45259.0, 45279.0, 45329.0, 45365.0, 45438.0, 45450.0, 45501.0, 45541.0, 45566.0, 45596.0, 45646.0, 45707.0, 45730.0, 45780.0, 45827.0, 45871.0, 45916.0, 45946.0, 46007.0, 46041.0, 46066.0, 46084.0, 46115.0, 46178.0, 46213.0, 46265.0, 46326.0, 46404.0, 46440.0, 46495.0, 46516.0, 46579.0, 46589.0, 46631.0, 46657.0, 46709.0, 46740.0, 46780.0, 46840.0, 46871.0, 46939.0, 46968.0, 47005.0, 47042.0, 47068.0, 47127.0, 47176.0, 47218.0, 47296.0, 47396.0 ], [ 1.0, 67.0, 146.0, 190.0, 271.0, 322.0, 360.0, 456.0, 493.0, 570.0, 609.0, 661.0, 774.0, 847.0, 894.0, 989.0, 1043.0, 1123.0, 1207.0, 1269.0, 1330.0, 1397.0, 1464.0, 1527.0, 1563.0, 1636.0, 1732.0, 1795.0, 1834.0, 1912.0, 1989.0, 2046.0, 2092.0, 2197.0, 2238.0, 2290.0, 2358.0, 2423.0, 2489.0, 2589.0, 2642.0, 2690.0, 2728.0, 2788.0, 2837.0, 2902.0, 2945.0, 2998.0, 3096.0, 3145.0, 3199.0, 3240.0, 3344.0, 3378.0, 3464.0, 3512.0, 3588.0, 3627.0, 3697.0, 3760.0, 3814.0, 3866.0, 3932.0, 3981.0, 4038.0, 4090.0, 4158.0, 4244.0, 4306.0, 4381.0, 4411.0, 4532.0, 4567.0, 4641.0, 4695.0, 4761.0, 4828.0, 4871.0, 4941.0, 4994.0, 5064.0, 5103.0, 5169.0, 5200.0, 5248.0, 5305.0, 5361.0, 5412.0, 5488.0, 5537.0, 5611.0, 5683.0, 5752.0, 5802.0, 5860.0, 5904.0, 5999.0, 6057.0, 6117.0, 6168.0, 6237.0, 6313.0, 6370.0, 6441.0, 6471.0, 6503.0, 6571.0, 6623.0, 6723.0, 6798.0, 6859.0, 6923.0, 7006.0, 7047.0, 7142.0, 7194.0, 7269.0, 7306.0, 7394.0, 7462.0, 7532.0, 7585.0, 7613.0, 7714.0, 7783.0, 7846.0, 7883.0, 7945.0, 8009.0, 8079.0, 8138.0, 8176.0, 8261.0, 8311.0, 8366.0, 8415.0, 8484.0, 8547.0, 8586.0, 8630.0, 8692.0, 8753.0, 8830.0, 8889.0, 8998.0, 9033.0, 9138.0, 9170.0, 9251.0, 9299.0, 9364.0, 9448.0, 9492.0, 9561.0, 9605.0, 9670.0, 9717.0, 9776.0, 9843.0, 9894.0, 9955.0, 10017.0, 10131.0, 10178.0, 10263.0, 10339.0, 10400.0, 10472.0, 10544.0, 10590.0, 10678.0, 10721.0, 10771.0, 10838.0, 10915.0, 10962.0, 11013.0, 11090.0, 11167.0, 11226.0, 11285.0, 11362.0, 11412.0, 11470.0, 11506.0, 11530.0, 11609.0, 11680.0, 11742.0, 11776.0, 11820.0, 11912.0, 12017.0, 12070.0, 12106.0, 12164.0, 12238.0, 12314.0, 12384.0, 12426.0, 12482.0, 12553.0, 12612.0, 12650.0, 12714.0, 12810.0, 12860.0, 12950.0, 12981.0, 13070.0, 13144.0, 13191.0, 13256.0, 13317.0, 13426.0, 13503.0, 13575.0, 13619.0, 13683.0, 13744.0, 13815.0, 13883.0, 13928.0, 14000.0, 14068.0, 14097.0, 14179.0, 14240.0, 14314.0, 14380.0, 14451.0, 14497.0, 14545.0, 14616.0, 14674.0, 14706.0, 14765.0, 14848.0, 14885.0, 14960.0, 15057.0, 15081.0, 15150.0, 15215.0, 15268.0, 15337.0, 15430.0, 15485.0, 15537.0, 15601.0, 15700.0, 15756.0, 15787.0, 15820.0, 15897.0, 15967.0, 16013.0, 16101.0, 16145.0, 16208.0, 16281.0, 16326.0, 16399.0, 16441.0, 16502.0, 16584.0, 16657.0, 16696.0, 16746.0, 16822.0, 16868.0, 16920.0, 17015.0, 17051.0, 17133.0, 17220.0, 17257.0, 17303.0, 17402.0, 17452.0, 17548.0, 17605.0, 17673.0, 17731.0, 17767.0, 17834.0, 17894.0, 17937.0, 17998.0, 18057.0, 18140.0, 18210.0, 18249.0, 18320.0, 18410.0, 18446.0, 18535.0, 18589.0, 18666.0, 18720.0, 18796.0, 18832.0, 18871.0, 18928.0, 18979.0, 19022.0, 19075.0, 19151.0, 19201.0, 19272.0, 19348.0, 19409.0, 19456.0, 19535.0, 19571.0, 19647.0, 19722.0, 19798.0, 19855.0, 19889.0, 19948.0, 19991.0, 20086.0, 20161.0, 20179.0, 20230.0, 20284.0, 20312.0, 20391.0, 20441.0, 20501.0, 20554.0, 20647.0, 20701.0, 20780.0, 20812.0, 20835.0, 20901.0, 20982.0, 21041.0, 21092.0, 21141.0, 21193.0, 21257.0, 21323.0, 21369.0, 21446.0, 21501.0, 21548.0, 21600.0, 21666.0, 21717.0, 21765.0, 21845.0, 21892.0, 21984.0, 22037.0, 22083.0, 22162.0, 22235.0, 22272.0, 22336.0, 22384.0, 22435.0, 22501.0, 22549.0, 22605.0, 22654.0, 22697.0, 22793.0, 22856.0, 22909.0, 22964.0, 23028.0, 23126.0, 23182.0, 23232.0, 23290.0, 23359.0, 23415.0, 23469.0, 23502.0, 23545.0, 23592.0, 23648.0, 23697.0, 23770.0, 23826.0, 23872.0, 23904.0, 23997.0, 24037.0, 24129.0, 24174.0, 24249.0, 24334.0, 24366.0, 24453.0, 24492.0, 24540.0, 24638.0, 24695.0, 24744.0, 24783.0, 24838.0, 24896.0, 24935.0, 25030.0, 25112.0, 25143.0, 25198.0, 25237.0, 25323.0, 25357.0, 25425.0, 25455.0, 25535.0, 25573.0, 25637.0, 25709.0, 25752.0, 25808.0, 25858.0, 25946.0, 25996.0, 26052.0, 26105.0, 26174.0, 26236.0, 26293.0, 26376.0, 26436.0, 26479.0, 26556.0, 26625.0, 26676.0, 26745.0, 26803.0, 26891.0, 26930.0, 27008.0, 27060.0, 27129.0, 27187.0, 27219.0, 27307.0, 27342.0, 27420.0, 27471.0, 27527.0, 27615.0, 27641.0, 27709.0, 27765.0, 27811.0, 27868.0, 27939.0, 28032.0, 28071.0, 28167.0, 28193.0, 28284.0, 28355.0, 28413.0, 28467.0, 28536.0, 28601.0, 28658.0, 28714.0, 28761.0, 28812.0, 28873.0, 28933.0, 28955.0, 29040.0, 29124.0, 29217.0, 29247.0, 29323.0, 29375.0, 29434.0, 29471.0, 29536.0, 29609.0, 29670.0, 29762.0, 29825.0, 29909.0, 29944.0, 30026.0, 30097.0, 30145.0, 30211.0, 30279.0, 30352.0, 30416.0, 30460.0, 30514.0, 30596.0, 30658.0, 30704.0, 30751.0, 30803.0, 30846.0, 30921.0, 30986.0, 31027.0, 31094.0, 31170.0, 31210.0, 31264.0, 31348.0, 31437.0, 31535.0, 31585.0, 31643.0, 31697.0, 31741.0, 31782.0, 31830.0, 31899.0, 31917.0, 31994.0, 32031.0, 32126.0, 32148.0, 32219.0, 32256.0, 32325.0, 32410.0, 32447.0, 32503.0, 32591.0, 32670.0, 32724.0, 32785.0, 32851.0, 32903.0, 32976.0, 33029.0, 33061.0, 33131.0, 33179.0, 33249.0, 33308.0, 33345.0, 33415.0, 33474.0, 33533.0, 33591.0, 33631.0, 33687.0, 33752.0, 33810.0, 33889.0, 33954.0, 34023.0, 34044.0, 34117.0, 34170.0, 34246.0, 34306.0, 34358.0, 34417.0, 34468.0, 34533.0, 34619.0, 34641.0, 34733.0, 34790.0, 34834.0, 34894.0, 34938.0, 35028.0, 35074.0, 35103.0, 35188.0, 35211.0, 35271.0, 35337.0, 35425.0, 35454.0, 35522.0, 35560.0, 35637.0, 35701.0, 35746.0, 35825.0, 35884.0, 35928.0, 36006.0, 36041.0, 36093.0, 36167.0, 36218.0, 36279.0, 36365.0, 36441.0, 36497.0, 36558.0, 36639.0, 36693.0, 36727.0, 36809.0, 36834.0, 36899.0, 36964.0, 37030.0, 37097.0, 37160.0, 37231.0, 37265.0, 37321.0, 37388.0, 37463.0, 37487.0, 37531.0, 37617.0, 37662.0, 37728.0, 37779.0, 37871.0, 37905.0, 38000.0, 38059.0, 38150.0, 38200.0, 38221.0, 38283.0, 38313.0, 38355.0, 38422.0, 38497.0, 38559.0, 38603.0, 38639.0, 38726.0, 38768.0, 38823.0, 38886.0, 38933.0, 38964.0, 39006.0, 39073.0, 39104.0, 39249.0, 39270.0, 39318.0, 39371.0, 39442.0, 39479.0, 39532.0, 39606.0, 39674.0, 39709.0, 39749.0, 39813.0, 39881.0, 39971.0, 40013.0, 40077.0, 40143.0, 40193.0, 40274.0, 40333.0, 40381.0, 40433.0, 40483.0, 40543.0, 40642.0, 40689.0, 40797.0, 40817.0, 40888.0, 40973.0, 41039.0, 41107.0, 41173.0, 41225.0, 41263.0, 41315.0, 41402.0, 41438.0, 41480.0, 41549.0, 41614.0, 41655.0, 41730.0, 41796.0, 41862.0, 41927.0, 41983.0, 42019.0, 42085.0, 42150.0, 42194.0, 42255.0, 42301.0, 42345.0, 42408.0, 42463.0, 42536.0, 42570.0, 42651.0, 42704.0, 42767.0, 42858.0, 42917.0, 42973.0, 43025.0, 43088.0, 43168.0, 43207.0, 43272.0, 43325.0, 43398.0, 43459.0, 43539.0, 43610.0, 43674.0, 43763.0, 43836.0, 43899.0, 43952.0, 43975.0, 44056.0, 44154.0, 44220.0, 44298.0, 44377.0, 44432.0, 44488.0, 44540.0, 44581.0, 44650.0, 44680.0, 44764.0, 44841.0, 44869.0, 44949.0, 44998.0, 45071.0, 45130.0, 45211.0, 45264.0, 45343.0, 45422.0, 45479.0, 45520.0, 45577.0, 45638.0, 45702.0, 45757.0, 45826.0, 45902.0, 45962.0, 46071.0, 46148.0, 46175.0, 46235.0, 46305.0, 46367.0, 46414.0, 46455.0, 46526.0, 46574.0, 46604.0, 46697.0, 46764.0, 46819.0, 46870.0, 46910.0, 46997.0, 47046.0, 47102.0, 47179.0, 47236.0, 47283.0, 47339.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_years\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 30.99153206364513,\n",
      "      \"sum\" : 1028423.0,\n",
      "      \"std_dev\" : 31.352060253695154,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 112.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 11.2,\n",
      "            \"count\" : 14672.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.2,\n",
      "            \"upper_bound\" : 22.4,\n",
      "            \"count\" : 3776.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 22.4,\n",
      "            \"upper_bound\" : 33.6,\n",
      "            \"count\" : 1860.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 33.6,\n",
      "            \"upper_bound\" : 44.8,\n",
      "            \"count\" : 1612.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 44.8,\n",
      "            \"upper_bound\" : 56.0,\n",
      "            \"count\" : 1784.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 56.0,\n",
      "            \"upper_bound\" : 67.2,\n",
      "            \"count\" : 2784.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 67.2,\n",
      "            \"upper_bound\" : 78.4,\n",
      "            \"count\" : 2884.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 78.4,\n",
      "            \"upper_bound\" : 89.6,\n",
      "            \"count\" : 2732.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 89.6,\n",
      "            \"upper_bound\" : 100.8,\n",
      "            \"count\" : 1064.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 100.8,\n",
      "            \"upper_bound\" : 112.0,\n",
      "            \"count\" : 16.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 94.0, 94.0, 95.0, 96.0, 96.0, 98.0, 99.0, 100.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 94.0, 94.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 96.0, 97.0, 98.0, 98.0, 99.0, 100.0, 103.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0\u001b[0m\n",
      "\u001b[34m, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 94.0, 94.0, 94.0, 95.0, 95.0, 95.0, 96.0, 96.0, 97.0, 98.0, 98.0, 99.0, 99.0, 100.0, 112.0 ], [ 102.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 94.0, 94.0, 94.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 96.0, 97.0, 97.0, 98.0, 98.0, 100.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 94.0, 94.0, 95.0, 95.0, 95.0, 96.0, 96.0, 97.0, 98.0, 99.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"insurance_grp\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 42.47495781099325,\n",
      "      \"sum\" : 1409489.0,\n",
      "      \"std_dev\" : 28.883565258300823,\n",
      "      \"min\" : 2.0,\n",
      "      \"max\" : 101.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 2.0,\n",
      "            \"upper_bound\" : 11.9,\n",
      "            \"count\" : 5508.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.9,\n",
      "            \"upper_bound\" : 21.8,\n",
      "            \"count\" : 6424.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 21.8,\n",
      "            \"upper_bound\" : 31.7,\n",
      "            \"count\" : 2540.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 31.7,\n",
      "            \"upper_bound\" : 41.6,\n",
      "            \"count\" : 4584.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 41.6,\n",
      "            \"upper_bound\" : 51.5,\n",
      "            \"count\" : 2328.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 51.5,\n",
      "            \"upper_bound\" : 61.4,\n",
      "            \"count\" : 2420.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 61.4,\n",
      "            \"upper_bound\" : 71.3,\n",
      "            \"count\" : 2236.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 71.3,\n",
      "            \"upper_bound\" : 81.2,\n",
      "            \"count\" : 2304.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 81.2,\n",
      "            \"upper_bound\" : 91.1,\n",
      "            \"count\" : 2396.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 91.1,\n",
      "            \"upper_bound\" : 101.0,\n",
      "            \"count\" : 2444.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 29.0, 29.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 71.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 85.0, 86.0, 87.0, 87.0, 87.0, 87.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 97.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0, 101.0, 101.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 71.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 85.0, 86.0, 87.0, 87.0, 87.0, 87.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 97.0, 97.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0, 101.0, 101.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.\u001b[0m\n",
      "\u001b[34m0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 75.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 85.0, 86.0, 86.0, 87.0, 87.0, 87.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 94.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 97.0, 97.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0, 101.0, 101.0 ], [ 101.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 71.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 75.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 85.0, 87.0, 87.0, 87.0, 87.0, 87.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 94.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 97.0, 97.0, 99.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0, 101.0, 101.0 ], [ 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 27.0, 28.0, 28.0, 28.0, 29.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 85.0, 86.0, 87.0, 87.0, 87.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 97.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"no_fam_member\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.4666706846673097,\n",
      "      \"sum\" : 48670.0,\n",
      "      \"std_dev\" : 1.165529937097626,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 8.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.7,\n",
      "            \"count\" : 28200.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7,\n",
      "            \"upper_bound\" : 2.4,\n",
      "            \"count\" : 416.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.4,\n",
      "            \"upper_bound\" : 3.1,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.1,\n",
      "            \"upper_bound\" : 3.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.8,\n",
      "            \"upper_bound\" : 4.5,\n",
      "            \"count\" : 3756.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.5,\n",
      "            \"upper_bound\" : 5.2,\n",
      "            \"count\" : 316.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.2,\n",
      "            \"upper_bound\" : 5.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.9,\n",
      "            \"upper_bound\" : 6.6,\n",
      "            \"count\" : 468.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.6,\n",
      "            \"upper_bound\" : 7.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.3,\n",
      "            \"upper_bound\" : 8.0,\n",
      "            \"count\" : 28.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0 ], [ 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \u001b[0m\n",
      "\u001b[34m1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0 ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"total_visit_count\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.9175506268081003,\n",
      "      \"sum\" : 30448.0,\n",
      "      \"std_dev\" : 0.9185819217439282,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 6.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 11552.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 15516.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.4,\n",
      "            \"count\" : 4432.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.4,\n",
      "            \"upper_bound\" : 3.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.0,\n",
      "            \"upper_bound\" : 3.6,\n",
      "            \"count\" : 892.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6,\n",
      "            \"upper_bound\" : 4.2,\n",
      "            \"count\" : 632.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.2,\n",
      "            \"upper_bound\" : 4.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.8,\n",
      "            \"upper_bound\" : 5.4,\n",
      "            \"count\" : 128.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.4,\n",
      "            \"upper_bound\" : 6.0,\n",
      "            \"count\" : 32.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0 ], [ 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 6.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"diagnosis_code_1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 58.958624638379945,\n",
      "      \"sum\" : 1956483.0,\n",
      "      \"std_dev\" : 5.78218371327896,\n",
      "      \"min\" : 41.0,\n",
      "      \"max\" : 74.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 41.0,\n",
      "            \"upper_bound\" : 44.3,\n",
      "            \"count\" : 1436.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 44.3,\n",
      "            \"upper_bound\" : 47.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 47.6,\n",
      "            \"upper_bound\" : 50.9,\n",
      "            \"count\" : 132.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 50.9,\n",
      "            \"upper_bound\" : 54.2,\n",
      "            \"count\" : 5084.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 54.2,\n",
      "            \"upper_bound\" : 57.5,\n",
      "            \"count\" : 2080.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 57.5,\n",
      "            \"upper_bound\" : 60.8,\n",
      "            \"count\" : 9112.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 60.8,\n",
      "            \"upper_bound\" : 64.1,\n",
      "            \"count\" : 13440.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 64.1,\n",
      "            \"upper_bound\" : 67.4,\n",
      "            \"count\" : 128.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 67.4,\n",
      "            \"upper_bound\" : 70.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 70.7,\n",
      "            \"upper_bound\" : 74.0,\n",
      "            \"count\" : 1772.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 48.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 66.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 48.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 66.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0,\n",
      " 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 66.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0 ], [ 74.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 48.0, 48.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 66.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 74.0, 74.0, 74.0, 74.0 ], [ 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 74.0, 74.0, 74.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"diagnosis_code_2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 23.10788331726133,\n",
      "      \"sum\" : 766812.0,\n",
      "      \"std_dev\" : 35.31140558750073,\n",
      "      \"min\" : -1.0,\n",
      "      \"max\" : 94.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : -1.0,\n",
      "            \"upper_bound\" : 8.5,\n",
      "            \"count\" : 21884.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 8.5,\n",
      "            \"upper_bound\" : 18.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 18.0,\n",
      "            \"upper_bound\" : 27.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 27.5,\n",
      "            \"upper_bound\" : 37.0,\n",
      "            \"count\" : 2076.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 37.0,\n",
      "            \"upper_bound\" : 46.5,\n",
      "            \"count\" : 64.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 46.5,\n",
      "            \"upper_bound\" : 56.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 56.0,\n",
      "            \"upper_bound\" : 65.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 65.5,\n",
      "            \"upper_bound\" : 75.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 75.0,\n",
      "            \"upper_bound\" : 84.5,\n",
      "            \"count\" : 7164.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 84.5,\n",
      "            \"upper_bound\" : 94.0,\n",
      "            \"count\" : 1996.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 38.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 92.0, 92.0, 93.0, 94.0, 94.0, 94.0, 94.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 92.0, 92.0, 94.0, 94.0, 94.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -\u001b[0m\n",
      "\u001b[34m1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 92.0, 92.0, 94.0, 94.0, 94.0, 94.0 ], [ 94.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 92.0, 92.0, 92.0, 92.0, 94.0, 94.0 ], [ -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 37.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 81.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 92.0, 92.0, 92.0, 93.0, 94.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"diagnosis_code_3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 19.6957268563163,\n",
      "      \"sum\" : 653583.0,\n",
      "      \"std_dev\" : 29.02333939384863,\n",
      "      \"min\" : -1.0,\n",
      "      \"max\" : 74.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : -1.0,\n",
      "            \"upper_bound\" : 6.5,\n",
      "            \"count\" : 21876.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.5,\n",
      "            \"upper_bound\" : 14.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 14.0,\n",
      "            \"upper_bound\" : 21.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 21.5,\n",
      "            \"upper_bound\" : 29.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 29.0,\n",
      "            \"upper_bound\" : 36.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 36.5,\n",
      "            \"upper_bound\" : 44.0,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 44.0,\n",
      "            \"upper_bound\" : 51.5,\n",
      "            \"count\" : 208.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 51.5,\n",
      "            \"upper_bound\" : 59.0,\n",
      "            \"count\" : 4700.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 59.0,\n",
      "            \"upper_bound\" : 66.5,\n",
      "            \"count\" : 4304.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 66.5,\n",
      "            \"upper_bound\" : 74.0,\n",
      "            \"count\" : 2088.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 55.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 66.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 73.0, 74.0, 74.0, 72.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 42.0, 42.0, 48.0, 48.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 66.0, 66.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 74.0, 74.0, 74.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
      " -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 48.0, 48.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 55.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 66.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 74.0, 74.0, 74.0, 74.0 ], [ 74.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 48.0, 48.0, 48.0, 48.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 55.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 66.0, 66.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 74.0, 74.0 ], [ -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 48.0, 48.0, 48.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 66.0, 66.0, 66.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 74.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2326.31843659595,\n",
      "      \"sum\" : 7.7196551E7,\n",
      "      \"std_dev\" : 1388.7626050011872,\n",
      "      \"min\" : 106.0,\n",
      "      \"max\" : 5044.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 106.0,\n",
      "            \"upper_bound\" : 599.8,\n",
      "            \"count\" : 1388.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 599.8,\n",
      "            \"upper_bound\" : 1093.6,\n",
      "            \"count\" : 4020.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1093.6,\n",
      "            \"upper_bound\" : 1587.4,\n",
      "            \"count\" : 4384.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1587.4,\n",
      "            \"upper_bound\" : 2081.2,\n",
      "            \"count\" : 12304.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2081.2,\n",
      "            \"upper_bound\" : 2575.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2575.0,\n",
      "            \"upper_bound\" : 3068.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3068.8,\n",
      "            \"upper_bound\" : 3562.6,\n",
      "            \"count\" : 1848.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3562.6,\n",
      "            \"upper_bound\" : 4056.4,\n",
      "            \"count\" : 916.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4056.4,\n",
      "            \"upper_bound\" : 4550.2,\n",
      "            \"count\" : 5940.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4550.2,\n",
      "            \"upper_bound\" : 5044.0,\n",
      "            \"count\" : 2384.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 115.0, 131.0, 214.0, 252.0, 268.0, 276.0, 281.0, 336.0, 342.0, 342.0, 342.0, 374.0, 374.0, 379.0, 380.0, 381.0, 393.0, 413.0, 413.0, 413.0, 417.0, 419.0, 428.0, 428.0, 431.0, 443.0, 463.0, 466.0, 466.0, 474.0, 478.0, 478.0, 480.0, 519.0, 519.0, 519.0, 546.0, 550.0, 557.0, 557.0, 566.0, 572.0, 572.0, 574.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 612.0, 613.0, 620.0, 620.0, 620.0, 638.0, 648.0, 648.0, 648.0, 648.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 652.0, 657.0, 661.0, 661.0, 661.0, 661.0, 661.0, 661.0, 661.0, 661.0, 670.0, 670.0, 670.0, 671.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 687.0, 687.0, 687.0, 687.0, 687.0, 689.0, 814.0, 827.0, 857.0, 884.0, 884.0, 884.0, 888.0, 899.0, 910.0, 910.0, 927.0, 949.0, 960.0, 974.0, 983.0, 983.0, 983.0, 1112.0, 1112.0, 1114.0, 1127.0, 1131.0, 1135.0, 1135.0, 1137.0, 1141.0, 1141.0, 1141.0, 1143.0, 1144.0, 1144.0, 1144.0, 1145.0, 1200.0, 1200.0, 1200.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1207.0, 1207.0, 1211.0, 1211.0, 1211.0, 1211.0, 1211.0, 1212.0, 1213.0, 1217.0, 1217.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1234.0, 1237.0, 1239.0, 1239.0, 1239.0, 1242.0, 1242.0, 1242.0, 1244.0, 1258.0, 1261.0, 1266.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1270.0, 1270.0, 1270.0, 1270.0, 1272.0, 1272.0, 1272.0, 1278.0, 1279.0, 1284.0, 1284.0, 1284.0, 1284.0, 1290.0, 1293.0, 1294.0, 1313.0, 1313.0, 1327.0, 1328.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1344.0, 1345.0, 1345.0, 1347.0, 1353.0, 1354.0, 1354.0, 1381.0, 1381.0, 1390.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1398.0, 1403.0, 1413.0, 1414.0, 1415.0, 1422.0, 1439.0, 1447.0, 1452.0, 1465.0, 1502.0, 1506.0, 1506.0, 1509.0, 1519.0, 1519.0, 1519.0, 1520.0, 1522.0, 1525.0, 1543.0, 1545.0, 1545.0, 1548.0, 1554.0, 1555.0, 1555.0, 1555.0, 1555.0, 1556.0, 1602.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1618.0, 1643.0, 1645.0, 1645.0, 1645.0, 1647.0, 1650.0, 1658.0, 1659.0, 1661.0, 1661.0, 1679.0, 1679.0, 1679.0, 1679.0, 1680.0, 1682.0, 1682.0, 1684.0, 1685.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1715.0, 1715.0, 1715.0, 1715.0, 1729.0, 1738.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1819.0, 1819.0, 1820.0, 1820.0, 1820.0, 1829.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1865.0, 1865.0, 1865.0, 1865.0, 1870.0, 1870.0, 1870.0, 1870.0, 1871.0, 1871.0, 1871.0, 1871.0, 1876.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1886.0, 1890.0, 1892.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1894.0, 1894.0, 1894.0, 1934.0, 3200.0, 3200.0, 3215.0, 3215.0, 3217.0, 3219.0, 3219.0, 3219.0, 3223.0, 3223.0, 3223.0, 3235.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3248.0, 3249.0, 3254.0, 3255.0, 3255.0, 3255.0, 3257.0, 3257.0, 3262.0, 3265.0, 3265.0, 3265.0, 3265.0, 3273.0, 3273.0, 3273.0, 3274.0, 3274.0, 3277.0, 3277.0, 3277.0, 3283.0, 3283.0, 3283.0, 3286.0, 3286.0, 3286.0, 3286.0, 3286.0, 3287.0, 3287.0, 3287.0, 3287.0, 3294.0, 3297.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 4004.0, 4004.0, 4010.0, 4011.0, 4014.0, 4014.0, 4014.0, 4016.0, 4025.0, 4025.0, 4030.0, 4050.0, 4050.0, 4050.0, 4055.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4063.0, 4071.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4080.0, 4080.0, 4080.0, 4082.0, 5005.0, 5010.0, 5016.0, 5016.0, 5016.0, 5019.0, 5020.0, 5021.0, 5021.0, 5022.0, 5022.0, 5023.0, 5023.0, 5024.0, 5024.0, 5024.0, 5024.0, 5025.0, 5025.0, 5025.0, 5030.0, 5031.0, 5031.0, 5033.0, 5034.0, 5034.0, 5036.0, 5036.0, 5036.0, 5036.0, 5037.0, 5037.0, 5037.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5043.0, 5041.0, 131.0, 214.0, 276.0, 276.0, 276.0, 281.0, 304.0, 336.0, 342.0, 342.0, 342.0, 367.0, 374.0, 374.0, 379.0, 379.0, 380.0, 380.0, 381.0, 393.0, 394.0, 413.0, 413.0, 413.0, 413.0, 428.0, 428.0, 428.0, 428.0, 428.0, 432.0, 438.0, 463.0, 463.0, 474.0, 478.0, 478.0, 478.0, 478.0, 519.0, 519.0, 519.0, 546.0, 550.0, 550.0, 557.0, 557.0, 566.0, 569.0, 572.0, 572.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 612.0, 612.0, 613.0, 618.0, 618.0, 628.0, 648.0, 648.0, 648.0, 648.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 652.0, 654.0, 661.0, 661.0, 661.0, 661.0, 661.0, 670.0, 670.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 687.0, 687.0, 687.0, 687.0, 698.0, 699.0, 827.0, 852.0, 883.0, 884.0, 884.0, 884.0, 885.0, 909.0, 910.0, 940.0, 956.0, 980.0, 983.0, 983.0, 1103.0, 1112.0, 1114.0, 1125.0, 1127.0, 1131.0, 1135.0, 1137.0, 1137.0, 1137.0, 1139.0, 1141.0, 1141.0, 1141.0, 1141.0, 1143.0, 1144.0, 1145.0, 1200.0, 1200.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1207.0, 1207.0, 1211.0, 1211.0, 1211.0, 1211.0, 1211.0, 1212.0, 1212.0, 1212.0, 1213.0, 1213.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1234.0, 1239.0, 1239.0, 1239.0, 1242.0, 1242.0, 1242.0, 1244.0, 1244.0, 1258.0, 1264.0, 1266.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1270.0, 1270.0, 1270.0, 1272.0, 1284.0, 1284.0, 1284.0, 1290.0, 1293.0, 1294.0, 1301.0, 1313.0, 1313.0, 1330.0, 1333.0, 1333.0, 1333.0, 1333.0, 1345.0, 1345.0, 1345.0, 1345.0, 1353.0, 1376.0, 1381.0, 1381.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1403.0, 1403.0, 1413.0, 1414.0, 1422.0, 1422.0, 1439.0, 1447.0, 1465.0, 1465.0, 1502.0, 1502.0, 1506.0, 1508.0, 1509.0, 1519.0, 1520.0, 1522.0, 1537.0, 1545.0, 1545.0, 1555.0, 1555.0, 1555.0, 1556.0, 1558.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1623.0, 1638.0, 1645.0, 1645.0, 1645.0, 1645.0, 1645.0, 1646.0, 1650.0, 1650.0, 1659.0, 1661.0, 1661.0, 1667.0, 1671.0, 1679.0, 1682.0, 1683.0, 1684.0, 1685.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1715.0, 1715.0, 1715.0, 1715.0, 1719.0, 1726.0, 1744.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1819.0, 1819.0, 1820.0, 1820.0, 1820.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1843.0, 1843.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1865.0, 1865.0, 1870.0, 1870.0, 1870.0, 1871.0, 1871.0, 1871.0, 1871.0, 1871.0, 1871.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1886.0, 1887.0, 1889.0, 1892.0, 1892.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1894.0, 1894.0, 1894.0, 1894.0, 1894.0, 1934.0, 3215.0, 3215.0, 3216.0, 3219.0, 3219.0, 3219.0, 3223.0, 3234.0, 3235.0, 3235.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3248.0, 3251.0, 3251.0, 3254.0, 3255.0, 3255.0, 3255.0, 3257.0, 3265.0, 3265.0, 3265.0, 3265.0, 3265.0, 3272.0, 3273.0, 3273.0, 3274.0, 3274.0, 3277.0, 3277.0, 3278.0, 3278.0, 3283.0, 3283.0, 3284.0, 3286.0, 3286.0, 3286.0, 3286.0, 3286.0, 3287.0, 3287.0, 3287.0, 3295.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 4004.0, 4010.0, 4010.0, 4014.0, 4014.0, 4014.0, 4025.0, 4025.0, 4025.0, 4030.0, 4047.0, 4050.0, 4055.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4058.0, 4067.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4\u001b[0m\n",
      "\u001b[34m076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4080.0, 4080.0, 4082.0, 5010.0, 5010.0, 5016.0, 5016.0, 5016.0, 5017.0, 5019.0, 5020.0, 5021.0, 5022.0, 5022.0, 5023.0, 5023.0, 5024.0, 5024.0, 5024.0, 5024.0, 5025.0, 5029.0, 5031.0, 5033.0, 5033.0, 5034.0, 5034.0, 5034.0, 5034.0, 5034.0, 5035.0, 5036.0, 5036.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5044.0, 115.0, 138.0, 214.0, 276.0, 276.0, 277.0, 281.0, 336.0, 342.0, 342.0, 374.0, 379.0, 380.0, 381.0, 408.0, 413.0, 413.0, 419.0, 428.0, 428.0, 428.0, 434.0, 464.0, 466.0, 478.0, 478.0, 480.0, 519.0, 550.0, 550.0, 550.0, 557.0, 557.0, 569.0, 572.0, 572.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 612.0, 612.0, 613.0, 617.0, 620.0, 638.0, 648.0, 648.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 652.0, 654.0, 661.0, 661.0, 661.0, 666.0, 670.0, 671.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 687.0, 687.0, 687.0, 689.0, 699.0, 827.0, 857.0, 884.0, 884.0, 884.0, 884.0, 893.0, 897.0, 910.0, 949.0, 960.0, 983.0, 983.0, 1103.0, 1112.0, 1114.0, 1127.0, 1130.0, 1133.0, 1137.0, 1137.0, 1137.0, 1141.0, 1141.0, 1141.0, 1143.0, 1144.0, 1144.0, 1200.0, 1200.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1211.0, 1211.0, 1211.0, 1212.0, 1213.0, 1215.0, 1217.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1239.0, 1239.0, 1239.0, 1242.0, 1242.0, 1242.0, 1244.0, 1244.0, 1261.0, 1266.0, 1266.0, 1267.0, 1267.0, 1267.0, 1270.0, 1270.0, 1270.0, 1272.0, 1279.0, 1283.0, 1284.0, 1284.0, 1293.0, 1293.0, 1294.0, 1301.0, 1313.0, 1326.0, 1327.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1344.0, 1345.0, 1345.0, 1345.0, 1347.0, 1354.0, 1381.0, 1394.0, 1394.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1399.0, 1411.0, 1413.0, 1414.0, 1439.0, 1452.0, 1464.0, 1465.0, 1502.0, 1502.0, 1506.0, 1512.0, 1519.0, 1519.0, 1519.0, 1519.0, 1522.0, 1543.0, 1545.0, 1545.0, 1554.0, 1555.0, 1555.0, 1556.0, 1604.0, 1615.0, 1615.0, 1615.0, 1615.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1638.0, 1645.0, 1645.0, 1645.0, 1647.0, 1658.0, 1661.0, 1661.0, 1671.0, 1679.0, 1679.0, 1679.0, 1679.0, 1682.0, 1682.0, 1685.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1715.0, 1715.0, 1715.0, 1726.0, 1744.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1819.0, 1820.0, 1821.0, 1829.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1857.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1865.0, 1870.0, 1870.0, 1871.0, 1871.0, 1871.0, 1871.0, 1876.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1889.0, 1890.0, 1892.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1894.0, 1894.0, 1934.0, 3200.0, 3215.0, 3216.0, 3219.0, 3223.0, 3235.0, 3235.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3249.0, 3251.0, 3254.0, 3255.0, 3256.0, 3259.0, 3265.0, 3272.0, 3273.0, 3273.0, 3273.0, 3274.0, 3274.0, 3274.0, 3277.0, 3277.0, 3277.0, 3278.0, 3283.0, 3283.0, 3284.0, 3286.0, 3286.0, 3286.0, 3287.0, 3287.0, 3287.0, 3287.0, 3293.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 4004.0, 4014.0, 4014.0, 4014.0, 4016.0, 4025.0, 4025.0, 4025.0, 4050.0, 4050.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4071.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4075.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4079.0, 4079.0, 4080.0, 4080.0, 4080.0, 5005.0, 5011.0, 5016.0, 5016.0, 5019.0, 5021.0, 5021.0, 5022.0, 5022.0, 5023.0, 5024.0, 5024.0, 5024.0, 5024.0, 5024.0, 5024.0, 5025.0, 5025.0, 5031.0, 5031.0, 5033.0, 5034.0, 5036.0, 5036.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5041.0, 5041.0, 5041.0, 5043.0, 5044.0 ], [ 5044.0, 115.0, 214.0, 264.0, 276.0, 276.0, 276.0, 281.0, 312.0, 342.0, 342.0, 374.0, 374.0, 374.0, 379.0, 380.0, 381.0, 393.0, 413.0, 413.0, 413.0, 417.0, 417.0, 428.0, 431.0, 438.0, 452.0, 464.0, 466.0, 478.0, 478.0, 480.0, 480.0, 519.0, 546.0, 550.0, 550.0, 550.0, 550.0, 557.0, 557.0, 569.0, 572.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 612.0, 612.0, 613.0, 617.0, 618.0, 620.0, 628.0, 648.0, 648.0, 648.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 653.0, 654.0, 661.0, 661.0, 661.0, 661.0, 661.0, 661.0, 667.0, 670.0, 671.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 687.0, 687.0, 687.0, 693.0, 827.0, 827.0, 857.0, 884.0, 884.0, 884.0, 884.0, 886.0, 893.0, 910.0, 949.0, 952.0, 960.0, 1062.0, 1107.0, 1112.0, 1112.0, 1114.0, 1123.0, 1123.0, 1127.0, 1130.0, 1135.0, 1137.0, 1137.0, 1141.0, 1141.0, 1141.0, 1141.0, 1143.0, 1144.0, 1144.0, 1200.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1208.0, 1211.0, 1211.0, 1211.0, 1212.0, 1212.0, 1213.0, 1213.0, 1213.0, 1215.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1239.0, 1239.0, 1239.0, 1242.0, 1242.0, 1242.0, 1244.0, 1244.0, 1258.0, 1261.0, 1266.0, 1266.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1270.0, 1270.0, 1270.0, 1272.0, 1278.0, 1279.0, 1282.0, 1284.0, 1284.0, 1284.0, 1284.0, 1293.0, 1294.0, 1313.0, 1328.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1333.0, 1345.0, 1345.0, 1347.0, 1353.0, 1354.0, 1376.0, 1381.0, 1392.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1401.0, 1403.0, 1411.0, 1413.0, 1414.0, 1422.0, 1439.0, 1447.0, 1465.0, 1465.0, 1502.0, 1502.0, 1506.0, 1508.0, 1513.0, 1513.0, 1519.0, 1522.0, 1522.0, 1543.0, 1545.0, 1545.0, 1545.0, 1549.0, 1555.0, 1555.0, 1555.0, 1555.0, 1558.0, 1607.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1623.0, 1644.0, 1645.0, 1645.0, 1645.0, 1646.0, 1647.0, 1658.0, 1660.0, 1661.0, 1669.0, 1679.0, 1679.0, 1679.0, 1679.0, 1682.0, 1684.0, 1685.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1701.0, 1715.0, 1715.0, 1726.0, 1738.0, 1738.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1808.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1819.0, 1819.0, 1819.0, 1820.0, 1820.0, 1820.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1843.0, 1843.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1865.0, 1866.0, 1870.0, 1870.0, 1870.0, 1870.0, 1871.0, 1871.0, 1871.0, 1871.0, 1871.0, 1871.0, 1871.0, 1876.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1889.0, 1890.0, 1892.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1894.0, 1894.0, 1894.0, 1934.0, 1934.0, 3200.0, 3215.0, 3216.0, 3219.0, 3219.0, 3223.0, 3223.0, 3235.0, 3235.0, 3246.0, 3246.0, 3246.0, 3246.0, 3246.0, 3249.0, 3251.0, 3254.0, 3255.0, 3255.0, 3257.0, 3259.0, 3265.0, 3265.0, 3272.0, 3273.0, 3273.0, 3273.0, 3273.0, 3274.0, 3274.0, 3277.0, 3277.0, 3277.0, 3278.0, 3278.0, 3283.0, 3283.0, 3286.0, 3286.0, 3286.0, 3286.0, 3286.0, 3287.0, 3287.0, 3287.0, 3287.0, 3287.0, 3295.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 4008.0, 4010.0, 4014.0, 4014.0, 4014.0, 4025.0, 4025.0, 4025.0, 4030.0, 4047.0, 4050.0, 4050.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4058.0, 4068.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4080.0, 4080.0, 4080.0, 4080.0, 4080.0, 4082.0, 5011.0, 5016.0, 5016.0, 5016.0, 5019.0, 5021.0, 5022.0, 5022.0, 5023.0, 5024.0, 5024.0, 5024.0, 5024.0, 5024.0, 5025.0, 5025.0, 5029.0, 5031.0, 5031.0, 5033.0, 5034.0, 5034.0, 5035.0, 5036.0, 5036.0, 5036.0, 5037.0, 5037.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5041.0, 5044.0 ], [ 110.0, 132.0, 227.0, 276.0, 276.0, 276.0, 336.0, 342.0, 365.0, 374.0, 379.0, 380.0, 405.0, 413.0, 413.0, 428.0, 428.0, 428.0, 443.0, 463.0, 464.0, 474.0, 478.0, 480.0, 482.0, 519.0, 546.0, 550.0, 557.0, 557.0, 569.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 604.0, 609.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 611.0, 613.0, 620.0, 628.0, 648.0, 648.0\u001b[0m\n",
      "\u001b[34m, 648.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 649.0, 652.0, 654.0, 661.0, 661.0, 661.0, 661.0, 661.0, 670.0, 670.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 679.0, 687.0, 687.0, 687.0, 687.0, 689.0, 814.0, 837.0, 857.0, 884.0, 884.0, 884.0, 884.0, 884.0, 893.0, 910.0, 960.0, 983.0, 983.0, 1112.0, 1120.0, 1127.0, 1135.0, 1137.0, 1139.0, 1141.0, 1141.0, 1144.0, 1144.0, 1200.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1205.0, 1206.0, 1211.0, 1211.0, 1211.0, 1212.0, 1213.0, 1215.0, 1233.0, 1233.0, 1233.0, 1233.0, 1233.0, 1234.0, 1239.0, 1239.0, 1242.0, 1242.0, 1244.0, 1258.0, 1266.0, 1267.0, 1267.0, 1267.0, 1267.0, 1267.0, 1270.0, 1270.0, 1272.0, 1272.0, 1279.0, 1284.0, 1284.0, 1284.0, 1293.0, 1294.0, 1301.0, 1313.0, 1328.0, 1330.0, 1333.0, 1333.0, 1333.0, 1342.0, 1345.0, 1345.0, 1345.0, 1350.0, 1354.0, 1376.0, 1389.0, 1394.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1395.0, 1399.0, 1405.0, 1413.0, 1414.0, 1414.0, 1439.0, 1465.0, 1502.0, 1508.0, 1509.0, 1519.0, 1520.0, 1522.0, 1522.0, 1543.0, 1545.0, 1545.0, 1555.0, 1555.0, 1555.0, 1556.0, 1615.0, 1615.0, 1615.0, 1615.0, 1615.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1616.0, 1623.0, 1638.0, 1645.0, 1645.0, 1647.0, 1658.0, 1660.0, 1671.0, 1679.0, 1679.0, 1682.0, 1685.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1686.0, 1687.0, 1715.0, 1715.0, 1715.0, 1744.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1816.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1817.0, 1819.0, 1820.0, 1820.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1843.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1865.0, 1865.0, 1870.0, 1870.0, 1871.0, 1871.0, 1871.0, 1878.0, 1878.0, 1878.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1889.0, 1890.0, 1892.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1893.0, 1894.0, 1894.0, 1934.0, 3200.0, 3215.0, 3215.0, 3219.0, 3219.0, 3223.0, 3234.0, 3235.0, 3246.0, 3246.0, 3246.0, 3246.0, 3250.0, 3254.0, 3254.0, 3255.0, 3257.0, 3259.0, 3265.0, 3265.0, 3272.0, 3273.0, 3273.0, 3273.0, 3274.0, 3277.0, 3277.0, 3278.0, 3279.0, 3283.0, 3284.0, 3286.0, 3286.0, 3286.0, 3286.0, 3287.0, 3287.0, 3287.0, 3294.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 3299.0, 4004.0, 4010.0, 4014.0, 4014.0, 4016.0, 4025.0, 4041.0, 4050.0, 4051.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4058.0, 4068.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4078.0, 4078.0, 4078.0, 4078.0, 4079.0, 4080.0, 4080.0, 4081.0, 5005.0, 5011.0, 5016.0, 5016.0, 5019.0, 5021.0, 5022.0, 5022.0, 5024.0, 5024.0, 5024.0, 5025.0, 5025.0, 5025.0, 5030.0, 5031.0, 5033.0, 5034.0, 5036.0, 5036.0, 5036.0, 5037.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5040.0, 5041.0, 5041.0, 5041.0, 5041.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 520.7357160077146,\n",
      "      \"sum\" : 1.7280094E7,\n",
      "      \"std_dev\" : 1051.8829971191776,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 5043.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 504.3,\n",
      "            \"count\" : 24900.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 504.3,\n",
      "            \"upper_bound\" : 1008.6,\n",
      "            \"count\" : 1256.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1008.6,\n",
      "            \"upper_bound\" : 1512.9,\n",
      "            \"count\" : 508.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1512.9,\n",
      "            \"upper_bound\" : 2017.2,\n",
      "            \"count\" : 4788.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2017.2,\n",
      "            \"upper_bound\" : 2521.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2521.5,\n",
      "            \"upper_bound\" : 3025.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3025.8,\n",
      "            \"upper_bound\" : 3530.1,\n",
      "            \"count\" : 136.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3530.1,\n",
      "            \"upper_bound\" : 4034.4,\n",
      "            \"count\" : 120.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4034.4,\n",
      "            \"upper_bound\" : 4538.7,\n",
      "            \"count\" : 1384.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4538.7,\n",
      "            \"upper_bound\" : 5043.0,\n",
      "            \"count\" : 92.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 276.0, 342.0, 379.0, 380.0, 393.0, 413.0, 438.0, 474.0, 519.0, 550.0, 557.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 611.0, 613.0, 613.0, 617.0, 627.0, 648.0, 649.0, 649.0, 649.0, 649.0, 661.0, 671.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 689.0, 699.0, 713.0, 837.0, 954.0, 983.0, 1112.0, 1114.0, 1141.0, 1143.0, 1200.0, 1205.0, 1233.0, 1244.0, 1284.0, 1284.0, 1390.0, 1395.0, 1395.0, 1413.0, 1425.0, 1462.0, 1506.0, 1508.0, 1519.0, 1548.0, 1553.0, 1555.0, 1558.0, 1615.0, 1618.0, 1645.0, 1645.0, 1646.0, 1658.0, 1669.0, 1715.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1817.0, 1819.0, 1829.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1843.0, 1857.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1870.0, 1870.0, 1871.0, 1876.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1888.0, 1893.0, 1893.0, 1893.0, 1894.0, 1934.0, 1934.0, 1936.0, 3248.0, 3251.0, 3273.0, 3284.0, 3299.0, 4004.0, 4010.0, 4014.0, 4025.0, 4055.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4067.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4080.0, 5018.0, 5024.0, 5040.0, 5025.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 263.0, 276.0, 336.0, 342.0, 379.0, 381.0, 413.0, 438.0, 478.0, 519.0, 550.0, 550.0, 572.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 613.0, 613.0, 617.0, 620.0, 648.0, 648.0, 648.0, 649.0, 649.0, 652.0, 657.0, 670.0, 671.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 687.0, 689.0, 704.0, 827.0, 884.0, 909.0, 981.0, 1103.0, 1137.0, 1143.0, 1200.0, 1211.0, 1266.0, 1278.0, 1294.0, 1381.0, 1395.0, 1414.0, 1447.0, 1465.0, 1545.0, 1555.0, 1556.0, 1558.0, 1615.0, 1615.0, 1615.0, 1615.0, 1623.0, 1645.0, 1645.0, 1645.0, 1647.0, 1658.0, 1684.0, 1686.0, 1715.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1817.0, 1820.0, 1820.0, 1820.0, 1829.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1843.0, 1864.0, 1864.0, 1864.0, 1864.0, 1870.0, 1870.0, 1871.0, 1871.0, 1878.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1893.0, 1893.0, 1893.0, 1893.0, 1894.0, 3218.0, 3221.0, 3265.0, 3274.0, 3289.0, 3299.0, 4008.0, 4014.0, 4014.0, 4025.0, 4050.0, 4055.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4071.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4075.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4081.0, 5011.0, 5020.0, 5040.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 263.0, 281.0, 379.0, 380.0, 413.0, 464.0, 474.0, 480.0, 519.0, 550.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 613.0, 613.0, 618.0, 649.0, 649.0, 653.0, 671.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 687.0, 689.0, 699.0, 884.0, 925.0, 1023.0, 1103.0, 1127.0, 1137.0, 1140.0, 1141.0, 1144.0, 1233.0, 1272.0, 1284.0, 1284.0, 1294.0, 1390.0, 1394.0, 1413.0, 1512.0, 1519.0, 1542.0, 1555.0, 1555.0, 1615.0, 1615.0, 1645.0, 1645.0, 1647.0, 1682.0, 1738.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0\u001b[0m\n",
      "\u001b[34m, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1820.0, 1829.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1864.0, 1864.0, 1864.0, 1865.0, 1865.0, 1870.0, 1870.0, 1871.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1892.0, 1893.0, 1893.0, 1894.0, 1894.0, 3246.0, 3254.0, 3265.0, 3277.0, 3299.0, 4010.0, 4014.0, 4016.0, 4025.0, 4051.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4080.0, 4081.0, 5016.0, 5033.0, 5040.0, 5041.0 ], [ 5040.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 276.0, 276.0, 281.0, 374.0, 379.0, 380.0, 413.0, 460.0, 474.0, 478.0, 546.0, 550.0, 557.0, 572.0, 604.0, 604.0, 604.0, 604.0, 604.0, 611.0, 611.0, 611.0, 613.0, 613.0, 627.0, 648.0, 648.0, 649.0, 649.0, 654.0, 663.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 679.0, 679.0, 689.0, 699.0, 881.0, 884.0, 904.0, 976.0, 983.0, 1112.0, 1127.0, 1137.0, 1141.0, 1144.0, 1200.0, 1205.0, 1234.0, 1272.0, 1284.0, 1284.0, 1294.0, 1353.0, 1395.0, 1395.0, 1413.0, 1465.0, 1508.0, 1519.0, 1545.0, 1553.0, 1558.0, 1615.0, 1615.0, 1645.0, 1645.0, 1647.0, 1658.0, 1671.0, 1682.0, 1715.0, 1738.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1817.0, 1819.0, 1820.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1843.0, 1864.0, 1864.0, 1864.0, 1865.0, 1870.0, 1870.0, 1871.0, 1871.0, 1876.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1889.0, 1893.0, 1893.0, 1893.0, 1894.0, 3219.0, 3265.0, 3274.0, 3278.0, 3299.0, 4004.0, 4014.0, 4014.0, 4050.0, 4051.0, 4055.0, 4056.0, 4056.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4062.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4074.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4078.0, 4080.0, 5019.0, 5019.0, 5034.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 134.0, 276.0, 342.0, 379.0, 393.0, 432.0, 474.0, 478.0, 480.0, 557.0, 572.0, 604.0, 604.0, 604.0, 604.0, 611.0, 612.0, 613.0, 617.0, 639.0, 649.0, 649.0, 654.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 679.0, 687.0, 702.0, 883.0, 1112.0, 1135.0, 1143.0, 1200.0, 1233.0, 1278.0, 1328.0, 1395.0, 1395.0, 1465.0, 1506.0, 1522.0, 1545.0, 1615.0, 1615.0, 1644.0, 1645.0, 1679.0, 1715.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1817.0, 1820.0, 1829.0, 1829.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1842.0, 1864.0, 1864.0, 1864.0, 1865.0, 1870.0, 1871.0, 1871.0, 1871.0, 1878.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1884.0, 1890.0, 1893.0, 1893.0, 1934.0, 3265.0, 3278.0, 4002.0, 4011.0, 4016.0, 4050.0, 4056.0, 4056.0, 4056.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4057.0, 4068.0, 4074.0, 4074.0, 4074.0, 4074.0, 4075.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4076.0, 4080.0, 5020.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"p3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 66.14992164898746,\n",
      "      \"sum\" : 2195119.0,\n",
      "      \"std_dev\" : 394.3956189732632,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 5040.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 504.0,\n",
      "            \"count\" : 32000.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 504.0,\n",
      "            \"upper_bound\" : 1008.0,\n",
      "            \"count\" : 288.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1008.0,\n",
      "            \"upper_bound\" : 1512.0,\n",
      "            \"count\" : 64.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1512.0,\n",
      "            \"upper_bound\" : 2016.0,\n",
      "            \"count\" : 660.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2016.0,\n",
      "            \"upper_bound\" : 2520.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2520.0,\n",
      "            \"upper_bound\" : 3024.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3024.0,\n",
      "            \"upper_bound\" : 3528.0,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3528.0,\n",
      "            \"upper_bound\" : 4032.0,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4032.0,\n",
      "            \"upper_bound\" : 4536.0,\n",
      "            \"count\" : 144.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4536.0,\n",
      "            \"upper_bound\" : 5040.0,\n",
      "            \"count\" : 8.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 281.0, 604.0, 613.0, 613.0, 676.0, 676.0, 676.0, 676.0, 676.0, 689.0, 1125.0, 1439.0, 1519.0, 1558.0, 1715.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1829.0, 1829.0, 1864.0, 1870.0, 1884.0, 1893.0, 3250.0, 4050.0, 4057.0, 4074.0, 4057.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 312.0, 480.0, 604.0, 613.0, 617.0, 652.0, 676.0, 676.0, 676.0, 676.0, 852.0, 1141.0, 1506.0, 1545.0, 1615.0, 1650.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1864.0, 1884.0, 1884.0, 1893.0, 1894.0, 3278.0, 4013.0, 4056.0, 4057.0, 4071.0, 4075.0, 4076.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 340.0, 480.0, 604.0, 648.0, 666.0, 676.0, 676.0, 676.0, 676.0, 676.0, 676.0, 679.0, 1272.0, 1425.0, 1556.0, 1615.0, 1682.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1819.0, 1864.0, 1884.0, 1893.0, 4042.0, 4056.0, 4057.0, 4057.0, 4057.0, 4076.0, 4076.0, 5016.0, 5040.0 ], [ 4080.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      " 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 134.0, 342.0, 550.0, 604.0, 604.0, 612.0, 648.0, 676.0, 676.0, 676.0, 676.0, 837.0, 1349.0, 1512.0, 1556.0, 1645.0, 1647.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1817.0, 1829.0, 1878.0, 1884.0, 1893.0, 4011.0, 4057.0, 4057.0, 4076.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 276.0, 463.0, 612.0, 613.0, 649.0, 676.0, 676.0, 883.0, 1137.0, 1447.0, 1560.0, 1645.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1807.0, 1829.0, 1878.0, 1884.0, 1894.0, 4056.0, 4057.0, 4061.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"alcohol\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.03531822565091611,\n",
      "      \"sum\" : 1172.0,\n",
      "      \"std_dev\" : 0.18458290437574912,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 32004.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 1180.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"drug\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.02305327868852459,\n",
      "      \"sum\" : 765.0,\n",
      "      \"std_dev\" : 0.15007273246740668,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 32420.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 764.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"fire\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 9.944551591128256E-4,\n",
      "      \"sum\" : 33.0,\n",
      "      \"std_dev\" : 0.03151929913639169,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 33152.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 32.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sex_M\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.5383919961427194,\n",
      "      \"sum\" : 17866.0,\n",
      "      \"std_dev\" : 0.49852387568919704,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 15324.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 17860.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sex_F\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.4616080038572806,\n",
      "      \"sum\" : 15318.0,\n",
      "      \"std_dev\" : 0.498523875689197,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 17860.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 15324.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_V\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.3289235776277724,\n",
      "      \"sum\" : 10915.0,\n",
      "      \"std_dev\" : 0.46982215540384953,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 22280.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 10904.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_C\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.2965887174541948,\n",
      "      \"sum\" : 9842.0,\n",
      "      \"std_dev\" : 0.45675359892733275,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 23344.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 9840.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_L\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.14742044358727097,\n",
      "      \"sum\" : 4892.0,\n",
      "      \"std_dev\" : 0.35452454978435977,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 28300.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 4884.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_S\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.12207690453230473,\n",
      "      \"sum\" : 4051.0,\n",
      "      \"std_dev\" : 0.3273746079220486,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 29140.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 4044.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country_of_origin_M\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.10499035679845709,\n",
      "      \"sum\" : 3484.0,\n",
      "      \"std_dev\" : 0.3065409952645652,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 29696.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3488.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_death_2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.5421287367405979,\n",
      "      \"sum\" : 17990.0,\n",
      "      \"std_dev\" : 0.4982220082861071,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 15188.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 17996.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_death_0\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.3604447926711668,\n",
      "      \"sum\" : 11961.0,\n",
      "      \"std_dev\" : 0.4801295076408098,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 21212.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 11972.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_death_1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.0974264705882353,\n",
      "      \"sum\" : 3233.0,\n",
      "      \"std_dev\" : 0.2965376087732463,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 29944.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3240.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Home\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.5099445515911283,\n",
      "      \"sum\" : 16922.0,\n",
      "      \"std_dev\" : 0.49990109611167327,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 16256.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 16928.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Not recorded\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.2778447444551591,\n",
      "      \"sum\" : 9220.0,\n",
      "      \"std_dev\" : 0.44793642677706563,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 23952.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 9232.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_School/ Sports Complex\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.09820998071359692,\n",
      "      \"sum\" : 3259.0,\n",
      "      \"std_dev\" : 0.29759835416519326,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 29924.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3260.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Public property\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.09233365477338476,\n",
      "      \"sum\" : 3064.0,\n",
      "      \"std_dev\" : 0.2894963747088629,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 30120.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3064.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Street\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.020973963355834138,\n",
      "      \"sum\" : 696.0,\n",
      "      \"std_dev\" : 0.14329709074849442,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 32492.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 692.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Unknown\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 6.62970106075217E-4,\n",
      "      \"sum\" : 22.0,\n",
      "      \"std_dev\" : 0.0257396693202082,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 33164.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 20.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"place_of_incident_Industrial area\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 3.0135004821600772E-5,\n",
      "      \"sum\" : 1.0,\n",
      "      \"std_dev\" : 0.0054894532244190945,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 33184.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 0.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_less than 20\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.5349867405978785,\n",
      "      \"sum\" : 17753.0,\n",
      "      \"std_dev\" : 0.49877442595058763,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 15432.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 17752.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_60 above\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.26449493731919,\n",
      "      \"sum\" : 8777.0,\n",
      "      \"std_dev\" : 0.4410639017780834,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 24404.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 8780.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_20 to 40\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.10508076181292189,\n",
      "      \"sum\" : 3487.0,\n",
      "      \"std_dev\" : 0.3066574559826287,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 29708.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3476.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_bins_41 to 60\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.09543756027000964,\n",
      "      \"sum\" : 3167.0,\n",
      "      \"std_dev\" : 0.29381836627365093,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 30016.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3168.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"insurance_grp_bin_less than 50\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.623945274831244,\n",
      "      \"sum\" : 20705.0,\n",
      "      \"std_dev\" : 0.4843940223072606,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 12480.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 20704.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"insurance_grp_bin_greater than 50\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 33184,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.37605472516875604,\n",
      "      \"sum\" : 12479.0,\n",
      "      \"std_dev\" : 0.4843940223072608,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 20696.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 12488.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ ], [ ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  } ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  FileUtil:29 - Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnClientSchedulerBackend:54 - Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnClientSchedulerBackend:54 - Shutting down all executors\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  YarnClientSchedulerBackend:54 - Stopped\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  MemoryStore:54 - MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  BlockManager:54 - BlockManager stopped\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  SparkContext:54 - Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  Main:65 - Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  Main:141 - Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  ShutdownHookManager:54 - Shutdown hook called\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-22d1a424-5423-4821-bbd7-d810af8a3dea\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:42 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-2d8d30ab-6ba1-44ea-9fc2-00ab349ff517\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:43,192 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2022-08-20 11:57:43,193 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating model monitoring job\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=5,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "\n",
    "my_default_monitor_baseline = my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri+'/training-dataset-with-header.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the generated constraints and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Files:\n",
      "model_monitor/baselining/results/constraints.json\n",
      " model_monitor/baselining/results/statistics.json\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client('s3')\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=baseline_results_prefix)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get('Contents')]\n",
    "print(\"Found Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Integral</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>23791.985626</td>\n",
       "      <td>789513251.0</td>\n",
       "      <td>13681.213108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47405.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 4741.4, '...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [14.0, 34.0, 86.0, 159.0, 216.0, 236....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age_years</td>\n",
       "      <td>Integral</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>30.991532</td>\n",
       "      <td>1028423.0</td>\n",
       "      <td>31.352060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 11.2, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insurance_grp</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>42.474958</td>\n",
       "      <td>1409489.0</td>\n",
       "      <td>28.883565</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'lower_bound': 2.0, 'upper_bound': 11.9, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_fam_member</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>1.466671</td>\n",
       "      <td>48670.0</td>\n",
       "      <td>1.165530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 1.7, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_visit_count</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917551</td>\n",
       "      <td>30448.0</td>\n",
       "      <td>0.918582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.6, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diagnosis_code_1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>58.958625</td>\n",
       "      <td>1956483.0</td>\n",
       "      <td>5.782184</td>\n",
       "      <td>41.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>[{'lower_bound': 41.0, 'upper_bound': 44.3, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [41.0, 41.0, 41.0, 41.0, 41.0, 41.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diagnosis_code_2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>23.107883</td>\n",
       "      <td>766812.0</td>\n",
       "      <td>35.311406</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>[{'lower_bound': -1.0, 'upper_bound': 8.5, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diagnosis_code_3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>19.695727</td>\n",
       "      <td>653583.0</td>\n",
       "      <td>29.023339</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>[{'lower_bound': -1.0, 'upper_bound': 6.5, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>2326.318437</td>\n",
       "      <td>77196551.0</td>\n",
       "      <td>1388.762605</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5044.0</td>\n",
       "      <td>[{'lower_bound': 106.0, 'upper_bound': 599.8, ...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [115.0, 131.0, 214.0, 252.0, 268.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>520.735716</td>\n",
       "      <td>17280094.0</td>\n",
       "      <td>1051.882997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5043.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 504.3, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>66.149922</td>\n",
       "      <td>2195119.0</td>\n",
       "      <td>394.395619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 504.0, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035318</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>0.184583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drug</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023053</td>\n",
       "      <td>765.0</td>\n",
       "      <td>0.150073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fire</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.031519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sex_M</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538392</td>\n",
       "      <td>17866.0</td>\n",
       "      <td>0.498524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sex_F</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461608</td>\n",
       "      <td>15318.0</td>\n",
       "      <td>0.498524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>country_of_origin_V</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328924</td>\n",
       "      <td>10915.0</td>\n",
       "      <td>0.469822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>country_of_origin_C</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296589</td>\n",
       "      <td>9842.0</td>\n",
       "      <td>0.456754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>country_of_origin_L</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147420</td>\n",
       "      <td>4892.0</td>\n",
       "      <td>0.354525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>country_of_origin_S</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122077</td>\n",
       "      <td>4051.0</td>\n",
       "      <td>0.327375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>country_of_origin_M</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104990</td>\n",
       "      <td>3484.0</td>\n",
       "      <td>0.306541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>place_of_death_2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542129</td>\n",
       "      <td>17990.0</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>place_of_death_0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>11961.0</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>place_of_death_1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097426</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>0.296538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>place_of_incident_Home</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509945</td>\n",
       "      <td>16922.0</td>\n",
       "      <td>0.499901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>place_of_incident_Not recorded</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277845</td>\n",
       "      <td>9220.0</td>\n",
       "      <td>0.447936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>place_of_incident_School/ Sports Complex</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098210</td>\n",
       "      <td>3259.0</td>\n",
       "      <td>0.297598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>place_of_incident_Public property</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092334</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>0.289496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>place_of_incident_Street</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>696.0</td>\n",
       "      <td>0.143297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>place_of_incident_Unknown</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.025740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>place_of_incident_Industrial area</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>age_bins_less than 20</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534987</td>\n",
       "      <td>17753.0</td>\n",
       "      <td>0.498774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>age_bins_60 above</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264495</td>\n",
       "      <td>8777.0</td>\n",
       "      <td>0.441064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>age_bins_20 to 40</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105081</td>\n",
       "      <td>3487.0</td>\n",
       "      <td>0.306657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>age_bins_41 to 60</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095438</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>0.293818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>insurance_grp_bin_less than 50</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623945</td>\n",
       "      <td>20705.0</td>\n",
       "      <td>0.484394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>insurance_grp_bin_greater than 50</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>33184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376055</td>\n",
       "      <td>12479.0</td>\n",
       "      <td>0.484394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name inferred_type  \\\n",
       "0                                        _c0      Integral   \n",
       "1                                  age_years      Integral   \n",
       "2                              insurance_grp    Fractional   \n",
       "3                              no_fam_member    Fractional   \n",
       "4                          total_visit_count    Fractional   \n",
       "5                           diagnosis_code_1    Fractional   \n",
       "6                           diagnosis_code_2    Fractional   \n",
       "7                           diagnosis_code_3    Fractional   \n",
       "8                                         p1    Fractional   \n",
       "9                                         p2    Fractional   \n",
       "10                                        p3    Fractional   \n",
       "11                                   alcohol    Fractional   \n",
       "12                                      drug    Fractional   \n",
       "13                                      fire    Fractional   \n",
       "14                                     sex_M    Fractional   \n",
       "15                                     sex_F    Fractional   \n",
       "16                       country_of_origin_V    Fractional   \n",
       "17                       country_of_origin_C    Fractional   \n",
       "18                       country_of_origin_L    Fractional   \n",
       "19                       country_of_origin_S    Fractional   \n",
       "20                       country_of_origin_M    Fractional   \n",
       "21                          place_of_death_2    Fractional   \n",
       "22                          place_of_death_0    Fractional   \n",
       "23                          place_of_death_1    Fractional   \n",
       "24                    place_of_incident_Home    Fractional   \n",
       "25            place_of_incident_Not recorded    Fractional   \n",
       "26  place_of_incident_School/ Sports Complex    Fractional   \n",
       "27         place_of_incident_Public property    Fractional   \n",
       "28                  place_of_incident_Street    Fractional   \n",
       "29                 place_of_incident_Unknown    Fractional   \n",
       "30         place_of_incident_Industrial area    Fractional   \n",
       "31                     age_bins_less than 20    Fractional   \n",
       "32                         age_bins_60 above    Fractional   \n",
       "33                         age_bins_20 to 40    Fractional   \n",
       "34                         age_bins_41 to 60    Fractional   \n",
       "35            insurance_grp_bin_less than 50    Fractional   \n",
       "36         insurance_grp_bin_greater than 50    Fractional   \n",
       "\n",
       "    numerical_statistics.common.num_present  \\\n",
       "0                                     33184   \n",
       "1                                     33184   \n",
       "2                                     33184   \n",
       "3                                     33184   \n",
       "4                                     33184   \n",
       "5                                     33184   \n",
       "6                                     33184   \n",
       "7                                     33184   \n",
       "8                                     33184   \n",
       "9                                     33184   \n",
       "10                                    33184   \n",
       "11                                    33184   \n",
       "12                                    33184   \n",
       "13                                    33184   \n",
       "14                                    33184   \n",
       "15                                    33184   \n",
       "16                                    33184   \n",
       "17                                    33184   \n",
       "18                                    33184   \n",
       "19                                    33184   \n",
       "20                                    33184   \n",
       "21                                    33184   \n",
       "22                                    33184   \n",
       "23                                    33184   \n",
       "24                                    33184   \n",
       "25                                    33184   \n",
       "26                                    33184   \n",
       "27                                    33184   \n",
       "28                                    33184   \n",
       "29                                    33184   \n",
       "30                                    33184   \n",
       "31                                    33184   \n",
       "32                                    33184   \n",
       "33                                    33184   \n",
       "34                                    33184   \n",
       "35                                    33184   \n",
       "36                                    33184   \n",
       "\n",
       "    numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                         0               23791.985626   \n",
       "1                                         0                  30.991532   \n",
       "2                                         0                  42.474958   \n",
       "3                                         0                   1.466671   \n",
       "4                                         0                   0.917551   \n",
       "5                                         0                  58.958625   \n",
       "6                                         0                  23.107883   \n",
       "7                                         0                  19.695727   \n",
       "8                                         0                2326.318437   \n",
       "9                                         0                 520.735716   \n",
       "10                                        0                  66.149922   \n",
       "11                                        0                   0.035318   \n",
       "12                                        0                   0.023053   \n",
       "13                                        0                   0.000994   \n",
       "14                                        0                   0.538392   \n",
       "15                                        0                   0.461608   \n",
       "16                                        0                   0.328924   \n",
       "17                                        0                   0.296589   \n",
       "18                                        0                   0.147420   \n",
       "19                                        0                   0.122077   \n",
       "20                                        0                   0.104990   \n",
       "21                                        0                   0.542129   \n",
       "22                                        0                   0.360445   \n",
       "23                                        0                   0.097426   \n",
       "24                                        0                   0.509945   \n",
       "25                                        0                   0.277845   \n",
       "26                                        0                   0.098210   \n",
       "27                                        0                   0.092334   \n",
       "28                                        0                   0.020974   \n",
       "29                                        0                   0.000663   \n",
       "30                                        0                   0.000030   \n",
       "31                                        0                   0.534987   \n",
       "32                                        0                   0.264495   \n",
       "33                                        0                   0.105081   \n",
       "34                                        0                   0.095438   \n",
       "35                                        0                   0.623945   \n",
       "36                                        0                   0.376055   \n",
       "\n",
       "    numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                789513251.0                  13681.213108   \n",
       "1                  1028423.0                     31.352060   \n",
       "2                  1409489.0                     28.883565   \n",
       "3                    48670.0                      1.165530   \n",
       "4                    30448.0                      0.918582   \n",
       "5                  1956483.0                      5.782184   \n",
       "6                   766812.0                     35.311406   \n",
       "7                   653583.0                     29.023339   \n",
       "8                 77196551.0                   1388.762605   \n",
       "9                 17280094.0                   1051.882997   \n",
       "10                 2195119.0                    394.395619   \n",
       "11                    1172.0                      0.184583   \n",
       "12                     765.0                      0.150073   \n",
       "13                      33.0                      0.031519   \n",
       "14                   17866.0                      0.498524   \n",
       "15                   15318.0                      0.498524   \n",
       "16                   10915.0                      0.469822   \n",
       "17                    9842.0                      0.456754   \n",
       "18                    4892.0                      0.354525   \n",
       "19                    4051.0                      0.327375   \n",
       "20                    3484.0                      0.306541   \n",
       "21                   17990.0                      0.498222   \n",
       "22                   11961.0                      0.480130   \n",
       "23                    3233.0                      0.296538   \n",
       "24                   16922.0                      0.499901   \n",
       "25                    9220.0                      0.447936   \n",
       "26                    3259.0                      0.297598   \n",
       "27                    3064.0                      0.289496   \n",
       "28                     696.0                      0.143297   \n",
       "29                      22.0                      0.025740   \n",
       "30                       1.0                      0.005489   \n",
       "31                   17753.0                      0.498774   \n",
       "32                    8777.0                      0.441064   \n",
       "33                    3487.0                      0.306657   \n",
       "34                    3167.0                      0.293818   \n",
       "35                   20705.0                      0.484394   \n",
       "36                   12479.0                      0.484394   \n",
       "\n",
       "    numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                        1.0                   47405.0   \n",
       "1                        0.0                     112.0   \n",
       "2                        2.0                     101.0   \n",
       "3                        1.0                       8.0   \n",
       "4                        0.0                       6.0   \n",
       "5                       41.0                      74.0   \n",
       "6                       -1.0                      94.0   \n",
       "7                       -1.0                      74.0   \n",
       "8                      106.0                    5044.0   \n",
       "9                        0.0                    5043.0   \n",
       "10                       0.0                    5040.0   \n",
       "11                       0.0                       1.0   \n",
       "12                       0.0                       1.0   \n",
       "13                       0.0                       1.0   \n",
       "14                       0.0                       1.0   \n",
       "15                       0.0                       1.0   \n",
       "16                       0.0                       1.0   \n",
       "17                       0.0                       1.0   \n",
       "18                       0.0                       1.0   \n",
       "19                       0.0                       1.0   \n",
       "20                       0.0                       1.0   \n",
       "21                       0.0                       1.0   \n",
       "22                       0.0                       1.0   \n",
       "23                       0.0                       1.0   \n",
       "24                       0.0                       1.0   \n",
       "25                       0.0                       1.0   \n",
       "26                       0.0                       1.0   \n",
       "27                       0.0                       1.0   \n",
       "28                       0.0                       1.0   \n",
       "29                       0.0                       1.0   \n",
       "30                       0.0                       1.0   \n",
       "31                       0.0                       1.0   \n",
       "32                       0.0                       1.0   \n",
       "33                       0.0                       1.0   \n",
       "34                       0.0                       1.0   \n",
       "35                       0.0                       1.0   \n",
       "36                       0.0                       1.0   \n",
       "\n",
       "        numerical_statistics.distribution.kll.buckets  \\\n",
       "0   [{'lower_bound': 1.0, 'upper_bound': 4741.4, '...   \n",
       "1   [{'lower_bound': 0.0, 'upper_bound': 11.2, 'co...   \n",
       "2   [{'lower_bound': 2.0, 'upper_bound': 11.9, 'co...   \n",
       "3   [{'lower_bound': 1.0, 'upper_bound': 1.7, 'cou...   \n",
       "4   [{'lower_bound': 0.0, 'upper_bound': 0.6, 'cou...   \n",
       "5   [{'lower_bound': 41.0, 'upper_bound': 44.3, 'c...   \n",
       "6   [{'lower_bound': -1.0, 'upper_bound': 8.5, 'co...   \n",
       "7   [{'lower_bound': -1.0, 'upper_bound': 6.5, 'co...   \n",
       "8   [{'lower_bound': 106.0, 'upper_bound': 599.8, ...   \n",
       "9   [{'lower_bound': 0.0, 'upper_bound': 504.3, 'c...   \n",
       "10  [{'lower_bound': 0.0, 'upper_bound': 504.0, 'c...   \n",
       "11  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "12  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "13  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "14  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "15  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "16  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "17  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "18  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "19  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "20  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "21  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "22  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "23  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "24  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "25  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "26  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "27  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "28  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "29  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "30  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "31  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "32  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "33  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "34  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "35  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "36  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "\n",
       "    numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                                0.64           \n",
       "1                                                0.64           \n",
       "2                                                0.64           \n",
       "3                                                0.64           \n",
       "4                                                0.64           \n",
       "5                                                0.64           \n",
       "6                                                0.64           \n",
       "7                                                0.64           \n",
       "8                                                0.64           \n",
       "9                                                0.64           \n",
       "10                                               0.64           \n",
       "11                                               0.64           \n",
       "12                                               0.64           \n",
       "13                                               0.64           \n",
       "14                                               0.64           \n",
       "15                                               0.64           \n",
       "16                                               0.64           \n",
       "17                                               0.64           \n",
       "18                                               0.64           \n",
       "19                                               0.64           \n",
       "20                                               0.64           \n",
       "21                                               0.64           \n",
       "22                                               0.64           \n",
       "23                                               0.64           \n",
       "24                                               0.64           \n",
       "25                                               0.64           \n",
       "26                                               0.64           \n",
       "27                                               0.64           \n",
       "28                                               0.64           \n",
       "29                                               0.64           \n",
       "30                                               0.64           \n",
       "31                                               0.64           \n",
       "32                                               0.64           \n",
       "33                                               0.64           \n",
       "34                                               0.64           \n",
       "35                                               0.64           \n",
       "36                                               0.64           \n",
       "\n",
       "    numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                              2048.0           \n",
       "1                                              2048.0           \n",
       "2                                              2048.0           \n",
       "3                                              2048.0           \n",
       "4                                              2048.0           \n",
       "5                                              2048.0           \n",
       "6                                              2048.0           \n",
       "7                                              2048.0           \n",
       "8                                              2048.0           \n",
       "9                                              2048.0           \n",
       "10                                             2048.0           \n",
       "11                                             2048.0           \n",
       "12                                             2048.0           \n",
       "13                                             2048.0           \n",
       "14                                             2048.0           \n",
       "15                                             2048.0           \n",
       "16                                             2048.0           \n",
       "17                                             2048.0           \n",
       "18                                             2048.0           \n",
       "19                                             2048.0           \n",
       "20                                             2048.0           \n",
       "21                                             2048.0           \n",
       "22                                             2048.0           \n",
       "23                                             2048.0           \n",
       "24                                             2048.0           \n",
       "25                                             2048.0           \n",
       "26                                             2048.0           \n",
       "27                                             2048.0           \n",
       "28                                             2048.0           \n",
       "29                                             2048.0           \n",
       "30                                             2048.0           \n",
       "31                                             2048.0           \n",
       "32                                             2048.0           \n",
       "33                                             2048.0           \n",
       "34                                             2048.0           \n",
       "35                                             2048.0           \n",
       "36                                             2048.0           \n",
       "\n",
       "    numerical_statistics.distribution.kll.sketch.data  \n",
       "0   [[], [], [14.0, 34.0, 86.0, 159.0, 216.0, 236....  \n",
       "1   [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "2   [[], [], [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2...  \n",
       "3   [[], [], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1...  \n",
       "4   [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "5   [[], [], [41.0, 41.0, 41.0, 41.0, 41.0, 41.0, ...  \n",
       "6   [[], [], [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, ...  \n",
       "7   [[], [], [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, ...  \n",
       "8   [[], [], [115.0, 131.0, 214.0, 252.0, 268.0, 2...  \n",
       "9   [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "10  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "11  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "12  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "13  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "14  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "15  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "16  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "17  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "18  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "19  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "20  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "21  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "22  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "23  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "24  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "25  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "26  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "27  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "28  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "29  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "30  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "31  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "32  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "33  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "34  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "35  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "36  [[], [], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Statistics\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',50)\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age_years</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insurance_grp</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_fam_member</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_visit_count</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diagnosis_code_1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diagnosis_code_2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diagnosis_code_3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drug</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fire</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sex_M</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sex_F</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>country_of_origin_V</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>country_of_origin_C</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>country_of_origin_L</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>country_of_origin_S</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>country_of_origin_M</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>place_of_death_2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>place_of_death_0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>place_of_death_1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>place_of_incident_Home</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>place_of_incident_Not recorded</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>place_of_incident_School/ Sports Complex</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>place_of_incident_Public property</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>place_of_incident_Street</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>place_of_incident_Unknown</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>place_of_incident_Industrial area</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>age_bins_less than 20</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>age_bins_60 above</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>age_bins_20 to 40</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>age_bins_41 to 60</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>insurance_grp_bin_less than 50</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>insurance_grp_bin_greater than 50</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name inferred_type  completeness  \\\n",
       "0                                        _c0      Integral           1.0   \n",
       "1                                  age_years      Integral           1.0   \n",
       "2                              insurance_grp    Fractional           1.0   \n",
       "3                              no_fam_member    Fractional           1.0   \n",
       "4                          total_visit_count    Fractional           1.0   \n",
       "5                           diagnosis_code_1    Fractional           1.0   \n",
       "6                           diagnosis_code_2    Fractional           1.0   \n",
       "7                           diagnosis_code_3    Fractional           1.0   \n",
       "8                                         p1    Fractional           1.0   \n",
       "9                                         p2    Fractional           1.0   \n",
       "10                                        p3    Fractional           1.0   \n",
       "11                                   alcohol    Fractional           1.0   \n",
       "12                                      drug    Fractional           1.0   \n",
       "13                                      fire    Fractional           1.0   \n",
       "14                                     sex_M    Fractional           1.0   \n",
       "15                                     sex_F    Fractional           1.0   \n",
       "16                       country_of_origin_V    Fractional           1.0   \n",
       "17                       country_of_origin_C    Fractional           1.0   \n",
       "18                       country_of_origin_L    Fractional           1.0   \n",
       "19                       country_of_origin_S    Fractional           1.0   \n",
       "20                       country_of_origin_M    Fractional           1.0   \n",
       "21                          place_of_death_2    Fractional           1.0   \n",
       "22                          place_of_death_0    Fractional           1.0   \n",
       "23                          place_of_death_1    Fractional           1.0   \n",
       "24                    place_of_incident_Home    Fractional           1.0   \n",
       "25            place_of_incident_Not recorded    Fractional           1.0   \n",
       "26  place_of_incident_School/ Sports Complex    Fractional           1.0   \n",
       "27         place_of_incident_Public property    Fractional           1.0   \n",
       "28                  place_of_incident_Street    Fractional           1.0   \n",
       "29                 place_of_incident_Unknown    Fractional           1.0   \n",
       "30         place_of_incident_Industrial area    Fractional           1.0   \n",
       "31                     age_bins_less than 20    Fractional           1.0   \n",
       "32                         age_bins_60 above    Fractional           1.0   \n",
       "33                         age_bins_20 to 40    Fractional           1.0   \n",
       "34                         age_bins_41 to 60    Fractional           1.0   \n",
       "35            insurance_grp_bin_less than 50    Fractional           1.0   \n",
       "36         insurance_grp_bin_greater than 50    Fractional           1.0   \n",
       "\n",
       "    num_constraints.is_non_negative  \n",
       "0                              True  \n",
       "1                              True  \n",
       "2                              True  \n",
       "3                              True  \n",
       "4                              True  \n",
       "5                              True  \n",
       "6                             False  \n",
       "7                             False  \n",
       "8                              True  \n",
       "9                              True  \n",
       "10                             True  \n",
       "11                             True  \n",
       "12                             True  \n",
       "13                             True  \n",
       "14                             True  \n",
       "15                             True  \n",
       "16                             True  \n",
       "17                             True  \n",
       "18                             True  \n",
       "19                             True  \n",
       "20                             True  \n",
       "21                             True  \n",
       "22                             True  \n",
       "23                             True  \n",
       "24                             True  \n",
       "25                             True  \n",
       "26                             True  \n",
       "27                             True  \n",
       "28                             True  \n",
       "29                             True  \n",
       "30                             True  \n",
       "31                             True  \n",
       "32                             True  \n",
       "33                             True  \n",
       "34                             True  \n",
       "35                             True  \n",
       "36                             True  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Constraints\n",
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Creating a Schedule and Analyzing collected data for data quality issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have collected the data above, analyze and monitor the data with Monitoring Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create a schedule**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, copy over some test scripts to the S3 bucket so that they can be used for pre and post processing\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(code_prefix+\"/preprocessor.py\").upload_file('preprocessor.py')\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(code_prefix+\"/postprocessor.py\").upload_file('postprocessor.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a model monitoring schedule for the endpoint created earlier. Use the baseline resources (constraints and statistics) to compare against the realtime traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating schedule using cron\n",
    "from sagemaker.model_monitor import CronExpressionGenerator \n",
    "from time import gmtime, strftime\n",
    "\n",
    "mon_schedule_name = 'DEMO-Death-Classification-Model' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "s3_report_path = 's3://{}/{}'.format(bucket,'report')\n",
    "\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    #record_preprocessor_script=pre_processor_script,\n",
    "#     post_analytics_processor_script=s3_code_postprocessor_uri,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generating some artificial traffic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below starts a thread to send some traffic to the endpoint. Note that you need to stop the kernel to terminate this thread. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuned-xgboost-2'"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "36\n",
      "[[208, 246, 203, 137, 244, 181, 70, 256, 144, 117, 242, 64, 104, 220, 137, 190, 252, 88, 41, 175, 203, 182, 138, 6, 107, 51, 133, 44, 179, 74, 140, 247, 57, 128, 53, 164], [127, 238, 245, 195, 71, 149, 123, 29, 195, 122, 199, 215, 158, 239, 198, 167, 36, 230, 3, 112, 245, 78, 247, 22, 65, 143, 19, 231, 62, 171, 15, 171, 80, 124, 99, 247], [101, 235, 176, 128, 213, 206, 135, 173, 73, 70, 52, 36, 14, 134, 55, 52, 156, 58, 174, 133, 51, 256, 92, 149, 244, 5, 43, 8, 68, 35, 31, 187, 149, 98, 132, 178], [126, 52, 48, 119, 189, 65, 255, 126, 20, 219, 51, 158, 14, 188, 104, 100, 110, 246, 170, 52, 253, 216, 119, 70, 175, 74, 193, 132, 90, 195, 193, 33, 234, 175, 87, 231], [110, 100, 195, 206, 167, 139, 115, 24, 158, 210, 46, 9, 130, 60, 238, 192, 237, 34, 137, 30, 76, 13, 60, 113, 245, 101, 214, 190, 2, 47, 5, 244, 184, 236, 130, 142], [224, 98, 168, 72, 4, 157, 1, 49, 92, 148, 1, 32, 40, 113, 251, 128, 166, 49, 106, 28, 87, 72, 44, 197, 1, 188, 171, 126, 205, 229, 12, 47, 9, 121, 175, 110], [143, 223, 42, 142, 13, 153, 124, 120, 133, 245, 102, 57, 219, 110, 42, 150, 238, 91, 1, 101, 63, 51, 183, 138, 104, 26, 173, 209, 46, 184, 76, 229, 155, 194, 243, 97], [6, 253, 24, 217, 103, 131, 60, 37, 7, 128, 256, 182, 125, 77, 202, 99, 111, 253, 84, 159, 128, 156, 172, 140, 26, 103, 57, 122, 190, 160, 80, 9, 116, 242, 195, 158], [60, 152, 28, 25, 124, 200, 157, 93, 162, 46, 156, 24, 9, 28, 107, 133, 205, 113, 3, 251, 86, 28, 173, 173, 173, 208, 123, 5, 106, 162, 38, 74, 178, 255, 188, 25], [81, 90, 125, 53, 240, 66, 246, 248, 52, 117, 4, 94, 72, 107, 209, 163, 120, 216, 228, 52, 186, 75, 140, 193, 56, 67, 9, 81, 82, 72, 177, 14, 47, 95, 188, 157]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    test_samples.append([random.randint(1,256) for _ in range(36)])\n",
    "\n",
    "print(len(test_samples))\n",
    "print(len(test_samples[0]))\n",
    "print(test_samples)\n",
    "\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "test_df.to_csv('test_artificial_data.csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "240,236,65,60,126,6,226,238,97,151,184,126,249,238,42,155,19,227,227,239,196,8,94,83,16,225,88,61,148,58,162,45,70,32,65,161\n",
      "110,25,168,181,61,68,165,149,85,113,182,133,188,38,152,76,226,15,33,18,215,238,143,80,114,79,138,194,225,201,239,145,214,177,19,6\n",
      "39,110,65,101,131,99,230,66,88,102,248,227,24,27,224,121,242,214,32,231,202,158,23,201,144,101,167,133,62,187,75,40,173,48,59,131\n",
      "58,250,130,32,111,156,222,177,157,83,31,204,174,255,171,105,139,243,109,229,254,38,60,202,194,177,28,107,150,167,27,118,70,144,243,156\n",
      "158,75,171,192,228,232,94,115,94,64,204,108,78,93,132,203,40,92,39,10,25,44,251,180,73,116,38,220,71,97,108,158,246,205,100,91\n",
      "28,173,127,105,13,116,186,12,179,157,158,79,25,37,214,205,73,151,148,152,139,6,83,108,35,135,169,108,168,52,81,29,94,245,61,44\n",
      "10,110,90,39,75,235,164,213,120,109,134,110,52,216,38,96,68,137,60,98,110,43,193,136,32,251,92,217,101,13,48,221,91,10,15,129\n",
      "123,28,9,152,157,251,123,255,80,185,139,244,230,80,84,238,71,107,218,213,4,255,175,88,87,105,106,188,105,204,47,177,105,236,233,240\n",
      "154,64,179,114,9,53,83,49,200,26,222,32,65,85,38,19,120,238,123,253,8,37,134,105,78,23,87,221,104,194,128,165,98,55,179,128\n",
      "207,216,252,126,170,98,33,132,72,101,34,201,203,75,214,228,230,177,167,170,239,72,39,172,111,117,199,195,233,65,206,185,73,54,85,29\n"
     ]
    }
   ],
   "source": [
    "# Method of passing artificial data\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "import time\n",
    "\n",
    "endpoint_name=predictor.endpoint_name\n",
    "runtime_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "# (just repeating code from above for convenience/ able to run this section independently)\n",
    "def invoke_endpoint(ep_name, file_name, runtime_client):\n",
    "    with open(file_name, 'r') as f:\n",
    "        for row in f:\n",
    "            payload = row.rstrip('\\n')\n",
    "            print(payload)\n",
    "            response = runtime_client.invoke_endpoint(EndpointName=ep_name,\n",
    "                                          ContentType='text/csv', \n",
    "                                          Body=payload)\n",
    "            response['Body'].read()\n",
    "            time.sleep(1)\n",
    "            \n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        invoke_endpoint(endpoint_name, 'test_artificial_data.csv', runtime_client)\n",
    "        \n",
    "thread = Thread(target = invoke_endpoint_forever)\n",
    "thread.start()\n",
    "\n",
    "# Note that you need to stop the kernel to stop the invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Describe and inspect the schedule**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you describe, observe that the MonitoringScheduleStatus changes to Scheduled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "# print('Schedule status: {}'.format(desc_schedule_result['MonitoringScheduleStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyze the Executions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule starts jobs at the previously specified intervals. Here, you list the latest five executions. Note that if you are kicking this off after creating the hourly schedule, you might find the executions empty. You might have to wait until you cross the hour boundary (in UTC) to see executions kick off. The code below has the logic for waiting.\n",
    "\n",
    "Note: Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule your execution. You might see your execution start in anywhere from zero to ~20 minutes from the hour boundary. This is expected and done for load balancing in the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\n",
      "We will have to wait till we hit the hour...\n"
     ]
    }
   ],
   "source": [
    "mon_executions = my_default_monitor.list_executions()\n",
    "print(\"We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\\nWe will have to wait till we hit the hour...\")\n",
    "\n",
    "while len(mon_executions) == 0:\n",
    "    print(\"Waiting for the 1st execution to happen...\")\n",
    "    time.sleep(60)\n",
    "    mon_executions = my_default_monitor.list_executions()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect a specific execution (latest execution)\n",
    "In the previous cell, you picked up the latest completed or failed scheduled execution. Here are the possible terminal states and what each of them mean: \n",
    "* Completed - This means the monitoring execution completed and no issues were found in the violations report.\n",
    "* CompletedWithViolations - This means the execution completed, but constraint violations were detected.\n",
    "* Failed - The monitoring execution failed, maybe due to client error (perhaps incorrect role premissions) or infrastructure issues. Further examination of FailureReason and ExitMessage is necessary to identify what exactly happened.\n",
    "* Stopped - job exceeded max runtime or was manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Latest execution status: Completed\n",
      "Latest execution result: CompletedWithViolations: Job completed successfully with 1 violations.\n"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[-1] # latest execution's index is -1, second to last is -2 and so on..\n",
    "# time.sleep(60)\n",
    "latest_execution.wait(logs=False)\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()['ProcessingJobStatus']))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()['ExitMessage']))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if (latest_job['ProcessingJobStatus'] != 'Completed'):\n",
    "        print(\"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Uri: s3://accidentbucket/report/tuned-xgboost-2/DEMO-Death-Classification-Model2022-08-20-14-23-11/2022/08/20/16\n"
     ]
    }
   ],
   "source": [
    "report_uri=latest_execution.output.destination\n",
    "print('Report Uri: {}'.format(report_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the generated reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report bucket: accidentbucket\n",
      "Report key: report/tuned-xgboost-2/DEMO-Death-Classification-Model2022-08-20-14-23-11/2022/08/20/16\n",
      "Found Report Files:\n",
      "report/tuned-xgboost-2/DEMO-Death-Classification-Model2022-08-20-14-23-11/2022/08/20/16/constraint_violations.json\n"
     ]
    }
   ],
   "source": [
    "# cell 23\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "report_uri = 's3://accidentbucket/report/tuned-xgboost-2/DEMO-Death-Classification-Model2022-08-20-14-23-11/2022/08/20/16'\n",
    "s3uri = urlparse(report_uri)\n",
    "report_bucket = s3uri.netloc\n",
    "report_key = s3uri.path.lstrip('/')\n",
    "print('Report bucket: {}'.format(report_bucket))\n",
    "print('Report key: {}'.format(report_key))\n",
    "\n",
    "s3_client = boto3.Session().client('s3')\n",
    "result = s3_client.list_objects(Bucket=report_bucket, Prefix=report_key)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get('Contents')]\n",
    "print(\"Found Report Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violations report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any violations compared to the baseline, they will be listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra columns</td>\n",
       "      <td>extra_column_check</td>\n",
       "      <td>There are extra columns in current dataset. Number of columns in current dataset: 86, Number of columns in baseline constraints: 37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_name constraint_check_type  \\\n",
       "0  Extra columns    extra_column_check   \n",
       "\n",
       "                                                                                                                           description  \n",
       "0  There are extra columns in current dataset. Number of columns in current dataset: 86, Number of columns in baseline constraints: 37  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 24\n",
    "violations = my_default_monitor.latest_monitoring_constraint_violations()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "constraints_df = pd.json_normalize(violations.body_dict[\"violations\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to check the status and executions of the scheduled Data Monitor: (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3://accidentbucket/report/tuned-xgboost-2/DEMO-Death-Classification-Model2022-08-20-14-23-11/2022/08/\n",
    "mon_schedule_name_tuned_2 = 'DEMO-Death-Classification-Model2022-08-20-14-23-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "my_monitor = DefaultModelMonitor.attach(monitor_schedule_name=mon_schedule_name_tuned_2,sagemaker_session=sagemaker.session.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\n",
      "We will have to wait till we hit the hour...\n"
     ]
    }
   ],
   "source": [
    "mon_executions = my_monitor.list_executions()\n",
    "print(\"We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\\nWe will have to wait till we hit the hour...\")\n",
    "\n",
    "while len(mon_executions) == 0:\n",
    "    print(\"Waiting for the 1st execution to happen...\")\n",
    "    time.sleep(60)\n",
    "    mon_executions = my_monitor.list_executions()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Latest execution status: Completed\n",
      "Latest execution result: CompletedWithViolations: Job completed successfully with 36 violations.\n"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[-1] # latest execution's index is -1, second to last is -2 and so on..\n",
    "# time.sleep(60)\n",
    "latest_execution.wait(logs=False)\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()['ProcessingJobStatus']))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()['ExitMessage']))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if (latest_job['ProcessingJobStatus'] != 'Completed'):\n",
    "        print(\"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Scheduled\n"
     ]
    }
   ],
   "source": [
    "desc_schedule_result = my_monitor.describe_schedule()\n",
    "print('Schedule status: {}'.format(desc_schedule_result['MonitoringScheduleStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:143176219551:monitoring-schedule/demo-death-classification-model2022-08-20-14-23-11',\n",
       " 'MonitoringScheduleName': 'DEMO-Death-Classification-Model2022-08-20-14-23-11',\n",
       " 'MonitoringScheduleStatus': 'Scheduled',\n",
       " 'MonitoringType': 'DataQuality',\n",
       " 'CreationTime': datetime.datetime(2022, 8, 20, 14, 23, 12, 347000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 8, 26, 9, 17, 9, 740000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'data-quality-job-definition-2022-08-20-14-23-12-083',\n",
       "  'MonitoringType': 'DataQuality'},\n",
       " 'EndpointName': 'tuned-xgboost-2',\n",
       " 'LastMonitoringExecutionSummary': {'MonitoringScheduleName': 'DEMO-Death-Classification-Model2022-08-20-14-23-11',\n",
       "  'ScheduledTime': datetime.datetime(2022, 8, 26, 9, 0, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2022, 8, 26, 9, 9, 32, 148000, tzinfo=tzlocal()),\n",
       "  'LastModifiedTime': datetime.datetime(2022, 8, 26, 9, 17, 9, 730000, tzinfo=tzlocal()),\n",
       "  'MonitoringExecutionStatus': 'CompletedWithViolations',\n",
       "  'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:143176219551:processing-job/model-monitoring-202208260900-036241029745e6a5e70ddb5c',\n",
       "  'EndpointName': 'tuned-xgboost-2'},\n",
       " 'ResponseMetadata': {'RequestId': 'ef6fbc73-5b3b-40be-b1b8-8c0cabc561fc',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ef6fbc73-5b3b-40be-b1b8-8c0cabc561fc',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1018',\n",
       "   'date': 'Fri, 26 Aug 2022 09:18:45 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country_of_origin_M</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex_M</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place_of_incident_Public property</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country_of_origin_L</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insurance_grp</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diagnosis_code_1</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>place_of_death_1</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diagnosis_code_3</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c0</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 0.0% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>place_of_incident_Unknown</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature_name constraint_check_type  \\\n",
       "0                country_of_origin_M       data_type_check   \n",
       "1                              sex_M       data_type_check   \n",
       "2  place_of_incident_Public property       data_type_check   \n",
       "3                country_of_origin_L       data_type_check   \n",
       "4                      insurance_grp       data_type_check   \n",
       "5                   diagnosis_code_1       data_type_check   \n",
       "6                   place_of_death_1       data_type_check   \n",
       "7                   diagnosis_code_3       data_type_check   \n",
       "8                                _c0       data_type_check   \n",
       "9          place_of_incident_Unknown       data_type_check   \n",
       "\n",
       "                                                                                                                                  description  \n",
       "0  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "1  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "2  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "3  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "4  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "5  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "6  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "7  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "8      Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 0.0% of data is Integral.  \n",
       "9  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 24\n",
    "violations = my_monitor.latest_monitoring_constraint_violations()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "constraints_df = pd.json_normalize(violations.body_dict[\"violations\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Latest execution status: Completed\n",
      "Latest execution result: CompletedWithViolations: Job completed successfully with 36 violations.\n"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[-1] # latest execution's index is -1, second to last is -2 and so on..\n",
    "# time.sleep(60)\n",
    "latest_execution.wait(logs=False)\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()['ProcessingJobStatus']))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()['ExitMessage']))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if (latest_job['ProcessingJobStatus'] != 'Completed'):\n",
    "        print(\"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon_executions = my_monitor.list_executions()\n",
    "len(mon_executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country_of_origin_M</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex_M</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place_of_incident_Public property</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country_of_origin_L</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insurance_grp</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diagnosis_code_1</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>place_of_death_1</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diagnosis_code_3</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c0</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 0.0% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>place_of_incident_Unknown</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>place_of_death_2</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>place_of_incident_Home</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>country_of_origin_C</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>place_of_incident_Street</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>country_of_origin_V</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>age_bins_less than 20</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>place_of_incident_School/ Sports Complex</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>place_of_death_0</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fire</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>insurance_grp_bin_greater than 50</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>age_bins_20 to 40</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>age_bins_60 above</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sex_F</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>p2</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>place_of_incident_Not recorded</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>total_visit_count</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>place_of_incident_Industrial area</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>diagnosis_code_2</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>age_bins_41 to 60</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>no_fam_member</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>drug</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>insurance_grp_bin_less than 50</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>p3</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>p1</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>country_of_origin_S</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature_name constraint_check_type  \\\n",
       "0                        country_of_origin_M       data_type_check   \n",
       "1                                      sex_M       data_type_check   \n",
       "2          place_of_incident_Public property       data_type_check   \n",
       "3                        country_of_origin_L       data_type_check   \n",
       "4                              insurance_grp       data_type_check   \n",
       "5                           diagnosis_code_1       data_type_check   \n",
       "6                           place_of_death_1       data_type_check   \n",
       "7                           diagnosis_code_3       data_type_check   \n",
       "8                                        _c0       data_type_check   \n",
       "9                  place_of_incident_Unknown       data_type_check   \n",
       "10                          place_of_death_2       data_type_check   \n",
       "11                    place_of_incident_Home       data_type_check   \n",
       "12                       country_of_origin_C       data_type_check   \n",
       "13                  place_of_incident_Street       data_type_check   \n",
       "14                       country_of_origin_V       data_type_check   \n",
       "15                     age_bins_less than 20       data_type_check   \n",
       "16  place_of_incident_School/ Sports Complex       data_type_check   \n",
       "17                          place_of_death_0       data_type_check   \n",
       "18                                      fire       data_type_check   \n",
       "19         insurance_grp_bin_greater than 50       data_type_check   \n",
       "20                         age_bins_20 to 40       data_type_check   \n",
       "21                         age_bins_60 above       data_type_check   \n",
       "22                                     sex_F       data_type_check   \n",
       "23                                        p2       data_type_check   \n",
       "24            place_of_incident_Not recorded       data_type_check   \n",
       "25                         total_visit_count       data_type_check   \n",
       "26         place_of_incident_Industrial area       data_type_check   \n",
       "27                          diagnosis_code_2       data_type_check   \n",
       "28                         age_bins_41 to 60       data_type_check   \n",
       "29                             no_fam_member       data_type_check   \n",
       "30                                      drug       data_type_check   \n",
       "31                                   alcohol       data_type_check   \n",
       "32            insurance_grp_bin_less than 50       data_type_check   \n",
       "33                                        p3       data_type_check   \n",
       "34                                        p1       data_type_check   \n",
       "35                       country_of_origin_S       data_type_check   \n",
       "\n",
       "                                                                                                                                   description  \n",
       "0   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "1   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "2   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "3   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "4   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "5   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "6   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "7   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "8       Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 0.0% of data is Integral.  \n",
       "9   Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "10  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "11  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "12  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "13  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "14  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "15  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "16  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "17  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "18  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "19  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "20  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "21  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "22  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "23  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "24  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "25  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "26  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "27  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "28  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "29  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "30  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "31  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "32  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "33  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "34  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  \n",
       "35  Data type match requirement is not met. Expected data type: Fractional, Expected match: 100.0%. Observed: Only 0.0% of data is Fractional.  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
